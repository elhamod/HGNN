{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import CNN\n",
    "import numpy as np\n",
    "\n",
    "# from config_plots import global_settings\n",
    "# global_settings()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining global variables\n",
    "experimentName = \"50_11_hier_phase6\"\n",
    "useRandomSearch = False\n",
    "numOfExperiments=50\n",
    "\n",
    "from configParser import ConfigParser, getModelName\n",
    "hyperpSearchObject = ConfigParser(experimentName).getHyperpSearchObject()\n",
    "\n",
    "import os\n",
    "experimentName = os.path.join(experimentName,\"hyperp-search\")\n",
    "import TrialStatistics\n",
    "ts = TrialStatistics.TrialStatistics(experimentName)\n",
    "ts_genus = TrialStatistics.TrialStatistics(experimentName, \"genus\")\n",
    "\n",
    "import dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0) # 0\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(\"We are using cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "all_experiment_params = []\n",
    "datasetManager = dataLoader.datasetManager(experimentName)\n",
    "def objective(experiment_params):\n",
    "    experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "    \n",
    "    print(\"experiment: \", experiment_params)\n",
    "    all_experiment_params.append(experiment_params)\n",
    "    \n",
    "    # load images\n",
    "    datasetManager.updateParams(experiment_params)\n",
    "    dataset = datasetManager.getDataset()\n",
    "    numberOfSpecies = len(dataset.getSpeciesList())\n",
    "    numberOfGenus = len(dataset.getGenusList())\n",
    "\n",
    "    for i in range(experiment_params[\"numOfTrials\"]):\n",
    "        trialName = os.path.join(experimentName, getModelName(experiment_params, i))\n",
    "\n",
    "        # Train/Load model\n",
    "        architecture = {\n",
    "            \"species\": numberOfSpecies,\n",
    "            \"genus\" : numberOfGenus\n",
    "        }\n",
    "        model = CNN.create_model(architecture, experiment_params)\n",
    "        train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "        if os.path.exists(CNN.getModelFile(trialName)):\n",
    "            df, epochs, time_elapsed = CNN.loadModel(model, trialName)\n",
    "            print(\"Model {0} loaded!\".format(trialName))\n",
    "        else:\n",
    "            df, epochs, time_elapsed = CNN.trainModel(train_loader, \n",
    "                                                      validation_loader, \n",
    "                                                      experiment_params, \n",
    "                                                      model, trialName, test_loader)\n",
    "        \n",
    "        # Update trial outcomes for statistics\n",
    "        predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params)\n",
    "        ts.addTrialPredictions(experiment_params, predlist, lbllist, numberOfSpecies)\n",
    "        micro_f1 = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "        predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "        topk = CNN.top_k_acc(predlist, lbllist, topk=(3,5))\n",
    "\n",
    "        predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params, 'genus')\n",
    "        ts_genus.addTrialPredictions(experiment_params, predlist, lbllist, numberOfGenus)\n",
    "        micro_f1_genus = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "        predlist, lbllist = CNN.getLoaderPredictions(validation_loader, model, experiment_params)\n",
    "        macro_f1_val = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "        ts.addTrial(experiment_params,\n",
    "                {'loss': CNN.getCrossEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                 'average best guess prob': CNN.getAvgProbBestGuessFromLoader(test_loader, model, experiment_params),\n",
    "                 'average correct guess prob': CNN.getAvgProbCorrectGuessFromLoader(test_loader, model, experiment_params),\n",
    "                 'entropy': CNN.getAvgEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                 'accuracy': CNN.getAccuracyFromLoader(test_loader, model, experiment_params),\n",
    "                 'macro_f1_species': micro_f1,\n",
    "                 'macro_f1_genus': micro_f1_genus,\n",
    "                 'time': time_elapsed,\n",
    "                 'epochs': epochs,\n",
    "                 'macro f1 validation': macro_f1_val,\n",
    "                 'top-3': topk[0].cpu().numpy(),\n",
    "                 'top-5': topk[1].cpu().numpy(),\n",
    "                }, i)\n",
    "                \n",
    "    answer ={\n",
    "        'loss': -ts.getStatistic(experiment_params, 'macro f1 validation', 'mean'),\n",
    "        'status': STATUS_OK,}\n",
    "    \n",
    "    return {**experiment_params, **answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment:                                           \n",
      "{'batchSize': 550, 'downsample': False, 'downsampleOutput': 350, 'fc_layers': 1, 'image_path': '/data/BGNN_data/INHS_cropped', 'lambda': 0.716944872997406, 'learning_rate': 0.0008395922131699092, 'n_epochs': 10000, 'normalizeFromResnet': True, 'numOfTrials': 1, 'patience': 100, 'resnet': '18', 'suffix': '50_11', 'takeFromIntermediate': True, 'takeFromIntermediateOutput': 400, 'training_count': 0.64, 'unsupervisedOnTest': False, 'useHeirarchy': True, 'validation_count': 0.16}\n",
      "Creating dataset...                                   \n",
      "Loading dataset...                                    \n",
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (550 of 550) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going through image files\n",
      "Creating dataset... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "N/A% (0 of 550) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved indices...\n",
      "file /data/BGNN_data/INHS_cropped/50_11/50_11_hier_phase6/hyperp-search/tc0.640000_vc0.160000/trainingIndex.pkl read\n",
      "file /data/BGNN_data/INHS_cropped/50_11/50_11_hier_phase6/hyperp-search/tc0.640000_vc0.160000/valIndex.pkl read\n",
      "file /data/BGNN_data/INHS_cropped/50_11/50_11_hier_phase6/hyperp-search/tc0.640000_vc0.160000/testIndex.pkl read\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "Training started...\n",
      "Transfrom images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (550 of 550) |######################| Elapsed Time: 0:00:47 Time:  0:00:47\n",
      "  0% (7 of 10000) |                      | Elapsed Time: 0:01:33 ETA:   5:25:27"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, hp, STATUS_OK, Trials, space_eval, plotting, rand, tpe\n",
    "import pickle\n",
    "\n",
    "trials = Trials()\n",
    "bestLoss = fmin(objective, \n",
    "                        space=hyperpSearchObject, \n",
    "                        algo=rand.suggest if useRandomSearch == False else tpe.suggest, \n",
    "                        trials=trials,\n",
    "                        max_evals=numOfExperiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# bestParams = space_eval(hyperpSearchObject, bestLoss)\n",
    "# print(\"best params = \", pd.DataFrame(bestParams, index=[0]))\n",
    "best_trial = sorted(trials.results, key=lambda x: x['loss'], reverse=True)[0]\n",
    "print(\"Best trial\")\n",
    "display(HTML(pd.DataFrame(best_trial, index=[0]).to_html()))\n",
    "\n",
    "# save trials\n",
    "pickle.dump(trials, open(os.path.join(experimentName,\"trials.p\"), \"wb\"))\n",
    "ts.saveStatistics()\n",
    "ts.saveStatistics(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_params in all_experiment_params:    \n",
    "    print(\"experiment: \", experiment_params)\n",
    "    \n",
    "    datasetManager.updateParams(experiment_params)\n",
    "    dataset = datasetManager.getDataset()\n",
    "    speciesList = dataset.getSpeciesList()\n",
    "    ts.printTrialConfusionMatrix(experiment_params, speciesList, True)\n",
    "    ts.printF1table(experiment_params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
