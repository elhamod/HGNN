{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser, getExperimentParamsAndRecord\n",
    "from HGNN.train import CNN, dataLoader\n",
    "\n",
    "testIndicesFile = \"testIndex.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data/\"\n",
    "experimentName=\"BestModelForJeremy\"\n",
    "trial_hash=\"4481a198e78a77a9e12c52f8fc3f40c73e1c948617ed7d37fbe4dbcb\"\n",
    "\n",
    "cuda=6\n",
    "\n",
    "numOfRows=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 6\n"
     ]
    }
   ],
   "source": [
    "# set cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda)\n",
    "    print(\"using cuda\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'INHS_cropped', 'suffix': '52', 'training_count': 0.64, 'validation_count': 0.16, 'batchSize': 32, 'n_epochs': 5000, 'learning_rate': 0.01, 'numOfTrials': 5, 'patience': 50, 'fc_width': 200, 'fc_layers': 1, 'modelType': 'DISCO', 'lambda': 0.6, 'unsupervisedOnTest': False, 'tl_model': 'ResNet18', 'augmented': False, 'weight_decay': 0}\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 2600/2600 [02:32<00:00, 17.06it/s, fileName=/data/BGNN_data/INHS_cropped/images/INHS_FISH_63588.jpg]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset... Done.\n",
      "file /home/elhamod/HGNN/experiments/BestModelForJeremy/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc/testIndex.csv read\n"
     ]
    }
   ],
   "source": [
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "experiment_params, experimentRecord = getExperimentParamsAndRecord(experimentsPath, experimentName, trial_hash)\n",
    "print(experiment_params)\n",
    "\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "datasetManager = dataLoader.datasetManager(experimentName, True)\n",
    "datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "dataset = datasetManager.getDataset()\n",
    "dataset.toggle_image_loading(augmentation=False, normalization=dataset.normalization_enabled) # Needed so we always get the same prediction accuracy \n",
    "fineList = dataset.csv_processor.getFineList()\n",
    "coarseList = dataset.csv_processor.getCoarseList()\n",
    "\n",
    "# get a test loader without randomization\n",
    "testIndicesFullPath = os.path.join(experimentPathAndName, experimentRecord['datasetName'].item(), testIndicesFile)\n",
    "subset = torch.utils.data.Subset(dataset, dataLoader.readFile(testIndicesFullPath))\n",
    "test_loader = torch.utils.data.DataLoader(subset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = {\n",
    "    \"fine\": len(fineList),\n",
    "    \"coarse\" : len(coarseList)\n",
    "}\n",
    "model = CNN.create_model(architecture, experiment_params)\n",
    "\n",
    "# get the model and the parameters\n",
    "modelName = experimentRecord.iloc[0][\"modelName\"]\n",
    "trialName = os.path.join(experimentPathAndName, modelName)\n",
    "_ = CNN.loadModel(model, trialName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort through predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming images: 100%|██████████| 2600/2600 [00:54<00:00, 47.34it/s]\n"
     ]
    }
   ],
   "source": [
    "df_misclassified = pd.DataFrame(columns=['file name', 'true label', 'probability of true label', 'predicted label'])\n",
    "df_correctlyclassified = pd.DataFrame(columns=['file name', 'true label', 'probability of true label', 'predicted label'])\n",
    "\n",
    "# get probability of correct prediction and true label\n",
    "predProblist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "_, predlist = torch.max(predProblist, 1)\n",
    "lbllist = lbllist.reshape(lbllist.shape[0], -1)\n",
    "correct_predProblist = predProblist.gather(1, lbllist)\n",
    "correct_predProblist = correct_predProblist.reshape(1, -1)\n",
    "correct_predProblist = correct_predProblist[0]\n",
    "\n",
    "for i, lbl in enumerate(lbllist):\n",
    "    prd = predlist[i]\n",
    "    prdProb = correct_predProblist[i]\n",
    "    fileName = subset[i]['fileName']\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        lbl = lbl.cpu()\n",
    "        prd = prd.cpu()\n",
    "        prdProb = prdProb.cpu()\n",
    "\n",
    "    row = {'file name' : fileName ,\n",
    "           'true label' : int(lbl.numpy()), \n",
    "           'probability of true label': float(prdProb.numpy()),\n",
    "           'predicted label' : int(prd.numpy())}\n",
    "    \n",
    "    if(lbl != prd):\n",
    "        df_misclassified = df_misclassified.append(row, ignore_index=True)\n",
    "    else:\n",
    "        df_correctlyclassified = df_correctlyclassified.append(row, ignore_index=True)\n",
    "        \n",
    "df_misclassified = df_misclassified.sort_values(by=[ 'true label', 'probability of true label'])\n",
    "df_correctlyclassified = df_correctlyclassified.sort_values(by=['true label', 'probability of true label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to plot top n of a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_n(df, fig_file_name, numOfRows=None, perRow=5):\n",
    "    if numOfRows is None:\n",
    "        numOfRows = df['true label'].nunique()\n",
    "    topn = df.groupby('true label').head(perRow)\n",
    "    fig, axes = plt.subplots(ncols=perRow, nrows=numOfRows, figsize=(15, 3*numOfRows), dpi= 300)\n",
    "    for i, row in enumerate(axes):\n",
    "        topn_lbl = topn[topn['true label']==i]\n",
    "        for j, ax in enumerate(row):\n",
    "            if len(topn_lbl.index) > j:\n",
    "                entry = topn_lbl.iloc[j]\n",
    "                fileName = entry['file name']\n",
    "                prediction = entry['predicted label']\n",
    "                trueLabel = entry['true label']\n",
    "                prob = entry['probability of true label']\n",
    "                ax.set_title(f\"{fileName} \\n {fineList[trueLabel]} \\n as \\n  {fineList[prediction]} \\n prob: {round(prob, 3)}\")\n",
    "                img = plt.imread(os.path.join(dataPath, experiment_params['image_path'], 'images',fileName ))\n",
    "                ax.imshow(img)             \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(experimentPathAndName, modelName, fig_file_name))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save mispredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_misclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'misclassified examples.csv'))\n",
    "plot_top_n(df_misclassified, \"misclassified examples.pdf\", numOfRows=numOfRows)\n",
    "df_misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correctlyclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'correctly classified examples.csv'))\n",
    "plot_top_n(df_correctlyclassified, \"correctly classified.pdf\", numOfRows=numOfRows)\n",
    "df_correctlyclassified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
