{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from PIL import Image, ImageDraw \n",
    "import math\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser, getExperimentParamsAndRecord\n",
    "from HGNN.train import CNN, dataLoader\n",
    "\n",
    "testIndicesFile = \"testIndex.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data/\"\n",
    "experimentName=\"biology_paper_augmentation_effect\"\n",
    "trial_hash=\"825aa4c30a7ace1285f54f2f26af4f9702b5fec2a2f7edf3b35666f7\"\n",
    "\n",
    "cuda=7\n",
    "\n",
    "numOfRows=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 7\n"
     ]
    }
   ],
   "source": [
    "# set cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda)\n",
    "    print(\"using cuda\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'INHS_cropped', 'suffix': 'biology_paper_200max', 'training_count': 0.64, 'validation_count': 0.16, 'batchSize': 128, 'n_epochs': 500, 'learning_rate': 5e-05, 'numOfTrials': 3, 'patience': 10, 'fc_width': 200, 'fc_layers': 1, 'modelType': 'BB', 'lambda': 0.6, 'unsupervisedOnTest': False, 'tl_model': 'ResNet18', 'augmented': True, 'weight_decay': 0.0001, 'img_res': 448, 'tl_freeze': False, 'cnn_layers': 0, 'cnn_channels': 128, 'pretrained': True, 'two_nets': True, 'link_layer': 'layer3', 'dataset_norm': True, 'aug_profile': 'withRotation_PCA1.5'}\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 6522/6522 [00:26<00:00, 246.36it/s, fileName=/data/BGNN_data/INHS_cropped/images/INHS_FISH_63588_448.jpg]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset... Done.\n",
      "file /home/elhamod/HGNN/experiments/biology_paper_augmentation_effect/datasplits/b4896471167c5599680115e51349929def797e403bead8f0fe554d79/testIndex.csv read\n"
     ]
    }
   ],
   "source": [
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "experiment_params, experimentRecord = getExperimentParamsAndRecord(experimentsPath, experimentName, trial_hash)\n",
    "print(experiment_params)\n",
    "\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "datasetManager = dataLoader.datasetManager(experimentPathAndName, dataPath, True)\n",
    "datasetManager.updateParams(config_parser.fixPaths({**experiment_params,**{'augmented': False}}))\n",
    "dataset = datasetManager.getDataset()\n",
    "dataset.toggle_image_loading(augmentation=False, normalization=dataset.normalization_enabled) # Needed so we always get the same prediction accuracy \n",
    "fineList = dataset.csv_processor.getFineList()\n",
    "coarseList = dataset.csv_processor.getCoarseList()\n",
    "\n",
    "# get a test loader without randomization\n",
    "testIndicesFullPath = os.path.join(experimentPathAndName, experimentRecord['datasetName'].item(), testIndicesFile)\n",
    "subset = torch.utils.data.Subset(dataset, dataLoader.readFile(testIndicesFullPath))\n",
    "test_loader = torch.utils.data.DataLoader(subset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = {\n",
    "    \"fine\": len(fineList),\n",
    "    \"coarse\" : len(coarseList)\n",
    "}\n",
    "model = CNN.create_model(architecture, experiment_params)\n",
    "\n",
    "# get the model and the parameters\n",
    "modelName = experimentRecord.iloc[0][\"modelName\"]\n",
    "trialName = os.path.join(experimentPathAndName, modelName)\n",
    "_ = CNN.loadModel(model, trialName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort through predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming images: 100%|██████████| 6522/6522 [00:11<00:00, 577.45it/s]\n"
     ]
    }
   ],
   "source": [
    "df_misclassified = pd.DataFrame(columns=['file name', 'true label', 'probability of true label', 'predicted label'])\n",
    "df_correctlyclassified_columns = ['file name', 'true label', 'probability of true label']\n",
    "df_correctlyclassified = pd.DataFrame(columns=df_correctlyclassified_columns)\n",
    "\n",
    "# get probability of correct prediction and true label\n",
    "predProblist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "_, predlist = torch.max(predProblist, 1)\n",
    "lbllist = lbllist.reshape(lbllist.shape[0], -1)\n",
    "# True label\n",
    "correct_predProblist = predProblist.gather(1, lbllist)\n",
    "correct_predProblist = correct_predProblist.reshape(1, -1)\n",
    "correct_predProblist = correct_predProblist[0]\n",
    "# Predicted label\n",
    "predicted_predProblist = predProblist.gather(1, predlist.unsqueeze(0).T)\n",
    "predicted_predProblist = predicted_predProblist.reshape(1, -1)\n",
    "predicted_predProblist = predicted_predProblist[0]\n",
    "\n",
    "for i, lbl in enumerate(lbllist):\n",
    "    prd = predlist[i]\n",
    "    correctProb = correct_predProblist[i]\n",
    "    prdProb = predicted_predProblist[i]\n",
    "    fileName = subset[i]['fileName']\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        lbl = lbl.cpu()\n",
    "        prd = prd.cpu()\n",
    "        prdProb = prdProb.cpu()\n",
    "        correctProb = correctProb.cpu()\n",
    "    \n",
    "    if(lbl != prd):\n",
    "        row = {'file name' : fileName ,\n",
    "           'true label' : int(lbl.numpy()), \n",
    "           'probability of true label': float(correctProb.numpy()),\n",
    "           'probability of predicted label': float(prdProb.numpy()),\n",
    "           'predicted label' : int(prd.numpy())}\n",
    "        df_misclassified = df_misclassified.append(row, ignore_index=True)\n",
    "    else:\n",
    "        row = {'file name' : fileName ,\n",
    "           'true label' : int(lbl.numpy()), \n",
    "           'probability of true label': float(correctProb.numpy())}\n",
    "        df_correctlyclassified = df_correctlyclassified.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_misclassified = df_misclassified.sort_values(by=[ 'true label', 'probability of true label'])\n",
    "df_correctlyclassified = df_correctlyclassified.sort_values(by=['true label', 'probability of true label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to plot top n of a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(dataPath, experiment_params['image_path'], 'images')\n",
    "\n",
    "# Given a data frame of specimen, prints a pdf of a grid of those examples with information about them\n",
    "# showPrediction: Should only used to show misclassifications\n",
    "# showClosestClassTrainingExample: Should only used to show misclassifications\n",
    "def plot_top_n(df, fig_file_name, numOfRows=None, perRow=5, show_same_class=True):\n",
    "    \n",
    "    # construct results data frame\n",
    "    h_list = ['image','image','image','image','image',\n",
    "              'closest example from training set','closest example from training set','closest example from training set',]\n",
    "    h2_list = ['file name','true label','probability of true label','predicted label','probability of predicted label',\n",
    "             'file name','true label','cosine similarity',]\n",
    "    if show_same_class:\n",
    "        h_list = h_list + ['closest same class example from training set','closest same class example from training set']\n",
    "        h2_list = h2_list + ['file name','cosine similarity']\n",
    "    df_result = pd.DataFrame(columns = [np.array(h_list), np.array(h2_list)]  )   \n",
    "    \n",
    "    # Disable augmentation\n",
    "    augmentation, normalization, _ = dataset.toggle_image_loading(augmentation=False, normalization=dataset.normalization_enabled)\n",
    "    training_indices = datasetManager.get_indices(\"trainingIndex.csv\")\n",
    "    training_dataset = torch.utils.data.Subset(dataset, training_indices)\n",
    "    \n",
    "    if numOfRows is None:\n",
    "        numOfRows = df['true label'].nunique()\n",
    "    topn = df.groupby('true label').head(perRow)\n",
    "    \n",
    "    rows_per_page = 10\n",
    "    number_of_pages = math.floor(numOfRows/rows_per_page)+1\n",
    "    with tqdm(total=perRow * numOfRows, desc=\"figure\") as bar:\n",
    "        with PdfPages(os.path.join(experimentPathAndName, modelName, fig_file_name+\".pdf\")) as pdf:\n",
    "            for k in range(number_of_pages):\n",
    "                fig, axes = plt.subplots(ncols=perRow, nrows=rows_per_page, figsize=(15, 4*rows_per_page), dpi= 300)\n",
    "\n",
    "                for i, row in enumerate(axes):\n",
    "                    if i >= numOfRows + k*rows_per_page:\n",
    "                        break\n",
    "                        \n",
    "                    topn_lbl = topn[topn['true label']==i+k*rows_per_page]\n",
    "                    for j, ax in enumerate(row):\n",
    "\n",
    "                        if len(topn_lbl.index) > j:\n",
    "\n",
    "                            entry = topn_lbl.iloc[j]\n",
    "                            fileName = entry['file name']\n",
    "                            trueLabel = entry['true label']\n",
    "                            correct_prob = entry['probability of true label']\n",
    "                            if show_same_class:\n",
    "                                prediction = entry['predicted label']\n",
    "                                predicted_prob = entry['probability of predicted label']\n",
    "                            \n",
    "                            img = Image.open(os.path.join(images_path,fileName))\n",
    "                            img.thumbnail((448,448), Image.ANTIALIAS)\n",
    "\n",
    "                            # get closest training image from dataset training set\n",
    "                            closest, cosine_score = get_closest_example(fileName, dataset, training_dataset, experiment_params, model)\n",
    "                            closest_fileName = closest['fileName']\n",
    "                            closest_species = fineList[closest['fine']]\n",
    "                            img2 = Image.open(os.path.join(images_path,closest_fileName))\n",
    "                            img2.thumbnail((448,448), Image.ANTIALIAS)\n",
    "                            draw = ImageDraw.Draw(img2)\n",
    "                            draw.text((0, 0),\"closest: \" + closest_species,(0,0,0))\n",
    "                            \n",
    "                            vis = np.concatenate((img, img2), axis=0)\n",
    "                            \n",
    "                            # get closest training image from dataset training set of same class\n",
    "                            if show_same_class:\n",
    "                                # get subset of trainign set that corresponds to the true label\n",
    "                                class_training_indices = [indx for indx in training_indices if dataset[indx]['fine'] == trueLabel]\n",
    "                                class_training_dataset = torch.utils.data.Subset(dataset, class_training_indices)\n",
    "\n",
    "                                closest_fromClass, cosine_score_fromClass = get_closest_example(fileName, dataset, class_training_dataset, experiment_params, model)\n",
    "                                closest_fromClass_fileName = closest_fromClass['fileName']\n",
    "                                closest_fromClass_species = fineList[closest_fromClass['fine']]\n",
    "                                img3 = Image.open(os.path.join(images_path,closest_fromClass_fileName))\n",
    "                                img3.thumbnail((448,448), Image.ANTIALIAS)\n",
    "                                draw2 = ImageDraw.Draw(img3)\n",
    "                                draw2.text((0, 0),\"closest same label\",(0,0,0))\n",
    "                                vis = np.concatenate((vis, img3), axis=0)\n",
    "                            \n",
    "                            ax.imshow(vis)\n",
    "                            txt = f\"{fileName} \\n {fineList[trueLabel]}\"\n",
    "                            if show_same_class:\n",
    "                                txt = txt + f\" \\n as {fineList[prediction]}\"\n",
    "                            ax.set_title(txt)\n",
    "                            \n",
    "                            # add to dataframe\n",
    "                            row = {\n",
    "                                ('image', 'file name'): fileName,\n",
    "                                ('image', 'true label'): fineList[trueLabel],\n",
    "                                ('image', 'probability of true label'): round(correct_prob, 3),\n",
    "                                ('closest example from training set', 'file name'): closest_fileName,\n",
    "                                ('closest example from training set', 'true label'): closest_species,\n",
    "                                ('closest example from training set', 'cosine similarity'): round(cosine_score, 3),\n",
    "                            }\n",
    "                            if show_same_class:\n",
    "                                row = {**row, **{\n",
    "                                   ('image', 'predicted label'): fineList[prediction],\n",
    "                                   ('image', 'probability of predicted label'): round(predicted_prob, 3),\n",
    "                                   ('closest same class example from training set', 'file name'): closest_fromClass_fileName,\n",
    "                                   ('closest same class example from training set', 'cosine similarity'): round(cosine_score_fromClass, 3),\n",
    "                               }}\n",
    "                            df_result = df_result.append(row, ignore_index=True)\n",
    "\n",
    "                        bar.update()\n",
    "\n",
    "                fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                pdf.savefig()\n",
    "                df_result.to_csv(os.path.join(experimentPathAndName, modelName, fig_file_name+\".csv\"))\n",
    "                plt.close()\n",
    "\n",
    "    # Reenable aggregation if needed.\n",
    "    dataset.toggle_image_loading(augmentation=augmentation, normalization=normalization)\n",
    "\n",
    "def get_closest_example(fileName, source_dataset, target_dataset, experiment_params, model):\n",
    "    fileName_index = source_dataset.csv_processor.get_index_from_fileName(fileName)\n",
    "    top_1 = torch.topk(CNN.get_distance_from_example(target_dataset, source_dataset[fileName_index], model, experiment_params), 1)\n",
    "    closest = target_dataset[top_1.indices[0][0].item()]\n",
    "    cosine_score = top_1.values[0][0].item()\n",
    "    return closest, cosine_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save mispredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/elhamod/HGNN/experiments/biology_paper_augmentation_effect/datasplits/b4896471167c5599680115e51349929def797e403bead8f0fe554d79/trainingIndex.csv read\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10068b00a8c549f9b9356297e57e327c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='figure', max=155.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name</th>\n",
       "      <th>true label</th>\n",
       "      <th>probability of true label</th>\n",
       "      <th>predicted label</th>\n",
       "      <th>probability of predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>INHS_FISH_51790.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>33</td>\n",
       "      <td>0.984169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>INHS_FISH_41599.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>33</td>\n",
       "      <td>0.858448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INHS_FISH_86024.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>33</td>\n",
       "      <td>0.942587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>INHS_FISH_55544.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040605</td>\n",
       "      <td>33</td>\n",
       "      <td>0.786328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>INHS_FISH_4172.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>33</td>\n",
       "      <td>0.540209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INHS_FISH_16124.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INHS_FISH_85582.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>0.099280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INHS_FISH_92608.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>0.104537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>INHS_FISH_25130.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>0.306219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>INHS_FISH_62393.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>0.070814</td>\n",
       "      <td>28</td>\n",
       "      <td>0.259031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file name true label  probability of true label predicted label  \\\n",
       "24  INHS_FISH_51790.jpg          0                   0.000484              33   \n",
       "67  INHS_FISH_41599.jpg          0                   0.004159              33   \n",
       "17  INHS_FISH_86024.jpg          0                   0.007538              33   \n",
       "83  INHS_FISH_55544.jpg          0                   0.040605              33   \n",
       "69   INHS_FISH_4172.jpg          0                   0.191964              33   \n",
       "..                  ...        ...                        ...             ...   \n",
       "8   INHS_FISH_16124.jpg         33                   0.002724               0   \n",
       "13  INHS_FISH_85582.jpg         33                   0.099280               0   \n",
       "6   INHS_FISH_92608.jpg         33                   0.104537               0   \n",
       "78  INHS_FISH_25130.jpg         33                   0.306219               0   \n",
       "50  INHS_FISH_62393.jpg         34                   0.070814              28   \n",
       "\n",
       "    probability of predicted label  \n",
       "24                        0.984169  \n",
       "67                        0.858448  \n",
       "17                        0.942587  \n",
       "83                        0.786328  \n",
       "69                        0.540209  \n",
       "..                             ...  \n",
       "8                         0.899437  \n",
       "13                        0.564271  \n",
       "6                         0.561070  \n",
       "78                        0.428838  \n",
       "50                        0.259031  \n",
       "\n",
       "[89 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'misclassified examples.csv'))\n",
    "plot_top_n(df_misclassified, \"misclassified examples\", numOfRows=numOfRows)\n",
    "df_misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/elhamod/HGNN/experiments/biology_paper_augmentation_effect/datasplits/b4896471167c5599680115e51349929def797e403bead8f0fe554d79/trainingIndex.csv read\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403dd0e477334d3b83d40548a303e86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='figure', max=190.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name</th>\n",
       "      <th>true label</th>\n",
       "      <th>probability of true label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>INHS_FISH_41181.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>INHS_FISH_25715.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>INHS_FISH_84473.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>INHS_FISH_9758.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>INHS_FISH_25694.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>INHS_FISH_65534.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>0.984275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>INHS_FISH_81262.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>0.986948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INHS_FISH_37323.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>0.986988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>INHS_FISH_40590.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>0.988063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>INHS_FISH_93023.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>0.988111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file name true label  probability of true label\n",
       "1067  INHS_FISH_41181.jpg          0                   0.389659\n",
       "565   INHS_FISH_25715.jpg          0                   0.565110\n",
       "432   INHS_FISH_84473.jpg          0                   0.578712\n",
       "633    INHS_FISH_9758.jpg          0                   0.634390\n",
       "797   INHS_FISH_25694.jpg          0                   0.846018\n",
       "...                   ...        ...                        ...\n",
       "760   INHS_FISH_65534.jpg         37                   0.984275\n",
       "803   INHS_FISH_81262.jpg         37                   0.986948\n",
       "25    INHS_FISH_37323.jpg         37                   0.986988\n",
       "84    INHS_FISH_40590.jpg         37                   0.988063\n",
       "476   INHS_FISH_93023.jpg         37                   0.988111\n",
       "\n",
       "[1216 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correctlyclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'correctly classified examples.csv'))\n",
    "plot_top_n(df_correctlyclassified, \"correctly classified\", numOfRows=numOfRows, show_same_class=False)\n",
    "df_correctlyclassified[df_correctlyclassified_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
