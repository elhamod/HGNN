{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from PIL import Image, ImageDraw \n",
    "import math\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser, getExperimentParamsAndRecord\n",
    "from HGNN.train import CNN, dataLoader\n",
    "\n",
    "testIndicesFile = \"testIndex.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data/\"\n",
    "experimentName=\"biology_paper_augmentation_effect\"\n",
    "trial_hash=\"38dd66a2911c31fcd5a766dc40b98cd1ec49c83db380f2827cdafd42\"\n",
    "\n",
    "cuda=7\n",
    "\n",
    "numOfRows=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda)\n",
    "    print(\"using cuda\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "experiment_params, experimentRecord = getExperimentParamsAndRecord(experimentsPath, experimentName, trial_hash)\n",
    "print(experiment_params)\n",
    "\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "datasetManager = dataLoader.datasetManager(experimentPathAndName, dataPath, True)\n",
    "datasetManager.updateParams(config_parser.fixPaths({**experiment_params,**{'augmented': False}}))\n",
    "train_dataset, _, test_dataset = datasetManager.getDataset()\n",
    "train_dataset.toggle_image_loading(augmentation=False, normalization=train_dataset.normalization_enabled) # Needed so we always get the same prediction accuracy \n",
    "fineList = train_dataset.csv_processor.getFineList()\n",
    "coarseList = train_dataset.csv_processor.getCoarseList()\n",
    "\n",
    "# get a test loader without randomization\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = {\n",
    "    \"fine\": len(fineList),\n",
    "    \"coarse\" : len(coarseList)\n",
    "}\n",
    "model = CNN.create_model(architecture, experiment_params)\n",
    "\n",
    "# get the model and the parameters\n",
    "modelName = experimentRecord.iloc[0][\"modelName\"]\n",
    "trialName = os.path.join(experimentPathAndName, modelName)\n",
    "_ = CNN.loadModel(model, trialName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort through predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_misclassified = pd.DataFrame(columns=['file name', 'true label', 'probability of true label', 'predicted label'])\n",
    "df_correctlyclassified_columns = ['file name', 'true label', 'probability of true label']\n",
    "df_correctlyclassified = pd.DataFrame(columns=df_correctlyclassified_columns)\n",
    "\n",
    "# get probability of correct prediction and true label\n",
    "predProblist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "_, predlist = torch.max(predProblist, 1)\n",
    "lbllist = lbllist.reshape(lbllist.shape[0], -1)\n",
    "# True label\n",
    "correct_predProblist = predProblist.gather(1, lbllist)\n",
    "correct_predProblist = correct_predProblist.reshape(1, -1)\n",
    "correct_predProblist = correct_predProblist[0]\n",
    "# Predicted label\n",
    "predicted_predProblist = predProblist.gather(1, predlist.unsqueeze(0).T)\n",
    "predicted_predProblist = predicted_predProblist.reshape(1, -1)\n",
    "predicted_predProblist = predicted_predProblist[0]\n",
    "\n",
    "for i, lbl in enumerate(lbllist):\n",
    "    prd = predlist[i]\n",
    "    correctProb = correct_predProblist[i]\n",
    "    prdProb = predicted_predProblist[i]\n",
    "    fileName = subset[i]['fileName']\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        lbl = lbl.cpu()\n",
    "        prd = prd.cpu()\n",
    "        prdProb = prdProb.cpu()\n",
    "        correctProb = correctProb.cpu()\n",
    "    \n",
    "    if(lbl != prd):\n",
    "        row = {'file name' : fileName ,\n",
    "           'true label' : int(lbl.numpy()), \n",
    "           'probability of true label': float(correctProb.numpy()),\n",
    "           'probability of predicted label': float(prdProb.numpy()),\n",
    "           'predicted label' : int(prd.numpy())}\n",
    "        df_misclassified = df_misclassified.append(row, ignore_index=True)\n",
    "    else:\n",
    "        row = {'file name' : fileName ,\n",
    "           'true label' : int(lbl.numpy()), \n",
    "           'probability of true label': float(correctProb.numpy())}\n",
    "        df_correctlyclassified = df_correctlyclassified.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_misclassified = df_misclassified.sort_values(by=[ 'true label', 'probability of true label'])\n",
    "df_correctlyclassified = df_correctlyclassified.sort_values(by=['true label', 'probability of true label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to plot top n of a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(dataPath, experiment_params['image_path'], 'images')\n",
    "\n",
    "# Given a data frame of specimen, prints a pdf of a grid of those examples with information about them\n",
    "# showPrediction: Should only used to show misclassifications\n",
    "# showClosestClassTrainingExample: Should only used to show misclassifications\n",
    "def plot_top_n(df, fig_file_name, numOfRows=None, perRow=5, show_same_class=True):\n",
    "    \n",
    "    # construct results data frame\n",
    "    h_list = ['image','image','image','image','image',\n",
    "              'closest example from training set','closest example from training set','closest example from training set',]\n",
    "    h2_list = ['file name','true label','probability of true label','predicted label','probability of predicted label',\n",
    "             'file name','true label','cosine similarity',]\n",
    "    if show_same_class:\n",
    "        h_list = h_list + ['closest same class example from training set','closest same class example from training set']\n",
    "        h2_list = h2_list + ['file name','cosine similarity']\n",
    "    df_result = pd.DataFrame(columns = [np.array(h_list), np.array(h2_list)]  )   \n",
    "    \n",
    "    # Disable augmentation\n",
    "    augmentation, normalization, _ = train_dataset.toggle_image_loading(augmentation=False, normalization=dataset.normalization_enabled)\n",
    "    \n",
    "    if numOfRows is None:\n",
    "        numOfRows = df['true label'].nunique()\n",
    "    topn = df.groupby('true label').head(perRow)\n",
    "    \n",
    "    rows_per_page = 10\n",
    "    number_of_pages = math.floor(numOfRows/rows_per_page)+1\n",
    "    with tqdm(total=perRow * numOfRows, desc=\"figure\") as bar:\n",
    "        with PdfPages(os.path.join(experimentPathAndName, modelName, fig_file_name+\".pdf\")) as pdf:\n",
    "            for k in range(number_of_pages):\n",
    "                fig, axes = plt.subplots(ncols=perRow, nrows=rows_per_page, figsize=(15, 4*rows_per_page), dpi= 300)\n",
    "\n",
    "                for i, row in enumerate(axes):\n",
    "                    if i >= numOfRows + k*rows_per_page:\n",
    "                        break\n",
    "                        \n",
    "                    topn_lbl = topn[topn['true label']==i+k*rows_per_page]\n",
    "                    for j, ax in enumerate(row):\n",
    "\n",
    "                        if len(topn_lbl.index) > j:\n",
    "\n",
    "                            entry = topn_lbl.iloc[j]\n",
    "                            fileName = entry['file name']\n",
    "                            trueLabel = entry['true label']\n",
    "                            correct_prob = entry['probability of true label']\n",
    "                            if show_same_class:\n",
    "                                prediction = entry['predicted label']\n",
    "                                predicted_prob = entry['probability of predicted label']\n",
    "                            \n",
    "                            img = Image.open(os.path.join(images_path,fileName))\n",
    "                            img.thumbnail((448,448), Image.ANTIALIAS)\n",
    "\n",
    "                            # get closest training image from dataset training set\n",
    "                            closest, cosine_score = get_closest_example(fileName, test_dataset, train_dataset, experiment_params, model)\n",
    "                            closest_fileName = closest['fileName']\n",
    "                            closest_species = fineList[closest['fine']]\n",
    "                            img2 = Image.open(os.path.join(images_path,closest_fileName))\n",
    "                            img2.thumbnail((448,448), Image.ANTIALIAS)\n",
    "                            draw = ImageDraw.Draw(img2)\n",
    "                            draw.text((0, 0),\"closest: \" + closest_species,(0,0,0))\n",
    "                            \n",
    "                            vis = np.concatenate((img, img2), axis=0)\n",
    "                            \n",
    "                            # get closest training image from dataset training set of same class\n",
    "                            if show_same_class:\n",
    "                                # get subset of trainign set that corresponds to the true label\n",
    "                                class_training_indices = [indx for indx in training_indices if train_dataset[indx]['fine'] == trueLabel]\n",
    "                                class_training_dataset = torch.utils.data.Subset(train_dataset, class_training_indices)\n",
    "\n",
    "                                closest_fromClass, cosine_score_fromClass = get_closest_example(fileName, test_dataset, class_training_dataset, experiment_params, model)\n",
    "                                closest_fromClass_fileName = closest_fromClass['fileName']\n",
    "                                closest_fromClass_species = fineList[closest_fromClass['fine']]\n",
    "                                img3 = Image.open(os.path.join(images_path,closest_fromClass_fileName))\n",
    "                                img3.thumbnail((448,448), Image.ANTIALIAS)\n",
    "                                draw2 = ImageDraw.Draw(img3)\n",
    "                                draw2.text((0, 0),\"closest same label\",(0,0,0))\n",
    "                                vis = np.concatenate((vis, img3), axis=0)\n",
    "                            \n",
    "                            ax.imshow(vis)\n",
    "                            txt = f\"{fileName} \\n {fineList[trueLabel]}\"\n",
    "                            if show_same_class:\n",
    "                                txt = txt + f\" \\n as {fineList[prediction]}\"\n",
    "                            ax.set_title(txt)\n",
    "                            \n",
    "                            # add to dataframe\n",
    "                            row = {\n",
    "                                ('image', 'file name'): fileName,\n",
    "                                ('image', 'true label'): fineList[trueLabel],\n",
    "                                ('image', 'probability of true label'): round(correct_prob, 3),\n",
    "                                ('closest example from training set', 'file name'): closest_fileName,\n",
    "                                ('closest example from training set', 'true label'): closest_species,\n",
    "                                ('closest example from training set', 'cosine similarity'): round(cosine_score, 3),\n",
    "                            }\n",
    "                            if show_same_class:\n",
    "                                row = {**row, **{\n",
    "                                   ('image', 'predicted label'): fineList[prediction],\n",
    "                                   ('image', 'probability of predicted label'): round(predicted_prob, 3),\n",
    "                                   ('closest same class example from training set', 'file name'): closest_fromClass_fileName,\n",
    "                                   ('closest same class example from training set', 'cosine similarity'): round(cosine_score_fromClass, 3),\n",
    "                               }}\n",
    "                            df_result = df_result.append(row, ignore_index=True)\n",
    "\n",
    "                        bar.update()\n",
    "\n",
    "                fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                pdf.savefig()\n",
    "                df_result.to_csv(os.path.join(experimentPathAndName, modelName, fig_file_name+\".csv\"))\n",
    "                plt.close()\n",
    "\n",
    "    # Reenable aggregation if needed.\n",
    "    train_dataset.toggle_image_loading(augmentation=augmentation, normalization=normalization)\n",
    "\n",
    "def get_closest_example(fileName, source_dataset, target_dataset, experiment_params, model):\n",
    "    top_1 = torch.topk(CNN.get_distance_from_example(target_dataset, source_dataset[fileName], model, experiment_params), 1)\n",
    "    closest = target_dataset[top_1.indices[0][0].item()]\n",
    "    cosine_score = top_1.values[0][0].item()\n",
    "    return closest, cosine_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save mispredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_misclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'misclassified examples.csv'))\n",
    "# plot_top_n(df_misclassified, \"misclassified\", numOfRows=numOfRows)\n",
    "# df_misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correctlyclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'correctly classified examples.csv'))\n",
    "plot_top_n(df_correctlyclassified, \"correctly classified\", numOfRows=numOfRows, show_same_class=False)\n",
    "df_correctlyclassified[df_correctlyclassified_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}