{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from myhelpers import config_plots, TrialStatistics\n",
    "from HGNN.train import CNN, dataLoader\n",
    "from HGNN.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "config_plots.global_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data\"\n",
    "experimentName=\"biology_paper_dataset_differentModels_layers\"\n",
    "\n",
    "generate_confusion_matrix = True\n",
    "\n",
    "cuda=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda)\n",
    "    print(\"using cuda\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "\n",
    "# instantiate trial stat object\n",
    "results_dir = os.path.join(experimentPathAndName, \"results\")\n",
    "ts = TrialStatistics.TrialStatistics(results_dir)\n",
    "ts_coarse = TrialStatistics.TrialStatistics(results_dir, \"coarse\")\n",
    "\n",
    "datasetManager = dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show and save trial statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for experiment_params in config_parser.getExperiments():\n",
    "        print(experiment_params)\n",
    "\n",
    "        # For analyzing experiments, we don't care about augmentation\n",
    "        datasetManager.updateParams(config_parser.fixPaths({**experiment_params,**{'augmented': False}}))\n",
    "        train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "        fineList = train_loader.dataset.csv_processor.getFineList()\n",
    "        coarseList = train_loader.dataset.csv_processor.getCoarseList()\n",
    "        ordered_fineList_indices = sorted(range(len(fineList)), key=lambda k: fineList[k])\n",
    "        ordered_coarseList_indices = sorted(range(len(coarseList)), key=lambda k: coarseList[k])\n",
    "        architecture = {\n",
    "            \"fine\": len(fineList),\n",
    "            \"coarse\" : len(coarseList)\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "        # Loop through n trials\n",
    "        for i in trange(experiment_params[\"numOfTrials\"], desc=\"trial\"):\n",
    "            modelName = getModelName(experiment_params, i)\n",
    "            trialName = os.path.join(experimentPathAndName, modelName)\n",
    "            \n",
    "            # Train/Load model\n",
    "            print(CNN.getModelFile(trialName))\n",
    "            model = CNN.create_model(architecture, experiment_params)\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                df, epochs, time_elapsed = CNN.loadModel(model, trialName)\n",
    "                \n",
    "                # Update trial outcomes for statistics\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params)\n",
    "                ts.addTrialPredictions(experiment_params, predlist, lbllist, ordered_fineList_indices)\n",
    "                micro_f1 = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "                predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "                topk = CNN.top_k_acc(predlist, lbllist, topk=(3,5))\n",
    "\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params, 'coarse')\n",
    "                ts_coarse.addTrialPredictions(experiment_params, predlist, lbllist, ordered_coarseList_indices)\n",
    "                micro_f1_coarse = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(validation_loader, model, experiment_params)\n",
    "                macro_f1_val = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "                score = {'loss': CNN.getCrossEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                         'average correct guess prob': CNN.getAvgProbCorrectGuessFromLoader(test_loader, model, experiment_params),\n",
    "                         'macro f1 test fine': micro_f1,\n",
    "                         'macro f1 test coarse': micro_f1_coarse,\n",
    "                         'macro f1 validation fine': macro_f1_val,\n",
    "                         'time': time_elapsed,\n",
    "                         'epochs': epochs,\n",
    "                         'top-3': topk[0].cpu().numpy(),\n",
    "                         'top-5': topk[1].cpu().numpy(),\n",
    "                        }\n",
    "\n",
    "                ts.addTrial(experiment_params,\n",
    "                    score, i)\n",
    "            else:\n",
    "                print(\"Model {0} not found!\".format(trialName))\n",
    "        \n",
    "        bar.update()\n",
    "        \n",
    "# Save experiment results\n",
    "ts.saveStatistics()\n",
    "ts.saveStatistics(False)\n",
    "ts.showStatistics()\n",
    "ts.showStatistics(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show and save confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if generate_confusion_matrix:\n",
    "    with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "        for experiment_params in config_parser.getExperiments():\n",
    "            print(experiment_params)\n",
    "\n",
    "            ts.printTrialConfusionMatrix(experiment_params, ordered_fineList , printOutput=True)\n",
    "            ts_coarse.printTrialConfusionMatrix(experiment_params,  ordered_coarseList, printOutput=True)\n",
    "\n",
    "            bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.trialScatter('macro f1 validation fine', 'macro f1 test fine', 'link_layer', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts.trialScatter('macro f1 test fine', 'time', 'learning_rate', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts.df = ts.df.rename(columns={\"link_layer\": \"linkLayer\"})\n",
    "# ts.df.boxplot(column=['time'], by=['linkLayer'], figsize=(16, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}