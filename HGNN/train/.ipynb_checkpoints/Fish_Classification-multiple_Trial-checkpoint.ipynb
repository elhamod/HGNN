{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import CNN\n",
    "\n",
    "# from config_plots import global_settings\n",
    "# global_settings()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining global variables\n",
    "experimentName = \"50_11_hier_species_twice_phase7\"\n",
    "showListOfSpecies = False\n",
    "\n",
    "from configParser import ConfigParser, getModelName\n",
    "config_parser = ConfigParser(experimentName)\n",
    "\n",
    "import os\n",
    "experimentName = os.path.join(experimentName, \"multi-trial\")\n",
    "import TrialStatistics\n",
    "ts = TrialStatistics.TrialStatistics(experimentName)\n",
    "ts_genus = TrialStatistics.TrialStatistics(experimentName, \"genus\")\n",
    "\n",
    "import dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0) # 0\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(\"We are using cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 1) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment  1 / 1 :  {'image_path': '/data/BGNN_data/INHS_cropped', 'suffix': '50_11', 'training_count': 0.64, 'validation_count': 0.16, 'batchSize': 2650, 'n_epochs': 10000, 'learning_rate': 0.001, 'numOfTrials': 3, 'patience': 200, 'useHeirarchy': True, 'downsample': True, 'downsampleOutput': 0, 'takeFromIntermediate': True, 'takeFromIntermediateOutput': 200, 'lambda': -1, 'unsupervisedOnTest': False, 'fc_layers': 1, 'resnet': '18', 'normalizeFromResnet': True, 'dummy': 0}\n",
      "Creating dataset...\n",
      "Loading dataset...\n",
      "Going through image files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (550 of 550) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (3 of 550) |                        | Elapsed Time: 0:00:00 ETA:   0:00:24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved indices...\n",
      "file /data/BGNN_data/INHS_cropped/50_11/50_11_hier_species_twice_phase7/multi-trial/tc0.640000_vc0.160000/trainingIndex.pkl read\n",
      "trainingIndex.pkl 352\n",
      "file /data/BGNN_data/INHS_cropped/50_11/50_11_hier_species_twice_phase7/multi-trial/tc0.640000_vc0.160000/valIndex.pkl read\n",
      "valIndex.pkl 88\n",
      "file /data/BGNN_data/INHS_cropped/50_11/50_11_hier_species_twice_phase7/multi-trial/tc0.640000_vc0.160000/testIndex.pkl read\n",
      "testIndex.pkl 110\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "Training started...\n",
      "Transfrom images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (550 of 550) |######################| Elapsed Time: 0:00:42 Time:  0:00:42\n",
      "  0% (30 of 10000) |                     | Elapsed Time: 0:01:58 ETA:   5:09:02"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from confusion_matrix_plotter import plot_confusion_matrix2, generate_classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import progressbar\n",
    "\n",
    "paramsIterator = config_parser.getHyperpIter()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)\n",
    "paramsIterator = config_parser.getHyperpIter()  \n",
    "experiment_index = 0\n",
    "\n",
    "datasetManager = dataLoader.datasetManager(experimentName, showListOfSpecies)\n",
    "with progressbar.ProgressBar(max_value=number_of_experiments) as bar:\n",
    "    for experiment_params in paramsIterator:\n",
    "        bar.update(experiment_index)\n",
    "        experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "\n",
    "        print(\"experiment \", experiment_index+1, \"/\", number_of_experiments, \": \", experiment_params)\n",
    "\n",
    "        # load images\n",
    "        datasetManager.updateParams(experiment_params)\n",
    "        dataset = datasetManager.getDataset()\n",
    "        speciesList = dataset.getSpeciesList()\n",
    "        numberOfSpecies = len(speciesList)\n",
    "        numberOfGenus = len(dataset.getGenusList())\n",
    "\n",
    "        confusionMatricesPerTrial = []\n",
    "\n",
    "        for i in range(experiment_params[\"numOfTrials\"]):\n",
    "            trialName = os.path.join(experimentName, getModelName(experiment_params, i))\n",
    "\n",
    "            # Train/Load model\n",
    "            architecture = {\n",
    "                \"species\": numberOfSpecies,\n",
    "                \"genus\" : numberOfGenus\n",
    "            }\n",
    "            model = CNN.create_model(architecture, experiment_params)\n",
    "            train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                df, epochs, time_elapsed = CNN.loadModel(model, trialName)\n",
    "                print(\"Model {0} loaded!\".format(trialName))\n",
    "            else:\n",
    "                df, epochs, time_elapsed = CNN.trainModel(train_loader, validation_loader, experiment_params, model, trialName, test_loader)\n",
    "            \n",
    "            # Update trial outcomes for statistics\n",
    "            predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params)\n",
    "            ts.addTrialPredictions(experiment_params, predlist, lbllist, numberOfSpecies)\n",
    "            micro_f1 = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "            \n",
    "            predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "            topk = CNN.top_k_acc(predlist, lbllist, topk=(3,5))\n",
    "            \n",
    "            predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params, 'genus')\n",
    "            ts_genus.addTrialPredictions(experiment_params, predlist, lbllist, numberOfGenus)\n",
    "            micro_f1_genus = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "            predlist, lbllist = CNN.getLoaderPredictions(validation_loader, model, experiment_params)\n",
    "            macro_f1_val = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "            \n",
    "            ts.addTrial(experiment_params,\n",
    "                    {'loss': CNN.getCrossEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                     'average best guess prob': CNN.getAvgProbBestGuessFromLoader(test_loader, model, experiment_params),\n",
    "                     'average correct guess prob': CNN.getAvgProbCorrectGuessFromLoader(test_loader, model, experiment_params),\n",
    "                     'entropy': CNN.getAvgEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                     'accuracy': CNN.getAccuracyFromLoader(test_loader, model, experiment_params),\n",
    "                     'macro_f1_species': micro_f1,\n",
    "                     'macro_f1_genus': micro_f1_genus,\n",
    "                     'time': time_elapsed,\n",
    "                     'epochs': epochs,\n",
    "                     'macro f1 validation': macro_f1_val,\n",
    "                     'top-3': topk[0].cpu().numpy(),\n",
    "                     'top-5': topk[1].cpu().numpy(),\n",
    "                    }, i)\n",
    "        \n",
    "        experiment_index = experiment_index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics()\n",
    "ts.saveStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics(False)\n",
    "ts.saveStatistics(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsIterator = config_parser.getHyperpIter() \n",
    "for experiment_params in paramsIterator:\n",
    "    experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "    \n",
    "    print(\"experiment: \", experiment_params)\n",
    "    \n",
    "    datasetManager.updateParams(experiment_params)\n",
    "    dataset = datasetManager.getDataset()\n",
    "    speciesList = dataset.getSpeciesList()\n",
    "    ts.printTrialConfusionMatrix(experiment_params, speciesList, True)\n",
    "    ts.printF1table(experiment_params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsIterator = config_parser.getHyperpIter() \n",
    "for experiment_params in paramsIterator:\n",
    "    experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "    if experiment_params[\"useHeirarchy\"]:\n",
    "        print(\"experiment: \", experiment_params)\n",
    "\n",
    "        datasetManager.updateParams(experiment_params)\n",
    "        dataset = datasetManager.getDataset()\n",
    "    \n",
    "        genusList = dataset.getGenusList()\n",
    "        ts_genus.printTrialConfusionMatrix(experiment_params, genusList, True)\n",
    "        ts_genus.printF1table(experiment_params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.trialScatter('accuracy', 'time', False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
