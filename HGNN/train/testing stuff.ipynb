{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only way to do it is to launch jupyter this way:\n",
    "\n",
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Loading dataset...\n",
      "/raid/elhamod/cifar-100-python/\n",
      "Files already downloaded and verified\n",
      "CIFAR normalization\n",
      "Loading dataset...\n",
      "/raid/elhamod/cifar-100-python/\n",
      "Files already downloaded and verified\n",
      "CIFAR normalization\n",
      "Creating dataset... Done.\n",
      "Loading saved indices...\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "layer4 not found\n",
      "0.7520963670629908\n",
      "0.7514\n",
      "0.7514\n",
      "layer4 not found\n",
      "0.7520963670629908\n",
      "0.7514\n",
      "0.7514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-95414c7d88b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_fine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mpredlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbllist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLoaderPredictionProbabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mpredlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbllist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbllist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/HGNN/code/HGNN/HGNN/train/CNN.py\u001b[0m in \u001b[0;36mgetLoaderPredictionProbabilities\u001b[0;34m(loader, model, params, label, device)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/myhelpers/myhelpers/cifar_dataLoader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposedTransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;31m# if torch.cuda.is_available():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m#     image = image.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# get encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder %s not available\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experimentsPath = \"/raid/elhamod/CIFAR_HGNN/experiments/\" #\"/raid/elhamod/Fish/experiments/\"\n",
    "dataPath = \"/raid/elhamod/\" #\"/raid/elhamod/Fish/\"\n",
    "experimentName = \"CIFAR_phylogeny_tripletloss_new_archi_full\"\n",
    "i=0\n",
    "device = 0\n",
    "experiment_params = {\"image_path\": \"cifar-100-python\", \"suffix\": None, \"img_res\": 32, \"augmented\": True, \"batchSize\": 64, \"learning_rate\": 0.01, \"numOfTrials\": 2, \"fc_layers\": 1, \"pretrained\": True, \"epochs\": 30, \"patience\": 12, \"optimizer\": \"adabelief\", \"scheduler\": \"cosine\", \"weightdecay\": 0.0005, \"modelType\": \"BB\", \"lambda\": 10, \"tl_model\": \"preResNet\", \"link_layer\": \"avgpool\", \"adaptive_smoothing\": True, \"adaptive_lambda\": 0.1, \"adaptive_alpha\": 0.1, \"tripletEnabled\": True, \"tripletSamples\": 3, \"tripletSelector\": \"semihard\", \"tripletMargin\": 0.3, \"phylogeny_loss\": False, \"displayName\": \"CIFARpretrained4-Triplet-Cos\", \"noSpeciesBackprop\": False, \"phylogeny_loss_epsilon\": 0.03}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# experiment_params = {\"image_path\": \"cifar-100-python\", \"suffix\": None, \"img_res\": 32, \"augmented\": True, \"batchSize\": 64, \"learning_rate\": 0.001, \"numOfTrials\": 1, \"fc_layers\": 1, \"pretrained\": True, \"epochs\": 30, \"patience\": 12, \"optimizer\": \"adabelief\", \"scheduler\": \"plateau\", \"weightdecay\": 0.0005, \"modelType\": \"BB\", \"lambda\": 10, \"tl_model\": \"preResNet\", \"link_layer\": \"avgpool\", \"adaptive_smoothing\": True, \"adaptive_lambda\": 0.1, \"adaptive_alpha\": 0.1, \"tripletEnabled\": False, \"tripletSamples\": 3, \"tripletSelector\": \"semihard\", \"tripletMargin\": 0.2, \"phylogeny_loss\": False, \"displayName\": \"CIFARpretrained4-BB\", \"noSpeciesBackprop\": False, \"phylogeny_loss_epsilon\": 0.03}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from myhelpers import cifar_dataLoader\n",
    "from HGNN.train import CNN\n",
    "from HGNN.train.configParser import getModelName\n",
    "from configParser import ConfigParser, getModelName\n",
    "import os\n",
    "import torch\n",
    "from myhelpers.resnet_cifar2 import cifar100\n",
    "import numpy as np\n",
    "from myhelpers.preresnet_cifar import resnet as preresnet_cifar\n",
    "import random\n",
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# seed_everything(121)\n",
    "\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "experiment_params = config_parser.fixExperimentParams(experiment_params)\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "datasetManager = cifar_dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "\n",
    "train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "architecture = {\n",
    "    \"fine\": len(train_loader.dataset.csv_processor.getFineList()),\n",
    "    \"coarse\" : len(train_loader.dataset.csv_processor.getCoarseList())\n",
    "}\n",
    "\n",
    "# from myhelpers.resnet_cifar import cifar_resnet56\n",
    "\n",
    "# # modelName = getModelName(experiment_params, i)\n",
    "# print(modelName)\n",
    "# modelName = \"models/b07640aa2d0c1aacb31f7bcda75ac772ad8bf53db3dacc06d2280a98\"\n",
    "# trialName = os.path.join(experimentPathAndName, modelName)\n",
    "# # initModelPath = CNN.getInitModelFile(experimentPathAndName)\n",
    "# finalModelPath = CNN.getModelFile(trialName)\n",
    "# model.load_state_dict(torch.load(finalModelPath))\n",
    "\n",
    "# model = cifar_resnet56(pretrained='cifar100')\n",
    "model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "# model = cifar100(128, pretrained=True)\n",
    "# model = preresnet_cifar(dataset='cifar100', inpt_size=32, pretrained=True)\n",
    "# CNN.trainModel(train_loader, validation_loader, experiment_params, model, \"hello\", test_loader, device=device)\n",
    "# print(model)\n",
    "\n",
    "predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params, device=device)\n",
    "predlist, lbllist = CNN.getPredictions(predlist, lbllist)\n",
    "if device is not None:\n",
    "    predlist = predlist.cpu()\n",
    "    lbllist = lbllist.cpu()   \n",
    "print(f1_score(lbllist, predlist, average='macro'))\n",
    "print(f1_score(lbllist, predlist, average='micro'))\n",
    "print(accuracy_score(lbllist, predlist))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     rand_input = torch.rand(2, 3, model.network_fine.img_res, model.network_fine.img_res)\n",
    "#     if model.network_fine.device is not None:\n",
    "#         rand_input = rand_input.cuda()\n",
    "#     out_ = model.network_fine(rand_input)\n",
    "\n",
    "model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "\n",
    "predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params, device=device)\n",
    "predlist, lbllist = CNN.getPredictions(predlist, lbllist)\n",
    "if device is not None:\n",
    "    predlist = predlist.cpu()\n",
    "    lbllist = lbllist.cpu()   \n",
    "print(f1_score(lbllist, predlist, average='macro'))\n",
    "print(f1_score(lbllist, predlist, average='micro'))\n",
    "print(accuracy_score(lbllist, predlist))\n",
    "\n",
    "\n",
    "model = model.network_fine\n",
    "\n",
    "predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params, device=device)\n",
    "predlist, lbllist = CNN.getPredictions(predlist, lbllist)\n",
    "if device is not None:\n",
    "    predlist = predlist.cpu()\n",
    "    lbllist = lbllist.cpu()   \n",
    "print(f1_score(lbllist, predlist, average='macro'))\n",
    "print(f1_score(lbllist, predlist, average='micro'))\n",
    "print(accuracy_score(lbllist, predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbbee1b0da0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = next(iter(train_loader))\n",
    "plt.imshow(np.transpose(images['image'][0].cpu().detach().numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05]\n",
      "[8.681980515339464e-06]\n",
      "[5.5e-06]\n",
      "[2.3180194846605362e-06]\n",
      "[1.0000000000000002e-06]\n",
      "[2.3180194846605362e-06]\n",
      "[5.5000000000000016e-06]\n",
      "[8.681980515339468e-06]\n",
      "[1.0000000000000004e-05]\n",
      "[8.681980515339468e-06]\n",
      "[5.500000000000003e-06]\n",
      "[2.3180194846605405e-06]\n",
      "[1.0000000000000002e-06]\n",
      "[2.3180194846605362e-06]\n",
      "[5.499999999999991e-06]\n",
      "[8.681980515339447e-06]\n",
      "[9.999999999999986e-06]\n",
      "[8.68198051533945e-06]\n",
      "[5.499999999999995e-06]\n",
      "[2.3180194846605388e-06]\n",
      "[1.0000000000000002e-06]\n",
      "[2.3180194846605362e-06]\n",
      "[5.499999999999986e-06]\n",
      "[8.681980515339454e-06]\n",
      "[9.999999999999994e-06]\n",
      "[8.68198051533946e-06]\n",
      "[5.499999999999993e-06]\n",
      "[2.3180194846605405e-06]\n",
      "[1.0000000000000002e-06]\n",
      "[2.3180194846605362e-06]\n",
      "[5.499999999999988e-06]\n",
      "[8.681980515339456e-06]\n",
      "[9.999999999999997e-06]\n",
      "[8.681980515339461e-06]\n",
      "[5.499999999999995e-06]\n",
      "[2.318019484660542e-06]\n",
      "[1.0000000000000002e-06]\n",
      "[2.3180194846605362e-06]\n",
      "[5.49999999999999e-06]\n",
      "[8.681980515339461e-06]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "learning_rate = 0.00001\n",
    "scheduler_gamma = 0.1\n",
    "scheduler_patience = 4\n",
    "epochs = 40\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_patience, eta_min=learning_rate*scheduler_gamma)\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(scheduler.get_last_lr())\n",
    "    scheduler.step() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fine': 0.5, 'layer2': 0.25, 'layer4': 0.25}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "adaptive_alpha=0.5\n",
    "adaptive_lambda=0.1\n",
    "fine_loss=[torch.tensor(25)]\n",
    "other_losses ={\n",
    "    'layer2': torch.tensor(2),\n",
    "    'layer4': torch.tensor(2)\n",
    "}\n",
    "\n",
    "from myhelpers.adaptive_smoothing import get_lambdas\n",
    "\n",
    "for fine_loss_ in fine_loss:\n",
    "    print(get_lambdas(adaptive_alpha, adaptive_lambda, fine_loss_, other_losses =other_losses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet18()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model on cpu!\n",
      "Warning! model is on cpu\n",
      "CNN_One_Net_Triplet_Wrapper(\n",
      "  (network_fine): CNN_One_Net(\n",
      "    (pretrained): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Sequential(\n",
      "        (linear0): Linear(in_features=512, out_features=50, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (intermediate_outputs): ModuleDict(\n",
      "    (layer1): Sequential(\n",
      "      (flatten__layer1): Flatten()\n",
      "      (linear__layer1): Linear(in_features=4096, out_features=50, bias=True)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (flatten__layer2): Flatten()\n",
      "      (linear__layer2): Linear(in_features=2048, out_features=50, bias=True)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (flatten__layer3): Flatten()\n",
      "      (linear__layer3): Linear(in_features=1024, out_features=50, bias=True)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (flatten__layer4): Flatten()\n",
      "      (linear__layer4): Linear(in_features=512, out_features=50, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from HGNN.train import CNN\n",
    "\n",
    "experiment_params = {\"image_path\": \"cifar-100-python\", \n",
    "                     \"suffix\": None, \n",
    "                     \"img_res\": 32,\n",
    "                     \"augmented\": True, \n",
    "                     \"batchSize\": 64,\n",
    "                     \"learning_rate\": 0.01,\n",
    "                     \"numOfTrials\": 2,\n",
    "                     \"fc_layers\": 1, \"pretrained\": True, \"epochs\": 30, \"patience\": 12,\n",
    "                     \"optimizer\": \"adabelief\", \"scheduler\": \"cosine\", \"weightdecay\": 0.0005,\n",
    "                     \"modelType\": \"BB\", \"lambda\": 10, \"tl_model\": \"ResNet18\", \"link_layer\": \"avgpool\", \"adaptive_smoothing\": True, \"adaptive_lambda\": 0.1, \"adaptive_alpha\": 0.1, \"tripletEnabled\": True, \"tripletSamples\": 3, \"tripletSelector\": \"semihard\", \"tripletMargin\": 0.3, \"phylogeny_loss\": False, \"displayName\": \"CIFARpretrained4-Triplet-Cos\", \"noSpeciesBackprop\": False, \"phylogeny_loss_epsilon\": 0.03}\n",
    "\n",
    "architecture = {\n",
    "    \"fine\": 50,\n",
    "    \"coarse\" : None\n",
    "}\n",
    "\n",
    "\n",
    "model = CNN.create_model(architecture, experiment_params)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000, 0.6000, 0.0000],\n",
       "        [0.4558, 0.5698, 0.6838]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embeddings = torch.tensor([[4., 3., 0.],[4., 5., 6.]])\n",
    "F.normalize(embeddings, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.tensor([[4.],[4.]])\n",
    "(embeddings-4).eq(torch.zeros_like(embeddings)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
