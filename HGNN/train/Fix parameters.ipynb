{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "from myhelpers import TrialStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data\"\n",
    "experimentName=\"biology_paper_datasizes_BB\"\n",
    "\n",
    "cuda=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file and changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_params_file = os.path.join(experimentsPath, experimentName, \"params.json\")\n",
    "\n",
    "# Keep same order as ConfigParserWriter!\n",
    "changes = {\n",
    "    'numOfTrials': 3\n",
    "}\n",
    "removes = ['patience','aug_profile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)\n",
    "\n",
    "# populate a hash table of all experiments, indexed by trial hash\n",
    "experiments = {}\n",
    "for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "    num_of_models = experiment_params[\"numOfTrials\"]\n",
    "    for k in range(num_of_models):\n",
    "        old_trialHash = TrialStatistics.getTrialName(experiment_params, k)\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        new_trialHash = TrialStatistics.getTrialName(experiment_params_new, k)\n",
    "        experiments[old_trialHash] = {\"trialHash\": new_trialHash}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9488c291ce494fb48eadf99d878127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c248b3330ed4416bb1cfc986f4cdf80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model /home/elhamod/HGNN/experiments/biology_paper_datasizes_BB/models/4c578e69396e5fdf84b6f8c67ac4e2055811f695d840d2a40ca81f32 -> /home/elhamod/HGNN/experiments/biology_paper_datasizes_BB/models/4c578e69396e5fdf84b6f8c67ac4e2055811f695d840d2a40ca81f32 updated\n",
      "json /home/elhamod/HGNN/experiments/biology_paper_datasizes_BB/models/4c578e69396e5fdf84b6f8c67ac4e2055811f695d840d2a40ca81f32/params.json updated\n",
      "model models/831dc79ea7b6e034cacead51aed9d63696e796b862bbf29150dc6e0e could not be fixed to models/831dc79ea7b6e034cacead51aed9d63696e796b862bbf29150dc6e0e\n",
      "model models/4a786f7dda776afeaa7daeeb82f1330f6962446ac3320b37f2c33c67 could not be fixed to models/4a786f7dda776afeaa7daeeb82f1330f6962446ac3320b37f2c33c67\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c14a707920444e871381568e852656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model models/dcfabf5ce714de42b5bbaeb41b1e0e3730b7e9d950df15420e0548ae could not be fixed to models/dcfabf5ce714de42b5bbaeb41b1e0e3730b7e9d950df15420e0548ae\n",
      "model models/32879544d09cfb1f7c6b6a8b9cb03b1a8b86a69718b6d152f65341e7 could not be fixed to models/32879544d09cfb1f7c6b6a8b9cb03b1a8b86a69718b6d152f65341e7\n",
      "model models/814c55ad45d1fb2926f3263807b4412e644ef2c5cb6ee8e41425107e could not be fixed to models/814c55ad45d1fb2926f3263807b4412e644ef2c5cb6ee8e41425107e\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34ee31401054f48934075bc152f4e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model models/25610f5d2832d5369b1c1e631160b92950da7cdbddce764e2c60e3ef could not be fixed to models/25610f5d2832d5369b1c1e631160b92950da7cdbddce764e2c60e3ef\n",
      "model models/663b0cb31f1785c4e2662da64a5897201cb8d67801369078f636f255 could not be fixed to models/663b0cb31f1785c4e2662da64a5897201cb8d67801369078f636f255\n",
      "model models/67829df4f9f07949903575bad092abd529fec317b1d4ec9611023eb8 could not be fixed to models/67829df4f9f07949903575bad092abd529fec317b1d4ec9611023eb8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "\n",
    "        num_of_models = experiment_params[\"numOfTrials\"]\n",
    "        with tqdm(total=num_of_models, desc=\"trial\") as bar2:\n",
    "            for k in range(num_of_models):\n",
    "            \n",
    "                # Fix model names\n",
    "                old_model_name = getModelName(experiment_params, k)\n",
    "                old_modelPath = os.path.join(experimentsPath, experimentName, old_model_name)\n",
    "                new_model_name = getModelName(experiment_params_new, k)\n",
    "                new_modelPath = os.path.join(experimentsPath, experimentName, new_model_name)\n",
    "\n",
    "                try:\n",
    "                    if os.path.exists(old_modelPath):\n",
    "                        os.rename(old_modelPath, new_modelPath)\n",
    "                        print(\"model\", old_modelPath, '->', new_modelPath, \"updated\")\n",
    "\n",
    "                        j = json.dumps(experiment_params_new)\n",
    "                        json_fileName = os.path.join(new_modelPath, 'params.json')\n",
    "                        f = open(json_fileName,\"w\")        \n",
    "                        f.write(j)\n",
    "                        f.close()  \n",
    "                        print(\"json\", json_fileName, \"updated\")\n",
    "                    else:\n",
    "                        raise\n",
    "                    \n",
    "                except:\n",
    "                    print(\"model\", old_model_name, \"could not be fixed to\", new_model_name)\n",
    "                    pass  \n",
    "                \n",
    "                \n",
    "\n",
    "                bar2.update()\n",
    "                \n",
    "                experiments[TrialStatistics.getTrialName(experiment_params, k)]['modelName'] = new_model_name\n",
    "\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d638a4b99f4feabc59f9d95e362e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 5e22b0570f3e427d8c05ea1c55d284c0309188738361f92e99ced27a could not be fixed to 5e22b0570f3e427d8c05ea1c55d284c0309188738361f92e99ced27a\n",
      "result f7ac08342108aa0218195ccec8495f64ff54d6b12a08db45c12028bd could not be fixed to f7ac08342108aa0218195ccec8495f64ff54d6b12a08db45c12028bd\n",
      "result e278ad9ff3a35ee8f8879b1e050ab79a62473e7213bf4a2474b83bee could not be fixed to e278ad9ff3a35ee8f8879b1e050ab79a62473e7213bf4a2474b83bee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "\n",
    "        old_experimentHash = TrialStatistics.getTrialName(experiment_params)\n",
    "        old_experimentPath = os.path.join(experimentsPath, experimentName, \"results\", old_experimentHash)\n",
    "        new_experimentHash = TrialStatistics.getTrialName(experiment_params_new)\n",
    "        new_experimentPath = os.path.join(experimentsPath, experimentName, \"results\", new_experimentHash)\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(old_experimentPath):\n",
    "\n",
    "                os.rename(old_experimentPath, new_experimentPath)\n",
    "                print(\"result\", old_experimentPath, '->', new_experimentPath, \"updated\")\n",
    "\n",
    "                j = json.dumps(experiment_params_new)\n",
    "                json_fileName = os.path.join(new_experimentPath, 'params.json')\n",
    "                f = open(json_fileName,\"w\")        \n",
    "                f.write(j)\n",
    "                f.close()  \n",
    "                print(\"json\", json_fileName, \"updated\")\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        except:\n",
    "            print(\"result\", old_experimentHash, \"could not be fixed to\",new_experimentHash)\n",
    "            pass \n",
    "        \n",
    "        experiments[TrialStatistics.getTrialName(experiment_params, 0)]['experimentHash'] = new_experimentHash\n",
    "        \n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0443a81f3a2049ab8f1f8452b86b5a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64d666a69da431490d0f3d15feff8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522d19f448804d39853cb2d820fa038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eee61c4f0e04b3f867cb08100ee7628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open experiments.csv file\n",
    "experimentsFileNameAndPath=os.path.join(experimentsPath, \"experiments.csv\")\n",
    "experiments_file= pd.read_csv(experimentsFileNameAndPath)\n",
    "\n",
    "# For all experiments\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        numOfTrials = experiment_params[\"numOfTrials\"]\n",
    "        trialHash_0 = TrialStatistics.getTrialName(experiment_params, 0) # used for keys who don't change for different trials\n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        \n",
    "        # For all trials\n",
    "        with tqdm(total=num_of_models, desc=\"trial\") as bar2:\n",
    "            for j in range(numOfTrials):\n",
    "                \n",
    "                trialHash = TrialStatistics.getTrialName(experiment_params, j)\n",
    "                try:\n",
    "                    # If old entry doesn't exist, nothing to update\n",
    "                    record_exists = not (experiments_file[experiments_file['trialHash'] == trialHash][experiments_file['experimentName'] == experimentName]).empty\n",
    "                    if record_exists:\n",
    "                        \n",
    "                        # drop old row and caluclate new row\n",
    "                        new_trialHash = experiments[trialHash][\"trialHash\"]\n",
    "                        experiments_file.drop(experiments_file[experiments_file['trialHash'] == trialHash][experiments_file['experimentName'] == experimentName].index, inplace = True) \n",
    "                        row_information = {\n",
    "                            'experimentName': experimentName,\n",
    "                            'modelName': experiments[trialHash][\"modelName\"],\n",
    "                            'datasetName': experiments[trialHash_0][\"datasetName\"],\n",
    "                            'experimentHash': experiments[trialHash_0][\"experimentHash\"],\n",
    "                            'trialHash': new_trialHash\n",
    "                        }\n",
    "                        row_information = {**row_information, **experiment_params_new} \n",
    "\n",
    "                        # error handling to avoid duplicates\n",
    "                        record_exists = not (experiments_file[experiments_file['trialHash'] == new_trialHash][experiments_file['experimentName'] == experimentName]).empty\n",
    "                        if record_exists:\n",
    "                            experiments_file.drop(experiments_file[experiments_file['trialHash'] == new_trialHash][experiments_file['experimentName'] == experimentName].index, inplace = True) \n",
    "\n",
    "                        # update with new entry    \n",
    "                        experiments_file = experiments_file.append(pd.DataFrame(row_information, index=[0]), ignore_index = True)\n",
    "                        print(\"trialHash\", trialHash, \"->\", new_trialHash, \"updated\")\n",
    "                except:\n",
    "                    print(\"trialHash\", trialHash, \"could not be updated!\")\n",
    "                    pass\n",
    "                bar2.update()\n",
    "        bar.update()\n",
    "\n",
    "# resave file\n",
    "experiments_file.to_csv(experimentsFileNameAndPath, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix params file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590fd788ac0647829aa6cb5fb4cab88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'INHS_cropped', 'suffix': 'biology_paper_cleaned_200max', 'img_res': 448, 'augmented': True, 'batchSize': 64, 'learning_rate': 5e-05, 'numOfTrials': 3, 'fc_layers': 1, 'modelType': 'BB', 'lambda': 0.6, 'unsupervisedOnTest': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool'}\n",
      "{'image_path': 'INHS_cropped', 'suffix': 'biology_paper_cleaned_100max', 'img_res': 448, 'augmented': True, 'batchSize': 64, 'learning_rate': 5e-05, 'numOfTrials': 3, 'fc_layers': 1, 'modelType': 'BB', 'lambda': 0.6, 'unsupervisedOnTest': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool'}\n",
      "{'image_path': 'INHS_cropped', 'suffix': 'biology_paper_cleaned_50max', 'img_res': 448, 'augmented': True, 'batchSize': 64, 'learning_rate': 5e-05, 'numOfTrials': 3, 'fc_layers': 1, 'modelType': 'BB', 'lambda': 0.6, 'unsupervisedOnTest': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool'}\n",
      "\n",
      "json /home/elhamod/HGNN/experiments/biology_paper_datasizes_BB/params.json updated\n"
     ]
    }
   ],
   "source": [
    "experiment_list = []\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        print(experiment_params_new)\n",
    "        experiment_list.append(experiment_params_new)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "j = json.dumps({\"experimentList\": experiment_list})\n",
    "f = open(old_params_file,\"w\")        \n",
    "f.write(j)\n",
    "f.close()  \n",
    "print(\"json\", old_params_file, \"updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
