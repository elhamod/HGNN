{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "from myhelpers import TrialStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data\"\n",
    "experimentName=\"learningRateDecay\"\n",
    "\n",
    "cuda=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file and changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_params_file = os.path.join(experimentsPath, experimentName, \"params.json\")\n",
    "\n",
    "# Keep same order as ConfigParserWriter!\n",
    "changes = {\n",
    "    \"numOfTrials\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)\n",
    "\n",
    "# populate a hash table of all experiments, indexed by trial hash\n",
    "experiments = {}\n",
    "for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "    num_of_models = experiment_params[\"numOfTrials\"]\n",
    "    for k in range(num_of_models):\n",
    "        old_trialHash = TrialStatistics.getTrialName(experiment_params, k)\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        new_trialHash = TrialStatistics.getTrialName(experiment_params_new, k)\n",
    "        experiments[old_trialHash] = {\"trialHash\": new_trialHash}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcf91adb8744f548190fe04262675f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasplit /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc -> /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc/params.json updated\n",
      "datasplit /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc -> /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc/params.json updated\n",
      "datasplit /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc -> /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/datasplits/2788d2bc2c355b1c8cf2f3ac00958c413530a8f359f22067b2b8cfbc/params.json updated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        # update experiment params\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "\n",
    "        # fix data split names\n",
    "        old_dataset_name = getDatasetName(config_parser.fixPaths(experiment_params))\n",
    "        old_datasplitsPath = os.path.join(experimentsPath, experimentName, old_dataset_name)\n",
    "        new_dataset_name = getDatasetName(config_parser.fixPaths(experiment_params_new))\n",
    "        new_datasplitsPath = os.path.join(experimentsPath, experimentName, new_dataset_name)\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(old_datasplitsPath):\n",
    "\n",
    "                # update the folder names\n",
    "                os.rename(old_datasplitsPath, new_datasplitsPath)\n",
    "                print(\"datasplit\", old_datasplitsPath, '->', new_datasplitsPath, \"updated\")\n",
    "\n",
    "                # update the params.json\n",
    "                j = json.dumps(experiment_params_new)\n",
    "                json_fileName = os.path.join(new_datasplitsPath, 'params.json')\n",
    "                f = open(json_fileName,\"w\")        \n",
    "                f.write(j)\n",
    "                f.close()  \n",
    "                print(\"json\", json_fileName, \"updated\")\n",
    "                \n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        except:\n",
    "            print(\"datasplit\", old_dataset_name, \"could not be fixed to\", new_dataset_name)\n",
    "            pass   \n",
    "        \n",
    "        experiments[TrialStatistics.getTrialName(experiment_params, 0)]['datasetName'] = new_dataset_name\n",
    "\n",
    "        \n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abcae8a846c42889b2dbd7ca2fd8d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4c8e48f5eb410bb7fd0e27af273eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/528b945e39ac36c5b753c4cd1782448c5ac1b787d9e40673d1188a36 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/5b0ee470deceb7bf49e1f3ef1b4e11c9eb28a0e7547d6f70ef321161 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/5b0ee470deceb7bf49e1f3ef1b4e11c9eb28a0e7547d6f70ef321161/params.json updated\n",
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/5f1201f392ab8b1a11b2ff5e67d9b247cd3c4935a56d18fe94702682 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/f50d9131cb91206e57e8f3910e33ddfe7d6f896cce51b24d5f08d8ca updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/f50d9131cb91206e57e8f3910e33ddfe7d6f896cce51b24d5f08d8ca/params.json updated\n",
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/33001298a97c7c8c99988c583d0db3372baf5e19a1294f6c9ac361aa -> /home/elhamod/HGNN/experiments/learningRateDecay/models/a806689000bd4b5a2443d1567b98327ff519646d9fb3ec4cdfa581ff updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/a806689000bd4b5a2443d1567b98327ff519646d9fb3ec4cdfa581ff/params.json updated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756d205f7dc44b648e4eaec423667443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/6ebabb66d5df6e93590b955ce54420b82954faad8038e9a73a6d61a0 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/cfebc02050936cb479082f1f0acca8cc266fc0175cffb57b91f99161 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/cfebc02050936cb479082f1f0acca8cc266fc0175cffb57b91f99161/params.json updated\n",
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/3716e87d39a02684469ecdc2ba2c49d914a09631c4e03e33cf36f343 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/753383b2bbc0f0ea0f57fccc874ebc4025b7a0085036218dd886dcbe updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/753383b2bbc0f0ea0f57fccc874ebc4025b7a0085036218dd886dcbe/params.json updated\n",
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/4682f72d1495bc72cd76e732a4cc1e83749ad2e78c67f6f0b5c0a753 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/a3f2599605669f8dcb985d062efba2149817c34c104038e8d29e3f98 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/a3f2599605669f8dcb985d062efba2149817c34c104038e8d29e3f98/params.json updated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07afb1f5f8294171b6ebdaf759f47644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/184a4be739f6570b28cb120dfa831ff07f7c17d89b44db4d4e7b2078 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/f7757e8ffc7802b85f32f1632c7f2c587af092d492a2e26809eef1b2 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/f7757e8ffc7802b85f32f1632c7f2c587af092d492a2e26809eef1b2/params.json updated\n",
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/47b50bef1cbad087832385acf3654e8da2c9bb819bb32da25b68fa6c -> /home/elhamod/HGNN/experiments/learningRateDecay/models/d74076fd22fa2e992868fca1a77b8a9a86912fcb9007b0a6894f7e2b updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/d74076fd22fa2e992868fca1a77b8a9a86912fcb9007b0a6894f7e2b/params.json updated\n",
      "model /home/elhamod/HGNN/experiments/learningRateDecay/models/7687d943583e7b8dd7182a2610b75000fb789a97d11060470ef05755 -> /home/elhamod/HGNN/experiments/learningRateDecay/models/48f431d7ca224cd24717d291c42e8c0576fa2b81786c58b7a88e5679 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/models/48f431d7ca224cd24717d291c42e8c0576fa2b81786c58b7a88e5679/params.json updated\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "\n",
    "        num_of_models = experiment_params[\"numOfTrials\"]\n",
    "        with tqdm(total=num_of_models, desc=\"trial\") as bar2:\n",
    "            for k in range(num_of_models):\n",
    "            \n",
    "                # Fix model names\n",
    "                old_model_name = getModelName(experiment_params, k)\n",
    "                old_modelPath = os.path.join(experimentsPath, experimentName, old_model_name)\n",
    "                new_model_name = getModelName(experiment_params_new, k)\n",
    "                new_modelPath = os.path.join(experimentsPath, experimentName, new_model_name)\n",
    "\n",
    "                try:\n",
    "                    if os.path.exists(old_modelPath):\n",
    "                        os.rename(old_modelPath, new_modelPath)\n",
    "                        print(\"model\", old_modelPath, '->', new_modelPath, \"updated\")\n",
    "\n",
    "                        j = json.dumps(experiment_params_new)\n",
    "                        json_fileName = os.path.join(new_modelPath, 'params.json')\n",
    "                        f = open(json_fileName,\"w\")        \n",
    "                        f.write(j)\n",
    "                        f.close()  \n",
    "                        print(\"json\", json_fileName, \"updated\")\n",
    "                    else:\n",
    "                        raise\n",
    "                    \n",
    "                except:\n",
    "                    print(\"model\", old_model_name, \"could not be fixed to\", new_model_name)\n",
    "                    pass  \n",
    "                \n",
    "                \n",
    "\n",
    "                bar2.update()\n",
    "                \n",
    "                experiments[TrialStatistics.getTrialName(experiment_params, k)]['modelName'] = new_model_name\n",
    "\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c5a5caa5a246cf85458a43ff2c7ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result /home/elhamod/HGNN/experiments/learningRateDecay/results/820717ed8f08d7dddf10f9771ce303f82ed59ba4de8a36cd646f15ac -> /home/elhamod/HGNN/experiments/learningRateDecay/results/4d9376173150019b4d3a8435fcb73f89e2bfaea7ebe1b626036e3cb8 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/results/4d9376173150019b4d3a8435fcb73f89e2bfaea7ebe1b626036e3cb8/params.json updated\n",
      "result /home/elhamod/HGNN/experiments/learningRateDecay/results/cebb458b28b820c1874142e88b397a51794965aa90a7a7534ac3d7aa -> /home/elhamod/HGNN/experiments/learningRateDecay/results/ca3bd4bcdc6067d4803682eddc63645349c6067162ae4576d53f39fd updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/results/ca3bd4bcdc6067d4803682eddc63645349c6067162ae4576d53f39fd/params.json updated\n",
      "result /home/elhamod/HGNN/experiments/learningRateDecay/results/5b5b4cf2a9fdd8ec7c41edb417b20d106323552b3ac22d57380fcbee -> /home/elhamod/HGNN/experiments/learningRateDecay/results/7e71436c7c17b6caae8c52ba96db096fd88713fc8e18bdabc5bb3578 updated\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/results/7e71436c7c17b6caae8c52ba96db096fd88713fc8e18bdabc5bb3578/params.json updated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "\n",
    "        old_experimentHash = TrialStatistics.getTrialName(experiment_params)\n",
    "        old_experimentPath = os.path.join(experimentsPath, experimentName, \"results\", old_experimentHash)\n",
    "        new_experimentHash = TrialStatistics.getTrialName(experiment_params_new)\n",
    "        new_experimentPath = os.path.join(experimentsPath, experimentName, \"results\", new_experimentHash)\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(old_experimentPath):\n",
    "\n",
    "                os.rename(old_experimentPath, new_experimentPath)\n",
    "                print(\"result\", old_experimentPath, '->', new_experimentPath, \"updated\")\n",
    "\n",
    "                j = json.dumps(experiment_params_new)\n",
    "                json_fileName = os.path.join(new_experimentPath, 'params.json')\n",
    "                f = open(json_fileName,\"w\")        \n",
    "                f.write(j)\n",
    "                f.close()  \n",
    "                print(\"json\", json_fileName, \"updated\")\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        except:\n",
    "            print(\"result\", old_experimentHash, \"could not be fixed to\",new_experimentHash)\n",
    "            pass \n",
    "        \n",
    "        experiments[TrialStatistics.getTrialName(experiment_params, 0)]['experimentHash'] = new_experimentHash\n",
    "        \n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dec166dac345f5b89e6d63024276fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc3ca7e58e24368a85a0e269ec91d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialHash 528b945e39ac36c5b753c4cd1782448c5ac1b787d9e40673d1188a36 -> 5b0ee470deceb7bf49e1f3ef1b4e11c9eb28a0e7547d6f70ef321161 updated\n",
      "trialHash 5f1201f392ab8b1a11b2ff5e67d9b247cd3c4935a56d18fe94702682 -> f50d9131cb91206e57e8f3910e33ddfe7d6f896cce51b24d5f08d8ca updated\n",
      "trialHash 33001298a97c7c8c99988c583d0db3372baf5e19a1294f6c9ac361aa -> a806689000bd4b5a2443d1567b98327ff519646d9fb3ec4cdfa581ff updated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dffd2590fa04e65b759be0ea28d76ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialHash 6ebabb66d5df6e93590b955ce54420b82954faad8038e9a73a6d61a0 -> cfebc02050936cb479082f1f0acca8cc266fc0175cffb57b91f99161 updated\n",
      "trialHash 3716e87d39a02684469ecdc2ba2c49d914a09631c4e03e33cf36f343 -> 753383b2bbc0f0ea0f57fccc874ebc4025b7a0085036218dd886dcbe updated\n",
      "trialHash 4682f72d1495bc72cd76e732a4cc1e83749ad2e78c67f6f0b5c0a753 -> a3f2599605669f8dcb985d062efba2149817c34c104038e8d29e3f98 updated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81840d6bc2104dbea95d853b89e86046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialHash 184a4be739f6570b28cb120dfa831ff07f7c17d89b44db4d4e7b2078 -> f7757e8ffc7802b85f32f1632c7f2c587af092d492a2e26809eef1b2 updated\n",
      "trialHash 47b50bef1cbad087832385acf3654e8da2c9bb819bb32da25b68fa6c -> d74076fd22fa2e992868fca1a77b8a9a86912fcb9007b0a6894f7e2b updated\n",
      "trialHash 7687d943583e7b8dd7182a2610b75000fb789a97d11060470ef05755 -> 48f431d7ca224cd24717d291c42e8c0576fa2b81786c58b7a88e5679 updated\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open experiments.csv file\n",
    "experimentsFileNameAndPath=os.path.join(experimentsPath, \"experiments.csv\")\n",
    "experiments_file= pd.read_csv(experimentsFileNameAndPath)\n",
    "\n",
    "# For all experiments\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        numOfTrials = experiment_params[\"numOfTrials\"]\n",
    "        trialHash_0 = TrialStatistics.getTrialName(experiment_params, 0) # used for keys who don't change for different trials\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        \n",
    "        # For all trials\n",
    "        with tqdm(total=num_of_models, desc=\"trial\") as bar2:\n",
    "            for j in range(numOfTrials):\n",
    "                \n",
    "                trialHash = TrialStatistics.getTrialName(experiment_params, j)\n",
    "                try:\n",
    "                    # If old entry doesn't exist, nothing to update\n",
    "                    record_exists = not (experiments_file[experiments_file['trialHash'] == trialHash][experiments_file['experimentName'] == experimentName]).empty\n",
    "                    if record_exists:\n",
    "                        \n",
    "                        # drop old row and caluclate new row\n",
    "                        new_trialHash = experiments[trialHash][\"trialHash\"]\n",
    "                        experiments_file.drop(experiments_file[experiments_file['trialHash'] == trialHash][experiments_file['experimentName'] == experimentName].index, inplace = True) \n",
    "                        row_information = {\n",
    "                            'experimentName': experimentName,\n",
    "                            'modelName': experiments[trialHash][\"modelName\"],\n",
    "                            'datasetName': experiments[trialHash_0][\"datasetName\"],\n",
    "                            'experimentHash': experiments[trialHash_0][\"experimentHash\"],\n",
    "                            'trialHash': new_trialHash\n",
    "                        }\n",
    "                        row_information = {**row_information, **experiment_params_new} \n",
    "\n",
    "                        # error handling to avoid duplicates\n",
    "                        record_exists = not (experiments_file[experiments_file['trialHash'] == new_trialHash][experiments_file['experimentName'] == experimentName]).empty\n",
    "                        if record_exists:\n",
    "                            experiments_file.drop(experiments_file[experiments_file['trialHash'] == new_trialHash][experiments_file['experimentName'] == experimentName].index, inplace = True) \n",
    "\n",
    "                        # update with new entry    \n",
    "                        experiments_file = experiments_file.append(pd.DataFrame(row_information, index=[0]), ignore_index = True)\n",
    "                        print(\"trialHash\", trialHash, \"->\", new_trialHash, \"updated\")\n",
    "                except:\n",
    "                    print(\"trialHash\", trialHash, \"could not be updated!\")\n",
    "                    pass\n",
    "                bar2.update()\n",
    "        bar.update()\n",
    "\n",
    "# resave file\n",
    "experiments_file.to_csv(experimentsFileNameAndPath, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix params file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d239a590c3c4519928e2c963b3c02a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "json /home/elhamod/HGNN/experiments/learningRateDecay/params.json updated\n"
     ]
    }
   ],
   "source": [
    "experiment_list = []\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        experiment_list.append(experiment_params_new)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "j = json.dumps({\"experimentList\": experiment_list})\n",
    "f = open(old_params_file,\"w\")        \n",
    "f.write(j)\n",
    "f.close()  \n",
    "print(\"json\", old_params_file, \"updated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
