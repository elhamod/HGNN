{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser, getModelName\n",
    "from myhelpers import TrialStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/raid/elhamod/Fish/official_experiments/\"\n",
    "dataPath=\"/raid/elhamod/Fish/\"\n",
    "experimentName=\"Hard_notpretrained\"\n",
    "# experimentName=\"Hard_noaggregation\"\n",
    "# experimentName=\"Hard\"\n",
    "# experimentName=\"Easy\"\n",
    "\n",
    "cuda=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file and changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_params_file = os.path.join(experimentsPath, experimentName, \"params.json\")\n",
    "\n",
    "# Keep same order as ConfigParserWriter!\n",
    "changes = {\n",
    "#     'pretrained': False\n",
    "}\n",
    "removes = ['phylogeny_loss_epsilon', \"noSpeciesBackprop\", \"phylogeny_loss\", \"unsupervisedOnTest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'561cffae5e8eb405bfdf19f687fbb27008ffae6c0c9c35103b614cdf': {'trialHash': '5a1c1cb9ada98bf1bc733868da195dc1d1338c44e0098667996c129d'},\n",
       " '9260da9f7780479ba1396b6acf6ed5e0c866640a5f1b94e15c617107': {'trialHash': '07cf8b8f49af586a8e74be62c757e641592d78f1700a989e92f2eb3f'},\n",
       " 'edff1486b1c4597c6ad247475e489c91ed39e59c3502b46755cdb8e2': {'trialHash': 'a0a77de87f71334d10585afcae0401d22211391bb522cb4255803d6a'},\n",
       " '213cd4ec3515779c1ce9790eccf5cbaa36862b433eddfe472a65b71a': {'trialHash': '1a4e8720316c2f253c437dad3bbb716bdb18f9dd52a008d351e71caf'},\n",
       " '8d62203d0bf3da07aa24d919ec29b6425118f1a3e83dce79dbeee896': {'trialHash': '1a2f280a22dad1045212ea3f8ad2e2363e16369697f57dc725b6ccc1'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)\n",
    "\n",
    "# populate a hash table of all experiments, indexed by trial hash\n",
    "experiments = {}\n",
    "for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "    num_of_models = experiment_params[\"numOfTrials\"]\n",
    "    for k in range(num_of_models):\n",
    "#         print(experiment_params)\n",
    "        old_trialHash = TrialStatistics.getTrialName(experiment_params, k)\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "#         print(experiment_params_new)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        new_trialHash = TrialStatistics.getTrialName(experiment_params_new, k)\n",
    "        experiments[old_trialHash] = {\"trialHash\": new_trialHash}\n",
    "        \n",
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431e04d5767e41ff91f619753b3a6520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=1.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'Hard/curated_30_50', 'img_res': 448, 'augmented': True, 'batchSize': 100, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'modelType': 'HGNN', 'lambda': 0.01, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.01, 'adaptive_alpha': 0.9, 'pretrained': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ecb26e047147a2ba1e34c53081c43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/561cffae5e8eb405bfdf19f687fbb27008ffae6c0c9c35103b614cdf\n",
      "model /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/561cffae5e8eb405bfdf19f687fbb27008ffae6c0c9c35103b614cdf -> /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/5a1c1cb9ada98bf1bc733868da195dc1d1338c44e0098667996c129d updated\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/5a1c1cb9ada98bf1bc733868da195dc1d1338c44e0098667996c129d/params.json updated\n",
      "/raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/9260da9f7780479ba1396b6acf6ed5e0c866640a5f1b94e15c617107\n",
      "model /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/9260da9f7780479ba1396b6acf6ed5e0c866640a5f1b94e15c617107 -> /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/07cf8b8f49af586a8e74be62c757e641592d78f1700a989e92f2eb3f updated\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/07cf8b8f49af586a8e74be62c757e641592d78f1700a989e92f2eb3f/params.json updated\n",
      "/raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/edff1486b1c4597c6ad247475e489c91ed39e59c3502b46755cdb8e2\n",
      "model /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/edff1486b1c4597c6ad247475e489c91ed39e59c3502b46755cdb8e2 -> /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/a0a77de87f71334d10585afcae0401d22211391bb522cb4255803d6a updated\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/a0a77de87f71334d10585afcae0401d22211391bb522cb4255803d6a/params.json updated\n",
      "/raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/213cd4ec3515779c1ce9790eccf5cbaa36862b433eddfe472a65b71a\n",
      "model /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/213cd4ec3515779c1ce9790eccf5cbaa36862b433eddfe472a65b71a -> /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/1a4e8720316c2f253c437dad3bbb716bdb18f9dd52a008d351e71caf updated\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/1a4e8720316c2f253c437dad3bbb716bdb18f9dd52a008d351e71caf/params.json updated\n",
      "/raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/8d62203d0bf3da07aa24d919ec29b6425118f1a3e83dce79dbeee896\n",
      "model /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/8d62203d0bf3da07aa24d919ec29b6425118f1a3e83dce79dbeee896 -> /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/1a2f280a22dad1045212ea3f8ad2e2363e16369697f57dc725b6ccc1 updated\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/models/1a2f280a22dad1045212ea3f8ad2e2363e16369697f57dc725b6ccc1/params.json updated\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        print(experiment_params_new)\n",
    "\n",
    "        num_of_models = experiment_params[\"numOfTrials\"]\n",
    "        with tqdm(total=num_of_models, desc=\"trial\") as bar2:\n",
    "            for k in range(num_of_models):\n",
    "            \n",
    "                # Fix model names\n",
    "                old_model_name = getModelName(experiment_params, k)\n",
    "                old_modelPath = os.path.join(experimentsPath, experimentName, old_model_name)\n",
    "                new_model_name = getModelName(experiment_params_new, k)\n",
    "                new_modelPath = os.path.join(experimentsPath, experimentName, new_model_name)\n",
    "\n",
    "                try:\n",
    "                    print(old_modelPath)\n",
    "                    if os.path.exists(old_modelPath):\n",
    "                        os.rename(old_modelPath, new_modelPath)\n",
    "                        print(\"model\", old_modelPath, '->', new_modelPath, \"updated\")\n",
    "\n",
    "                        j = json.dumps(experiment_params_new)\n",
    "                        json_fileName = os.path.join(new_modelPath, 'params.json')\n",
    "                        f = open(json_fileName,\"w\")        \n",
    "                        f.write(j)\n",
    "                        f.close()  \n",
    "                        print(\"json\", json_fileName, \"updated\")\n",
    "                    else:\n",
    "                        raise\n",
    "                    \n",
    "                except:\n",
    "                    print(\"model\", old_model_name, \"could not be fixed to\", new_model_name)\n",
    "                    pass  \n",
    "                \n",
    "                \n",
    "\n",
    "                bar2.update()\n",
    "                \n",
    "                experiments[TrialStatistics.getTrialName(experiment_params, k)]['modelName'] = new_model_name\n",
    "\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b466b223237544fab7244da068cf0f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=1.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result /raid/elhamod/Fish/official_experiments/Hard_notpretrained/results/f60977adc490982166beb6abd461d6ae085432f9b146fab8b4b2a9e5 -> /raid/elhamod/Fish/official_experiments/Hard_notpretrained/results/331fdf718eccc581e40a50d4677aad181b371dd30263c35a143f74f0 updated\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/results/331fdf718eccc581e40a50d4677aad181b371dd30263c35a143f74f0/params.json updated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "\n",
    "        old_experimentHash = TrialStatistics.getTrialName(experiment_params)\n",
    "        old_experimentPath = os.path.join(experimentsPath, experimentName, \"results\", old_experimentHash)\n",
    "        new_experimentHash = TrialStatistics.getTrialName(experiment_params_new)\n",
    "        new_experimentPath = os.path.join(experimentsPath, experimentName, \"results\", new_experimentHash)\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(old_experimentPath):\n",
    "\n",
    "                os.rename(old_experimentPath, new_experimentPath)\n",
    "                print(\"result\", old_experimentPath, '->', new_experimentPath, \"updated\")\n",
    "\n",
    "                j = json.dumps(experiment_params_new)\n",
    "                json_fileName = os.path.join(new_experimentPath, 'params.json')\n",
    "                f = open(json_fileName,\"w\")        \n",
    "                f.write(j)\n",
    "                f.close()  \n",
    "                print(\"json\", json_fileName, \"updated\")\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        except:\n",
    "            print(\"result\", old_experimentHash, \"could not be fixed to\",new_experimentHash)\n",
    "            pass \n",
    "        \n",
    "        experiments[TrialStatistics.getTrialName(experiment_params, 0)]['experimentHash'] = new_experimentHash\n",
    "        \n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46430af589c347e78e77b7b4b9d90b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=1.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'Hard', 'img_res': 448, 'augmented': True, 'batchSize': 100, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'modelType': 'HGNN', 'lambda': 0.01, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.01, 'adaptive_alpha': 0.9, 'pretrained': False}\n",
      "{'image_path': 'Hard/curated_30_50', 'img_res': 448, 'augmented': True, 'batchSize': 100, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'modelType': 'HGNN', 'lambda': 0.01, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.01, 'adaptive_alpha': 0.9, 'pretrained': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b62dbd981634e0e81ba139bd58eb10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialHash 561cffae5e8eb405bfdf19f687fbb27008ffae6c0c9c35103b614cdf -> 5a1c1cb9ada98bf1bc733868da195dc1d1338c44e0098667996c129d updated\n",
      "trialHash 9260da9f7780479ba1396b6acf6ed5e0c866640a5f1b94e15c617107 -> 07cf8b8f49af586a8e74be62c757e641592d78f1700a989e92f2eb3f updated\n",
      "trialHash edff1486b1c4597c6ad247475e489c91ed39e59c3502b46755cdb8e2 -> a0a77de87f71334d10585afcae0401d22211391bb522cb4255803d6a updated\n",
      "trialHash 213cd4ec3515779c1ce9790eccf5cbaa36862b433eddfe472a65b71a -> 1a4e8720316c2f253c437dad3bbb716bdb18f9dd52a008d351e71caf updated\n",
      "trialHash 8d62203d0bf3da07aa24d919ec29b6425118f1a3e83dce79dbeee896 -> 1a2f280a22dad1045212ea3f8ad2e2363e16369697f57dc725b6ccc1 updated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "# open experiments.csv file\n",
    "experimentsFileNameAndPath=os.path.join(experimentsPath, \"experiments.csv\")\n",
    "experiments_file= pd.read_csv(experimentsFileNameAndPath)\n",
    "\n",
    "# For all experiments\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        numOfTrials = experiment_params[\"numOfTrials\"]\n",
    "        trialHash_0 = TrialStatistics.getTrialName(experiment_params, 0) # used for keys who don't change for different trials\n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        print(experiment_params_new)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        print(experiment_params_new)\n",
    "        \n",
    "        # For all trials\n",
    "        with tqdm(total=num_of_models, desc=\"trial\") as bar2:\n",
    "            for j in range(numOfTrials):\n",
    "                \n",
    "                trialHash = TrialStatistics.getTrialName(experiment_params, j)\n",
    "#                 try:\n",
    "                    # If old entry doesn't exist, nothing to update\n",
    "    #                     record_exists = not (experiments_file[experiments_file['trialHash'] == trialHash][experiments_file['experimentName'] == experimentName]).empty\n",
    "    #                     if record_exists:\n",
    "\n",
    "                # drop old row and caluclate new row\n",
    "                new_trialHash = experiments[trialHash][\"trialHash\"]\n",
    "                experiments_file.drop(experiments_file[experiments_file['trialHash'] == trialHash][experiments_file['experimentName'] == experimentName].index, inplace = True) \n",
    "#                     print(experiments)\n",
    "                row_information = {\n",
    "                    'experimentName': experimentName,\n",
    "                    'modelName': experiments[trialHash][\"modelName\"],\n",
    "#                     'datasetName': experiments[trialHash_0][\"datasetName\"],\n",
    "                    'experimentHash': experiments[trialHash_0][\"experimentHash\"],\n",
    "                    'trialHash': new_trialHash\n",
    "                }\n",
    "                row_information = {**row_information, **experiment_params_new} \n",
    "\n",
    "                # error handling to avoid duplicates\n",
    "                record_exists = not (experiments_file[experiments_file['trialHash'] == new_trialHash][experiments_file['experimentName'] == experimentName]).empty\n",
    "                if record_exists:\n",
    "                    experiments_file.drop(experiments_file[experiments_file['trialHash'] == new_trialHash][experiments_file['experimentName'] == experimentName].index, inplace = True) \n",
    "\n",
    "                # update with new entry    \n",
    "                experiments_file = experiments_file.append(pd.DataFrame(row_information, index=[0]), ignore_index = True)\n",
    "                print(\"trialHash\", trialHash, \"->\", new_trialHash, \"updated\")\n",
    "#                 except:\n",
    "#                     print(\"trialHash\", trialHash, \"could not be updated!\")\n",
    "#                     pass\n",
    "                bar2.update()\n",
    "        bar.update()\n",
    "\n",
    "# resave file\n",
    "experiments_file.to_csv(experimentsFileNameAndPath, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix params file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cea90a40234cea880ff533f1c5ed0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=1.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': 'Hard/curated_30_50', 'img_res': 448, 'augmented': True, 'batchSize': 100, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'modelType': 'HGNN', 'lambda': 0.01, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.01, 'adaptive_alpha': 0.9, 'pretrained': False}\n",
      "\n",
      "json /raid/elhamod/Fish/official_experiments/Hard_notpretrained/params.json updated\n"
     ]
    }
   ],
   "source": [
    "experiment_list = []\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for i, experiment_params in enumerate(config_parser.getExperiments(fixExperiments=False)):\n",
    "        \n",
    "        experiment_params_new = {**experiment_params, **changes} \n",
    "        for key in removes:\n",
    "            experiment_params_new.pop(key, None)\n",
    "        experiment_params_new = config_parser.fixExperimentParams(experiment_params_new)\n",
    "        print(experiment_params_new)\n",
    "        experiment_list.append(experiment_params_new)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "j = json.dumps({\"experimentList\": experiment_list})\n",
    "f = open(old_params_file,\"w\")        \n",
    "f.write(j)\n",
    "f.close()  \n",
    "print(\"json\", old_params_file, \"updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
