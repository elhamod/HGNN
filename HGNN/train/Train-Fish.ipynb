{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath = \"/raid/elhamod/Fish/experiments/\" #\"/raid/elhamod/CIFAR_HGNN/experiments/\" #\"/raid/elhamod/Fish/experiments/\"\n",
    "dataPath = \"/raid/elhamod/Fish/\" # \"/raid/elhamod/\" #\"/raid/elhamod/Fish/\"\n",
    "experimentName = \"Fish30-5runs\" #\"Fish_tripletloss_alpha_lr_experiments\"\n",
    "device = 0\n",
    "detailed_reporting = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmndhamod\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "experiment:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 0\n",
      "{'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-BB', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n",
      "Creating datasets...\n",
      "{'Alosa chrysochloris': 482298, 'Carassius auratus': 1005907, 'Cyprinus carpio': 429083, 'Esox americanus': 496115, 'Gambusia affinis': 617445, 'Lepisosteus osseus': 519445, 'Lepisosteus platostomus': 731608, 'Lepomis auritus': 1002718, 'Lepomis cyanellus': 476361, 'Lepomis gibbosus': 670266, 'Lepomis gulosus': 476359, 'Lepomis humilis': 892772, 'Lepomis macrochirus': 836783, 'Lepomis megalotis': 271249, 'Lepomis microlophus': 271244, 'Morone chrysops': 246133, 'Morone mississippiensis': 769290, 'Notropis atherinoides': 636312, 'Notropis blennius': 419165, 'Notropis boops': 443777, 'Notropis buccatus': 269524, 'Notropis buchanani': 555686, 'Notropis dorsalis': 419160, 'Notropis hudsonius': 135051, 'Notropis leuciodus': 338652, 'Notropis nubilus': 550199, 'Notropis percobromus': 403731, 'Notropis stramineus': 351741, 'Notropis telescopus': 550190, 'Notropis texanus': 550208, 'Notropis volucellus': 351735, 'Notropis wickliffi': 563834, 'Noturus exilis': 678206, 'Noturus flavus': 101864, 'Noturus gyrinus': 652777, 'Noturus miurus': 282530, 'Noturus nocturnus': 621586, 'Phenacobius mirabilis': 945111}\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dfbd306be3404a8c6507f57f3f55bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/78e0c9ed793cdb667b3fe3e808d2000c38c0f8875e18a1232b7952ea', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': 'd5cb3503ea225692caefee6fbb34cf8657aec723adb53d1c93d0ffad', 'trialHash': '78e0c9ed793cdb667b3fe3e808d2000c38c0f8875e18a1232b7952ea', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-BB', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">78e0c9ed793cdb667b3fe3e808d2000c38c0f8875e18a1232b7952ea</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/1q7eyxn7\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/1q7eyxn7</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161148-1q7eyxn7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/78e0c9ed793cdb667b3fe3e808d2000c38c0f8875e18a1232b7952ea found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:115: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28000<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645a33a821bd410885e87004cb176116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161148-1q7eyxn7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161148-1q7eyxn7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">78e0c9ed793cdb667b3fe3e808d2000c38c0f8875e18a1232b7952ea</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/1q7eyxn7\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/1q7eyxn7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/08feb0a9f63a13e44d61fc3fd859d18db1aa456fbc6407ca0f29e9fd', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': 'd5cb3503ea225692caefee6fbb34cf8657aec723adb53d1c93d0ffad', 'trialHash': '08feb0a9f63a13e44d61fc3fd859d18db1aa456fbc6407ca0f29e9fd', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-BB', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">08feb0a9f63a13e44d61fc3fd859d18db1aa456fbc6407ca0f29e9fd</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/36nfbqsl\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/36nfbqsl</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161200-36nfbqsl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/08feb0a9f63a13e44d61fc3fd859d18db1aa456fbc6407ca0f29e9fd found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28213<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9abc73af95434389b76a18e1ad618f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161200-36nfbqsl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161200-36nfbqsl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">08feb0a9f63a13e44d61fc3fd859d18db1aa456fbc6407ca0f29e9fd</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/36nfbqsl\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/36nfbqsl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/455b115a347e3e8f28d63a6faaae5f322345e2dfd7eafa6211ee9b9c', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': 'd5cb3503ea225692caefee6fbb34cf8657aec723adb53d1c93d0ffad', 'trialHash': '455b115a347e3e8f28d63a6faaae5f322345e2dfd7eafa6211ee9b9c', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-BB', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">455b115a347e3e8f28d63a6faaae5f322345e2dfd7eafa6211ee9b9c</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/1rh01ftg\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/1rh01ftg</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161212-1rh01ftg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/455b115a347e3e8f28d63a6faaae5f322345e2dfd7eafa6211ee9b9c found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28388<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f56a3139fb4b06a1965b50fe28514d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161212-1rh01ftg/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161212-1rh01ftg/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">455b115a347e3e8f28d63a6faaae5f322345e2dfd7eafa6211ee9b9c</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/1rh01ftg\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/1rh01ftg</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/565860b642cda985b2caf9eba16c4e5b03f2e17516874dcde090b88f', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': 'd5cb3503ea225692caefee6fbb34cf8657aec723adb53d1c93d0ffad', 'trialHash': '565860b642cda985b2caf9eba16c4e5b03f2e17516874dcde090b88f', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-BB', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">565860b642cda985b2caf9eba16c4e5b03f2e17516874dcde090b88f</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/1f11xpwd\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/1f11xpwd</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161223-1f11xpwd</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/565860b642cda985b2caf9eba16c4e5b03f2e17516874dcde090b88f found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28563<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da3eaca9eec46a48fef4d4824a2288f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161223-1f11xpwd/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161223-1f11xpwd/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">565860b642cda985b2caf9eba16c4e5b03f2e17516874dcde090b88f</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/1f11xpwd\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/1f11xpwd</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/6b1a0e04e06714c2d4c0be884316f767be47993da2acac85f94951a5', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': 'd5cb3503ea225692caefee6fbb34cf8657aec723adb53d1c93d0ffad', 'trialHash': '6b1a0e04e06714c2d4c0be884316f767be47993da2acac85f94951a5', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-BB', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">6b1a0e04e06714c2d4c0be884316f767be47993da2acac85f94951a5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/23w5z8o3\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/23w5z8o3</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161234-23w5z8o3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/6b1a0e04e06714c2d4c0be884316f767be47993da2acac85f94951a5 found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28738<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f050d7a7f6942a7a15f96e36e74f8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161234-23w5z8o3/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161234-23w5z8o3/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">6b1a0e04e06714c2d4c0be884316f767be47993da2acac85f94951a5</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/23w5z8o3\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/23w5z8o3</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  20%|██        | 1/5 [00:58<03:52, 58.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': 'MSE', 'displayName': 'Fish30-5runs-MSE', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n",
      "Creating datasets...\n",
      "{'Alosa chrysochloris': 482298, 'Carassius auratus': 1005907, 'Cyprinus carpio': 429083, 'Esox americanus': 496115, 'Gambusia affinis': 617445, 'Lepisosteus osseus': 519445, 'Lepisosteus platostomus': 731608, 'Lepomis auritus': 1002718, 'Lepomis cyanellus': 476361, 'Lepomis gibbosus': 670266, 'Lepomis gulosus': 476359, 'Lepomis humilis': 892772, 'Lepomis macrochirus': 836783, 'Lepomis megalotis': 271249, 'Lepomis microlophus': 271244, 'Morone chrysops': 246133, 'Morone mississippiensis': 769290, 'Notropis atherinoides': 636312, 'Notropis blennius': 419165, 'Notropis boops': 443777, 'Notropis buccatus': 269524, 'Notropis buchanani': 555686, 'Notropis dorsalis': 419160, 'Notropis hudsonius': 135051, 'Notropis leuciodus': 338652, 'Notropis nubilus': 550199, 'Notropis percobromus': 403731, 'Notropis stramineus': 351741, 'Notropis telescopus': 550190, 'Notropis texanus': 550208, 'Notropis volucellus': 351735, 'Notropis wickliffi': 563834, 'Noturus exilis': 678206, 'Noturus flavus': 101864, 'Noturus gyrinus': 652777, 'Noturus miurus': 282530, 'Noturus nocturnus': 621586, 'Phenacobius mirabilis': 945111}\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb496953e5e44e819d96fb441fb4b9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/7e14e25c82b973a80c06045092573e239f99b37d42885d83a1c026f5', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': '5aca2f765805f89fb5f676e4f34447d2268e14eb7e727a06d01024d2', 'trialHash': '7e14e25c82b973a80c06045092573e239f99b37d42885d83a1c026f5', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': 'MSE', 'displayName': 'Fish30-5runs-MSE', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">7e14e25c82b973a80c06045092573e239f99b37d42885d83a1c026f5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/z1ext2uh\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/z1ext2uh</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161246-z1ext2uh</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/7e14e25c82b973a80c06045092573e239f99b37d42885d83a1c026f5 found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28914<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94dc7edeb4244eba1afe15202559485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161246-z1ext2uh/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161246-z1ext2uh/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">7e14e25c82b973a80c06045092573e239f99b37d42885d83a1c026f5</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/z1ext2uh\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/z1ext2uh</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/7296f057e4d0de2fa31f2953a3ea0925d633b3d3f68ee14538874b9e', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': '5aca2f765805f89fb5f676e4f34447d2268e14eb7e727a06d01024d2', 'trialHash': '7296f057e4d0de2fa31f2953a3ea0925d633b3d3f68ee14538874b9e', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': 'MSE', 'displayName': 'Fish30-5runs-MSE', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">7296f057e4d0de2fa31f2953a3ea0925d633b3d3f68ee14538874b9e</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/ay7myhp5\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/ay7myhp5</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161256-ay7myhp5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/7296f057e4d0de2fa31f2953a3ea0925d633b3d3f68ee14538874b9e found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29090<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afe7d422e074d4f9797730766982eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161256-ay7myhp5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161256-ay7myhp5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">7296f057e4d0de2fa31f2953a3ea0925d633b3d3f68ee14538874b9e</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/ay7myhp5\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/ay7myhp5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/fd1be6e7f601c1a4aedbc6869cb7c902630e5daa0ba6b408149fbd88', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': '5aca2f765805f89fb5f676e4f34447d2268e14eb7e727a06d01024d2', 'trialHash': 'fd1be6e7f601c1a4aedbc6869cb7c902630e5daa0ba6b408149fbd88', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': 'MSE', 'displayName': 'Fish30-5runs-MSE', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fd1be6e7f601c1a4aedbc6869cb7c902630e5daa0ba6b408149fbd88</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/2ow5fsfr\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/2ow5fsfr</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161307-2ow5fsfr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/fd1be6e7f601c1a4aedbc6869cb7c902630e5daa0ba6b408149fbd88 found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29265<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1935adc737c4a3e976a8082412e801a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161307-2ow5fsfr/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161307-2ow5fsfr/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fd1be6e7f601c1a4aedbc6869cb7c902630e5daa0ba6b408149fbd88</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/2ow5fsfr\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/2ow5fsfr</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/2f6cf7751941d196cce942b2bf4cacba6f13d886134c34540dcd0cff', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': '5aca2f765805f89fb5f676e4f34447d2268e14eb7e727a06d01024d2', 'trialHash': '2f6cf7751941d196cce942b2bf4cacba6f13d886134c34540dcd0cff', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': 'MSE', 'displayName': 'Fish30-5runs-MSE', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">2f6cf7751941d196cce942b2bf4cacba6f13d886134c34540dcd0cff</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/2150c0u5\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/2150c0u5</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161318-2150c0u5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/2f6cf7751941d196cce942b2bf4cacba6f13d886134c34540dcd0cff found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29440<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93f2f7aa0904734a13dbf4b472c236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161318-2150c0u5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161318-2150c0u5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">2f6cf7751941d196cce942b2bf4cacba6f13d886134c34540dcd0cff</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/2150c0u5\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/2150c0u5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/b2187833a929ab3aa0fe2f3829ea2a6495892bc383caf5acd0a342b6', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': '5aca2f765805f89fb5f676e4f34447d2268e14eb7e727a06d01024d2', 'trialHash': 'b2187833a929ab3aa0fe2f3829ea2a6495892bc383caf5acd0a342b6', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': False, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': 'MSE', 'displayName': 'Fish30-5runs-MSE', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">b2187833a929ab3aa0fe2f3829ea2a6495892bc383caf5acd0a342b6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/dsa1znn8\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/dsa1znn8</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161329-dsa1znn8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model /raid/elhamod/Fish/experiments/Fish30-5runs/models/b2187833a929ab3aa0fe2f3829ea2a6495892bc383caf5acd0a342b6 found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29616<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddc249858684776a52a5d2ed5af6bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161329-dsa1znn8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161329-dsa1znn8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">b2187833a929ab3aa0fe2f3829ea2a6495892bc383caf5acd0a342b6</strong>: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/dsa1znn8\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/dsa1znn8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  40%|████      | 2/5 [01:53<02:51, 57.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 100, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-hiertriplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n",
      "Creating datasets...\n",
      "{'Alosa chrysochloris': 482298, 'Carassius auratus': 1005907, 'Cyprinus carpio': 429083, 'Esox americanus': 496115, 'Gambusia affinis': 617445, 'Lepisosteus osseus': 519445, 'Lepisosteus platostomus': 731608, 'Lepomis auritus': 1002718, 'Lepomis cyanellus': 476361, 'Lepomis gibbosus': 670266, 'Lepomis gulosus': 476359, 'Lepomis humilis': 892772, 'Lepomis macrochirus': 836783, 'Lepomis megalotis': 271249, 'Lepomis microlophus': 271244, 'Morone chrysops': 246133, 'Morone mississippiensis': 769290, 'Notropis atherinoides': 636312, 'Notropis blennius': 419165, 'Notropis boops': 443777, 'Notropis buccatus': 269524, 'Notropis buchanani': 555686, 'Notropis dorsalis': 419160, 'Notropis hudsonius': 135051, 'Notropis leuciodus': 338652, 'Notropis nubilus': 550199, 'Notropis percobromus': 403731, 'Notropis stramineus': 351741, 'Notropis telescopus': 550190, 'Notropis texanus': 550208, 'Notropis volucellus': 351735, 'Notropis wickliffi': 563834, 'Noturus exilis': 678206, 'Noturus flavus': 101864, 'Noturus gyrinus': 652777, 'Noturus miurus': 282530, 'Noturus nocturnus': 621586, 'Phenacobius mirabilis': 945111}\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a289bb9389d46e1bcabe22f4ba9f5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'Fish30-5runs', 'modelName': 'models/47ea4eceb762ad82178fd1a115fa6461c64b710456fbd1fc9e56098f', 'datasetName': 'datasplits/a30fade0855f8d4a9e28fdac4e65ae71ab21444a323ee6e3927d97f8', 'experimentHash': '4f2561522c5b25cca87e3274953ba031418f6f7a68577eb42f76277c', 'trialHash': '47ea4eceb762ad82178fd1a115fa6461c64b710456fbd1fc9e56098f', 'image_path': 'Curated4/Easy_30', 'suffix': None, 'img_res': 448, 'augmented': True, 'batchSize': 100, 'learning_rate': 0.001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 10, 'modelType': 'BB', 'lambda': 0, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': True, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 2, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'displayName': 'Fish30-5runs-hiertriplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">47ea4eceb762ad82178fd1a115fa6461c64b710456fbd1fc9e56098f</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/HGNN\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/HGNN/runs/2xloyv3k\" target=\"_blank\">https://wandb.ai/mndhamod/HGNN/runs/2xloyv3k</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/HGNN/code/HGNN/HGNN/train/wandb/run-20210607_161341-2xloyv3k</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:   0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layer2', 'layer4']\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration:   0%|          | 0/120 [00:26<?, ?it/s, min_val_loss=inf, train=0.00593, val=0.00527, val_loss=3.64]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   1%|          | 1/120 [00:26<52:26, 26.44s/it, min_val_loss=inf, train=0.00593, val=0.00527, val_loss=3.64]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   1%|          | 1/120 [01:56<52:26, 26.44s/it, min_val_loss=inf, train=0.00806, val=0.00629, val_loss=3.64]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   2%|▏         | 2/120 [01:56<1:29:16, 45.40s/it, min_val_loss=inf, train=0.00806, val=0.00629, val_loss=3.64]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   2%|▏         | 2/120 [03:32<1:29:16, 45.40s/it, min_val_loss=159, train=0.121, val=0.074, val_loss=3.62]    \u001b[A\u001b[A\n",
      "\n",
      "iteration:   2%|▎         | 3/120 [03:32<1:58:18, 60.67s/it, min_val_loss=159, train=0.121, val=0.074, val_loss=3.62]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   2%|▎         | 3/120 [05:07<1:58:18, 60.67s/it, min_val_loss=13.5, train=0.358, val=0.277, val_loss=3.6]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   3%|▎         | 4/120 [05:07<2:17:19, 71.03s/it, min_val_loss=13.5, train=0.358, val=0.277, val_loss=3.6]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   3%|▎         | 4/120 [06:40<2:17:19, 71.03s/it, min_val_loss=3.62, train=0.466, val=0.319, val_loss=3.54]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   4%|▍         | 5/120 [06:40<2:28:57, 77.72s/it, min_val_loss=3.62, train=0.466, val=0.319, val_loss=3.54]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   4%|▍         | 5/120 [08:19<2:28:57, 77.72s/it, min_val_loss=3.13, train=0.623, val=0.393, val_loss=3.49]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   5%|▌         | 6/120 [08:19<2:39:43, 84.07s/it, min_val_loss=3.13, train=0.623, val=0.393, val_loss=3.49]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   5%|▌         | 6/120 [09:54<2:39:43, 84.07s/it, min_val_loss=2.54, train=0.761, val=0.532, val_loss=3.44]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   6%|▌         | 7/120 [09:54<2:44:27, 87.33s/it, min_val_loss=2.54, train=0.761, val=0.532, val_loss=3.44]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   6%|▌         | 7/120 [11:30<2:44:27, 87.33s/it, min_val_loss=1.88, train=0.804, val=0.58, val_loss=3.4]  \u001b[A\u001b[A\n",
      "\n",
      "iteration:   7%|▋         | 8/120 [11:30<2:47:56, 89.97s/it, min_val_loss=1.88, train=0.804, val=0.58, val_loss=3.4]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   7%|▋         | 8/120 [13:05<2:47:56, 89.97s/it, min_val_loss=1.72, train=0.869, val=0.612, val_loss=3.37]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   8%|▊         | 9/120 [13:05<2:49:16, 91.50s/it, min_val_loss=1.72, train=0.869, val=0.612, val_loss=3.37]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   8%|▊         | 9/120 [14:39<2:49:16, 91.50s/it, min_val_loss=1.63, train=0.876, val=0.587, val_loss=3.34]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   8%|▊         | 10/120 [14:39<2:49:07, 92.25s/it, min_val_loss=1.63, train=0.876, val=0.587, val_loss=3.34]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   8%|▊         | 10/120 [16:14<2:49:07, 92.25s/it, min_val_loss=1.63, train=0.959, val=0.733, val_loss=3.27]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   9%|▉         | 11/120 [16:14<2:48:37, 92.82s/it, min_val_loss=1.63, train=0.959, val=0.733, val_loss=3.27]\u001b[A\u001b[A\n",
      "\n",
      "iteration:   9%|▉         | 11/120 [17:44<2:48:37, 92.82s/it, min_val_loss=1.36, train=0.982, val=0.748, val_loss=3.22]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  10%|█         | 12/120 [17:44<2:46:02, 92.25s/it, min_val_loss=1.36, train=0.982, val=0.748, val_loss=3.22]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  10%|█         | 12/120 [19:23<2:46:02, 92.25s/it, min_val_loss=1.34, train=0.997, val=0.768, val_loss=3.2] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  11%|█         | 13/120 [19:23<2:47:50, 94.12s/it, min_val_loss=1.34, train=0.997, val=0.768, val_loss=3.2]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  11%|█         | 13/120 [20:57<2:47:50, 94.12s/it, min_val_loss=1.3, train=0.992, val=0.686, val_loss=3.19]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  12%|█▏        | 14/120 [20:57<2:46:17, 94.13s/it, min_val_loss=1.3, train=0.992, val=0.686, val_loss=3.19]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  12%|█▏        | 14/120 [22:31<2:46:17, 94.13s/it, min_val_loss=1.3, train=0.999, val=0.82, val_loss=3.12] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  12%|█▎        | 15/120 [22:31<2:44:28, 93.99s/it, min_val_loss=1.3, train=0.999, val=0.82, val_loss=3.12]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  12%|█▎        | 15/120 [24:02<2:44:28, 93.99s/it, min_val_loss=1.22, train=0.999, val=0.81, val_loss=3.1]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  13%|█▎        | 16/120 [24:02<2:41:36, 93.23s/it, min_val_loss=1.22, train=0.999, val=0.81, val_loss=3.1]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  13%|█▎        | 16/120 [25:30<2:41:36, 93.23s/it, min_val_loss=1.22, train=1, val=0.82, val_loss=3.04]   \u001b[A\u001b[A\n",
      "\n",
      "iteration:  14%|█▍        | 17/120 [25:30<2:37:15, 91.61s/it, min_val_loss=1.22, train=1, val=0.82, val_loss=3.04]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  14%|█▍        | 17/120 [27:08<2:37:15, 91.61s/it, min_val_loss=1.22, train=0.999, val=0.833, val_loss=3.04]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  15%|█▌        | 18/120 [27:08<2:38:53, 93.47s/it, min_val_loss=1.22, train=0.999, val=0.833, val_loss=3.04]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  15%|█▌        | 18/120 [28:43<2:38:53, 93.47s/it, min_val_loss=1.2, train=1, val=0.811, val_loss=3.05]     \u001b[A\u001b[A\n",
      "\n",
      "iteration:  16%|█▌        | 19/120 [28:43<2:38:03, 93.89s/it, min_val_loss=1.2, train=1, val=0.811, val_loss=3.05]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  16%|█▌        | 19/120 [30:14<2:38:03, 93.89s/it, min_val_loss=1.2, train=1, val=0.814, val_loss=3.05]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  17%|█▋        | 20/120 [30:14<2:35:17, 93.17s/it, min_val_loss=1.2, train=1, val=0.814, val_loss=3.05]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  17%|█▋        | 20/120 [31:44<2:35:17, 93.17s/it, min_val_loss=1.2, train=1, val=0.834, val_loss=3.02]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  18%|█▊        | 21/120 [31:44<2:32:09, 92.22s/it, min_val_loss=1.2, train=1, val=0.834, val_loss=3.02]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  18%|█▊        | 21/120 [33:18<2:32:09, 92.22s/it, min_val_loss=1.2, train=0.999, val=0.835, val_loss=3.01]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  18%|█▊        | 22/120 [33:18<2:31:33, 92.79s/it, min_val_loss=1.2, train=0.999, val=0.835, val_loss=3.01]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  18%|█▊        | 22/120 [34:58<2:31:33, 92.79s/it, min_val_loss=1.2, train=1, val=0.864, val_loss=3.01]    \u001b[A\u001b[A\n",
      "\n",
      "iteration:  19%|█▉        | 23/120 [34:58<2:33:23, 94.89s/it, min_val_loss=1.2, train=1, val=0.864, val_loss=3.01]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  19%|█▉        | 23/120 [36:33<2:33:23, 94.89s/it, min_val_loss=1.16, train=1, val=0.855, val_loss=3]  \u001b[A\u001b[A\n",
      "\n",
      "iteration:  20%|██        | 24/120 [36:33<2:31:46, 94.86s/it, min_val_loss=1.16, train=1, val=0.855, val_loss=3]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  20%|██        | 24/120 [38:04<2:31:46, 94.86s/it, min_val_loss=1.16, train=1, val=0.852, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  21%|██        | 25/120 [38:04<2:28:13, 93.61s/it, min_val_loss=1.16, train=1, val=0.852, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  21%|██        | 25/120 [39:33<2:28:13, 93.61s/it, min_val_loss=1.16, train=1, val=0.865, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  22%|██▏       | 26/120 [39:33<2:24:31, 92.25s/it, min_val_loss=1.16, train=1, val=0.865, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  22%|██▏       | 26/120 [41:12<2:24:31, 92.25s/it, min_val_loss=1.16, train=1, val=0.873, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  22%|██▎       | 27/120 [41:12<2:26:05, 94.25s/it, min_val_loss=1.16, train=1, val=0.873, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  22%|██▎       | 27/120 [42:44<2:26:05, 94.25s/it, min_val_loss=1.15, train=1, val=0.877, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  23%|██▎       | 28/120 [42:44<2:23:31, 93.61s/it, min_val_loss=1.15, train=1, val=0.877, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  23%|██▎       | 28/120 [44:19<2:23:31, 93.61s/it, min_val_loss=1.14, train=1, val=0.859, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  24%|██▍       | 29/120 [44:19<2:22:39, 94.07s/it, min_val_loss=1.14, train=1, val=0.859, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  24%|██▍       | 29/120 [45:51<2:22:39, 94.07s/it, min_val_loss=1.14, train=1, val=0.865, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  25%|██▌       | 30/120 [45:51<2:20:25, 93.61s/it, min_val_loss=1.14, train=1, val=0.865, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  25%|██▌       | 30/120 [47:21<2:20:25, 93.61s/it, min_val_loss=1.14, train=1, val=0.866, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  26%|██▌       | 31/120 [47:21<2:16:57, 92.33s/it, min_val_loss=1.14, train=1, val=0.866, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  26%|██▌       | 31/120 [48:55<2:16:57, 92.33s/it, min_val_loss=1.14, train=1, val=0.867, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  27%|██▋       | 32/120 [48:55<2:16:22, 92.99s/it, min_val_loss=1.14, train=1, val=0.867, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  27%|██▋       | 32/120 [50:27<2:16:22, 92.99s/it, min_val_loss=1.14, train=1, val=0.852, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  28%|██▊       | 33/120 [50:27<2:14:27, 92.73s/it, min_val_loss=1.14, train=1, val=0.852, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  28%|██▊       | 33/120 [52:01<2:14:27, 92.73s/it, min_val_loss=1.14, train=1, val=0.838, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  28%|██▊       | 34/120 [52:01<2:13:19, 93.02s/it, min_val_loss=1.14, train=1, val=0.838, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  28%|██▊       | 34/120 [53:31<2:13:19, 93.02s/it, min_val_loss=1.14, train=0.999, val=0.87, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  29%|██▉       | 35/120 [53:31<2:10:24, 92.05s/it, min_val_loss=1.14, train=0.999, val=0.87, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  29%|██▉       | 35/120 [55:05<2:10:24, 92.05s/it, min_val_loss=1.14, train=1, val=0.861, val_loss=2.95]   \u001b[A\u001b[A\n",
      "\n",
      "iteration:  30%|███       | 36/120 [55:05<2:09:34, 92.55s/it, min_val_loss=1.14, train=1, val=0.861, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  30%|███       | 36/120 [56:35<2:09:34, 92.55s/it, min_val_loss=1.14, train=1, val=0.799, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  31%|███       | 37/120 [56:35<2:06:56, 91.76s/it, min_val_loss=1.14, train=1, val=0.799, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  31%|███       | 37/120 [58:06<2:06:56, 91.76s/it, min_val_loss=1.14, train=1, val=0.796, val_loss=3.01]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  32%|███▏      | 38/120 [58:06<2:05:10, 91.59s/it, min_val_loss=1.14, train=1, val=0.796, val_loss=3.01]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  32%|███▏      | 38/120 [59:36<2:05:10, 91.59s/it, min_val_loss=1.14, train=1, val=0.858, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  32%|███▎      | 39/120 [59:36<2:03:12, 91.26s/it, min_val_loss=1.14, train=1, val=0.858, val_loss=2.98]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  32%|███▎      | 39/120 [1:01:10<2:03:12, 91.26s/it, min_val_loss=1.14, train=1, val=0.868, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  33%|███▎      | 40/120 [1:01:10<2:02:44, 92.06s/it, min_val_loss=1.14, train=1, val=0.868, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  33%|███▎      | 40/120 [1:02:33<2:02:44, 92.06s/it, min_val_loss=1.14, train=1, val=0.889, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  34%|███▍      | 41/120 [1:02:33<1:57:36, 89.33s/it, min_val_loss=1.14, train=1, val=0.889, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  34%|███▍      | 41/120 [1:04:10<1:57:36, 89.33s/it, min_val_loss=1.13, train=1, val=0.885, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  35%|███▌      | 42/120 [1:04:10<1:59:13, 91.71s/it, min_val_loss=1.13, train=1, val=0.885, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  35%|███▌      | 42/120 [1:05:37<1:59:13, 91.71s/it, min_val_loss=1.13, train=1, val=0.851, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  36%|███▌      | 43/120 [1:05:37<1:55:51, 90.28s/it, min_val_loss=1.13, train=1, val=0.851, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  36%|███▌      | 43/120 [1:07:11<1:55:51, 90.28s/it, min_val_loss=1.13, train=1, val=0.859, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  37%|███▋      | 44/120 [1:07:11<1:55:29, 91.17s/it, min_val_loss=1.13, train=1, val=0.859, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  37%|███▋      | 44/120 [1:08:33<1:55:29, 91.17s/it, min_val_loss=1.13, train=1, val=0.858, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  38%|███▊      | 45/120 [1:08:33<1:50:43, 88.58s/it, min_val_loss=1.13, train=1, val=0.858, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  38%|███▊      | 45/120 [1:10:05<1:50:43, 88.58s/it, min_val_loss=1.13, train=1, val=0.859, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  38%|███▊      | 46/120 [1:10:05<1:50:33, 89.64s/it, min_val_loss=1.13, train=1, val=0.859, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  38%|███▊      | 46/120 [1:11:34<1:50:33, 89.64s/it, min_val_loss=1.13, train=1, val=0.838, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  39%|███▉      | 47/120 [1:11:34<1:48:42, 89.35s/it, min_val_loss=1.13, train=1, val=0.838, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  39%|███▉      | 47/120 [1:13:05<1:48:42, 89.35s/it, min_val_loss=1.13, train=1, val=0.893, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  40%|████      | 48/120 [1:13:05<1:48:01, 90.02s/it, min_val_loss=1.13, train=1, val=0.893, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  40%|████      | 48/120 [1:14:37<1:48:01, 90.02s/it, min_val_loss=1.12, train=1, val=0.893, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  41%|████      | 49/120 [1:14:37<1:47:12, 90.59s/it, min_val_loss=1.12, train=1, val=0.893, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  41%|████      | 49/120 [1:16:14<1:47:12, 90.59s/it, min_val_loss=1.12, train=1, val=0.873, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  42%|████▏     | 50/120 [1:16:14<1:47:50, 92.44s/it, min_val_loss=1.12, train=1, val=0.873, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  42%|████▏     | 50/120 [1:17:44<1:47:50, 92.44s/it, min_val_loss=1.12, train=1, val=0.854, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  42%|████▎     | 51/120 [1:17:44<1:45:20, 91.60s/it, min_val_loss=1.12, train=1, val=0.854, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  42%|████▎     | 51/120 [1:19:18<1:45:20, 91.60s/it, min_val_loss=1.12, train=1, val=0.864, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  43%|████▎     | 52/120 [1:19:18<1:44:35, 92.28s/it, min_val_loss=1.12, train=1, val=0.864, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  43%|████▎     | 52/120 [1:20:46<1:44:35, 92.28s/it, min_val_loss=1.12, train=1, val=0.877, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  44%|████▍     | 53/120 [1:20:46<1:41:51, 91.22s/it, min_val_loss=1.12, train=1, val=0.877, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  44%|████▍     | 53/120 [1:22:22<1:41:51, 91.22s/it, min_val_loss=1.12, train=1, val=0.897, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  45%|████▌     | 54/120 [1:22:22<1:41:48, 92.55s/it, min_val_loss=1.12, train=1, val=0.897, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  45%|████▌     | 54/120 [1:23:55<1:41:48, 92.55s/it, min_val_loss=1.11, train=1, val=0.868, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  46%|████▌     | 55/120 [1:23:55<1:40:28, 92.75s/it, min_val_loss=1.11, train=1, val=0.868, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  46%|████▌     | 55/120 [1:25:30<1:40:28, 92.75s/it, min_val_loss=1.11, train=1, val=0.845, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  47%|████▋     | 56/120 [1:25:30<1:39:33, 93.34s/it, min_val_loss=1.11, train=1, val=0.845, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  47%|████▋     | 56/120 [1:26:57<1:39:33, 93.34s/it, min_val_loss=1.11, train=1, val=0.859, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  48%|████▊     | 57/120 [1:26:57<1:36:05, 91.51s/it, min_val_loss=1.11, train=1, val=0.859, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  48%|████▊     | 57/120 [1:28:25<1:36:05, 91.51s/it, min_val_loss=1.11, train=1, val=0.836, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  48%|████▊     | 58/120 [1:28:25<1:33:25, 90.41s/it, min_val_loss=1.11, train=1, val=0.836, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  48%|████▊     | 58/120 [1:30:00<1:33:25, 90.41s/it, min_val_loss=1.11, train=1, val=0.83, val_loss=2.97] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  49%|████▉     | 59/120 [1:30:00<1:33:24, 91.87s/it, min_val_loss=1.11, train=1, val=0.83, val_loss=2.97]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  49%|████▉     | 59/120 [1:31:28<1:33:24, 91.87s/it, min_val_loss=1.11, train=1, val=0.873, val_loss=2.99]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  50%|█████     | 60/120 [1:31:28<1:30:40, 90.68s/it, min_val_loss=1.11, train=1, val=0.873, val_loss=2.99]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  50%|█████     | 60/120 [1:33:02<1:30:40, 90.68s/it, min_val_loss=1.11, train=1, val=0.84, val_loss=3]    \u001b[A\u001b[A\n",
      "\n",
      "iteration:  51%|█████     | 61/120 [1:33:02<1:30:02, 91.56s/it, min_val_loss=1.11, train=1, val=0.84, val_loss=3]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  51%|█████     | 61/120 [1:34:30<1:30:02, 91.56s/it, min_val_loss=1.11, train=1, val=0.792, val_loss=3]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  52%|█████▏    | 62/120 [1:34:30<1:27:33, 90.57s/it, min_val_loss=1.11, train=1, val=0.792, val_loss=3]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  52%|█████▏    | 62/120 [1:36:03<1:27:33, 90.57s/it, min_val_loss=1.11, train=1, val=0.845, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  52%|█████▎    | 63/120 [1:36:03<1:26:44, 91.31s/it, min_val_loss=1.11, train=1, val=0.845, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  52%|█████▎    | 63/120 [1:37:35<1:26:44, 91.31s/it, min_val_loss=1.11, train=0.999, val=0.848, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  53%|█████▎    | 64/120 [1:37:35<1:25:18, 91.39s/it, min_val_loss=1.11, train=0.999, val=0.848, val_loss=2.96]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  53%|█████▎    | 64/120 [1:39:03<1:25:18, 91.39s/it, min_val_loss=1.11, train=1, val=0.849, val_loss=2.95]    \u001b[A\u001b[A\n",
      "\n",
      "iteration:  54%|█████▍    | 65/120 [1:39:03<1:22:50, 90.38s/it, min_val_loss=1.11, train=1, val=0.849, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  54%|█████▍    | 65/120 [1:40:30<1:22:50, 90.38s/it, min_val_loss=1.11, train=0.999, val=0.832, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  55%|█████▌    | 66/120 [1:40:30<1:20:30, 89.45s/it, min_val_loss=1.11, train=0.999, val=0.832, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  55%|█████▌    | 66/120 [1:41:59<1:20:30, 89.45s/it, min_val_loss=1.11, train=1, val=0.869, val_loss=2.93]    \u001b[A\u001b[A\n",
      "\n",
      "iteration:  56%|█████▌    | 67/120 [1:41:59<1:18:52, 89.30s/it, min_val_loss=1.11, train=1, val=0.869, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  56%|█████▌    | 67/120 [1:43:28<1:18:52, 89.30s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  57%|█████▋    | 68/120 [1:43:28<1:17:22, 89.27s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  57%|█████▋    | 68/120 [1:45:02<1:17:22, 89.27s/it, min_val_loss=1.11, train=1, val=0.867, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  57%|█████▊    | 69/120 [1:45:02<1:16:55, 90.51s/it, min_val_loss=1.11, train=1, val=0.867, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  57%|█████▊    | 69/120 [1:46:27<1:16:55, 90.51s/it, min_val_loss=1.11, train=1, val=0.873, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  58%|█████▊    | 70/120 [1:46:27<1:14:09, 88.99s/it, min_val_loss=1.11, train=1, val=0.873, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  58%|█████▊    | 70/120 [1:47:56<1:14:09, 88.99s/it, min_val_loss=1.11, train=1, val=0.863, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  59%|█████▉    | 71/120 [1:47:56<1:12:33, 88.84s/it, min_val_loss=1.11, train=1, val=0.863, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  59%|█████▉    | 71/120 [1:49:26<1:12:33, 88.84s/it, min_val_loss=1.11, train=1, val=0.858, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  60%|██████    | 72/120 [1:49:26<1:11:21, 89.21s/it, min_val_loss=1.11, train=1, val=0.858, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  60%|██████    | 72/120 [1:50:57<1:11:21, 89.21s/it, min_val_loss=1.11, train=1, val=0.873, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  61%|██████    | 73/120 [1:50:57<1:10:24, 89.89s/it, min_val_loss=1.11, train=1, val=0.873, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  61%|██████    | 73/120 [1:52:28<1:10:24, 89.89s/it, min_val_loss=1.11, train=1, val=0.895, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  62%|██████▏   | 74/120 [1:52:28<1:09:12, 90.27s/it, min_val_loss=1.11, train=1, val=0.895, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  62%|██████▏   | 74/120 [1:54:04<1:09:12, 90.27s/it, min_val_loss=1.11, train=1, val=0.859, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  62%|██████▎   | 75/120 [1:54:04<1:08:51, 91.82s/it, min_val_loss=1.11, train=1, val=0.859, val_loss=2.95]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  62%|██████▎   | 75/120 [1:55:33<1:08:51, 91.82s/it, min_val_loss=1.11, train=1, val=0.872, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  63%|██████▎   | 76/120 [1:55:33<1:06:43, 90.98s/it, min_val_loss=1.11, train=1, val=0.872, val_loss=2.94]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  63%|██████▎   | 76/120 [1:57:06<1:06:43, 90.98s/it, min_val_loss=1.11, train=1, val=0.867, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  64%|██████▍   | 77/120 [1:57:06<1:05:38, 91.59s/it, min_val_loss=1.11, train=1, val=0.867, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  64%|██████▍   | 77/120 [1:58:34<1:05:38, 91.59s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.92] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  65%|██████▌   | 78/120 [1:58:34<1:03:26, 90.64s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  65%|██████▌   | 78/120 [2:00:06<1:03:26, 90.64s/it, min_val_loss=1.11, train=1, val=0.866, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  66%|██████▌   | 79/120 [2:00:06<1:02:06, 90.89s/it, min_val_loss=1.11, train=1, val=0.866, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  66%|██████▌   | 79/120 [2:01:33<1:02:06, 90.89s/it, min_val_loss=1.11, train=1, val=0.86, val_loss=2.93] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  67%|██████▋   | 80/120 [2:01:33<59:48, 89.71s/it, min_val_loss=1.11, train=1, val=0.86, val_loss=2.93]  \u001b[A\u001b[A\n",
      "\n",
      "iteration:  67%|██████▋   | 80/120 [2:03:04<59:48, 89.71s/it, min_val_loss=1.11, train=1, val=0.871, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  68%|██████▊   | 81/120 [2:03:04<58:41, 90.29s/it, min_val_loss=1.11, train=1, val=0.871, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  68%|██████▊   | 81/120 [2:04:31<58:41, 90.29s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.93] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  68%|██████▊   | 82/120 [2:04:31<56:28, 89.17s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  68%|██████▊   | 82/120 [2:06:03<56:28, 89.17s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  69%|██████▉   | 83/120 [2:06:03<55:37, 90.19s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  69%|██████▉   | 83/120 [2:07:32<55:37, 90.19s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  70%|███████   | 84/120 [2:07:32<53:49, 89.70s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  70%|███████   | 84/120 [2:09:03<53:49, 89.70s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  71%|███████   | 85/120 [2:09:03<52:30, 90.00s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  71%|███████   | 85/120 [2:10:31<52:30, 90.00s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  72%|███████▏  | 86/120 [2:10:31<50:39, 89.40s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  72%|███████▏  | 86/120 [2:12:04<50:39, 89.40s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  72%|███████▎  | 87/120 [2:12:04<49:47, 90.53s/it, min_val_loss=1.11, train=1, val=0.864, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  72%|███████▎  | 87/120 [2:13:35<49:47, 90.53s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.91] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  73%|███████▎  | 88/120 [2:13:35<48:22, 90.69s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.91]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  73%|███████▎  | 88/120 [2:15:07<48:22, 90.69s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  74%|███████▍  | 89/120 [2:15:07<47:08, 91.23s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  74%|███████▍  | 89/120 [2:16:35<47:08, 91.23s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  75%|███████▌  | 90/120 [2:16:35<45:02, 90.09s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  75%|███████▌  | 90/120 [2:18:06<45:02, 90.09s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  76%|███████▌  | 91/120 [2:18:06<43:43, 90.47s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  76%|███████▌  | 91/120 [2:19:34<43:43, 90.47s/it, min_val_loss=1.11, train=1, val=0.866, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  77%|███████▋  | 92/120 [2:19:34<41:52, 89.72s/it, min_val_loss=1.11, train=1, val=0.866, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  77%|███████▋  | 92/120 [2:21:05<41:52, 89.72s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.91] \u001b[A\u001b[A\n",
      "\n",
      "iteration:  78%|███████▊  | 93/120 [2:21:05<40:36, 90.23s/it, min_val_loss=1.11, train=1, val=0.87, val_loss=2.91]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  78%|███████▊  | 93/120 [2:22:34<40:36, 90.23s/it, min_val_loss=1.11, train=1, val=0.875, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  78%|███████▊  | 94/120 [2:22:34<38:53, 89.76s/it, min_val_loss=1.11, train=1, val=0.875, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  78%|███████▊  | 94/120 [2:24:07<38:53, 89.76s/it, min_val_loss=1.11, train=1, val=0.882, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  79%|███████▉  | 95/120 [2:24:07<37:44, 90.57s/it, min_val_loss=1.11, train=1, val=0.882, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  79%|███████▉  | 95/120 [2:25:34<37:44, 90.57s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.92]\u001b[A\u001b[A\n",
      "\n",
      "iteration:  80%|████████  | 96/120 [2:25:34<35:53, 89.72s/it, min_val_loss=1.11, train=1, val=0.865, val_loss=2.92]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import trange\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    print('wandb not found')\n",
    "\n",
    "from myhelpers import config_plots, TrialStatistics\n",
    "from myhelpers.try_warning import try_running\n",
    "from HGNN.train import CNN, dataLoader\n",
    "from myhelpers import cifar_dataLoader\n",
    "from HGNN.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "config_plots.global_settings()\n",
    "\n",
    "experimetnsFileName = \"experiments.csv\"\n",
    "WANDB_message=\"wandb not working\"\n",
    "\n",
    "\n",
    "# For logging to server\n",
    "try_running(lambda : wandb.login(), WANDB_message)\n",
    "\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "# set cuda\n",
    "if device is not None:\n",
    "    print(\"using cuda\", device)\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "else:\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# get experiment params\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "\n",
    "# init experiments file\n",
    "experimentsFileNameAndPath = os.path.join(experimentsPath, experimetnsFileName)\n",
    "\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)  \n",
    "experiment_index = 0\n",
    "\n",
    "# Loop through experiments\n",
    "# with progressbar.ProgressBar(max_value=number_of_experiments) as bar:\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for experiment_params in config_parser.getExperiments():\n",
    "        print(experiment_params)\n",
    "        experimentHash =TrialStatistics.getTrialName(experiment_params)\n",
    "\n",
    "        # load images \n",
    "        if experiment_params['image_path'] == 'cifar-100-python':\n",
    "            datasetManager = cifar_dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "        else:\n",
    "            datasetManager = dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "        datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "        train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "        architecture = {\n",
    "            \"fine\": len(train_loader.dataset.csv_processor.getFineList()),\n",
    "            \"coarse\" : len(train_loader.dataset.csv_processor.getCoarseList())\n",
    "        }\n",
    "\n",
    "        # Loop through n trials\n",
    "        for i in trange(experiment_params[\"numOfTrials\"], desc=\"trial\"):\n",
    "            modelName = getModelName(experiment_params, i)\n",
    "            trialName = os.path.join(experimentPathAndName, modelName)\n",
    "            trialHash = TrialStatistics.getTrialName(experiment_params, i)\n",
    "\n",
    "            row_information = {\n",
    "                'experimentName': experimentName,\n",
    "                'modelName': modelName,\n",
    "                'datasetName': getDatasetName(config_parser.fixPaths(experiment_params)),\n",
    "                'experimentHash': experimentHash,\n",
    "                'trialHash': trialHash\n",
    "            }\n",
    "            row_information = {**row_information, **experiment_params} \n",
    "            print(row_information)\n",
    "\n",
    "            run = try_running(lambda : wandb.init(project='HGNN', group=experimentName+\"-\"+experimentHash, name=trialHash, config=row_information), WANDB_message) #, reinit=True\n",
    "\n",
    "            # Train/Load model\n",
    "            model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "            \n",
    "#             from torchsummary import summary\n",
    "\n",
    "#             summary(model, (3, 224, 224))\n",
    "\n",
    "#             try_running(lambda : wandb.watch(model, log=\"all\"), WANDB_message)\n",
    "\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                print(\"Model {0} found!\".format(trialName))\n",
    "            else:\n",
    "                initModelPath = CNN.getInitModelFile(experimentPathAndName)\n",
    "                if os.path.exists(initModelPath):\n",
    "                    model.load_state_dict(torch.load(initModelPath))\n",
    "                    print(\"Init Model {0} found!\".format(initModelPath))\n",
    "                CNN.trainModel(train_loader, validation_loader, experiment_params, model, trialName, test_loader, device=device, detailed_reporting=detailed_reporting)\n",
    "\n",
    "            # Add to experiments file\n",
    "            if os.path.exists(experimentsFileNameAndPath):\n",
    "                experiments_df = pd.read_csv(experimentsFileNameAndPath)\n",
    "            else:\n",
    "                experiments_df = pd.DataFrame()\n",
    "\n",
    "            record_exists = not (experiments_df[experiments_df['modelName'] == modelName][experiments_df['experimentName'] == experimentName]).empty if not experiments_df.empty else False\n",
    "            if record_exists:\n",
    "                experiments_df.drop(experiments_df[experiments_df['modelName'] == modelName][experiments_df['experimentName'] == experimentName].index, inplace = True) \n",
    "\n",
    "            experiments_df = experiments_df.append(pd.DataFrame(row_information, index=[0]), ignore_index = True)\n",
    "            experiments_df.to_csv(experimentsFileNameAndPath, header=True, index=False)\n",
    "\n",
    "            try_running(lambda : run.finish(), WANDB_message)\n",
    "\n",
    "        bar.update()\n",
    "\n",
    "        experiment_index = experiment_index + 1\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     torch.multiprocessing.set_start_method('spawn')\n",
    "    \n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--cuda', required=True, type=int)\n",
    "#     parser.add_argument('--experiments', required=True)\n",
    "#     parser.add_argument('--data', required=True)\n",
    "#     parser.add_argument('--name', required=True)\n",
    "#     parser.add_argument('--detailed', required=False, action='store_true')\n",
    "#     args = parser.parse_args()\n",
    "#     main(experimentName=args.name, experimentsPath=args.experiments, dataPath=args.data, device=args.cuda, detailed_reporting=args.detailed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
