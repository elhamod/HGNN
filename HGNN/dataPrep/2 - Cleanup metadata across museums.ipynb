{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_csv_fileName = \"metadata.csv\"\n",
    "cleaned_fine_csv_fileName = \"cleaned_metadata.csv\"\n",
    "data_root = \"/raid/elhamod/Fish\"\n",
    "destination = \"Curated3/Easy\"\n",
    "sources=[\"cropped2/INHS\", \"cropped2/FMNH\", \"cropped2/JFBM\", \"cropped2/OSUM\", \"cropped2/UWZM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata table headers.\n",
    "fine_csv_fileName_header = \"fileName\"\n",
    "fine_csv_scientificName_header = \"scientificName\"\n",
    "fine_csv_Coarse_header = \"Genus\"\n",
    "fine_csv_Family_header = \"Family\"\n",
    "fine_csv_usedColumns = [fine_csv_fileName_header,\n",
    "                          fine_csv_scientificName_header,\n",
    "                          fine_csv_Coarse_header,\n",
    "                          fine_csv_Family_header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing                            scientificName     Genus         Family\n",
      "fileName                                                          \n",
      "inhs_fish_26586.jpg     Lepomis cyanellus   Lepomis  Centrarchidae\n",
      "inhs_fish_85748.jpg      Lepomis gibbosus   Lepomis  Centrarchidae\n",
      "inhs_fish_50859.jpg       Cyprinus carpio  Cyprinus     Cyprinidae\n",
      "inhs_fish_62239.jpg  Notropis percobromus  Notropis     Cyprinidae\n",
      "inhs_fish_22926.jpg       Morone chrysops    Morone      Moronidae\n"
     ]
    }
   ],
   "source": [
    "# Get destination dataframe uncleaned metadata\n",
    "destination_metadata_fileName_full_path = os.path.join(data_root, destination, fine_csv_fileName)\n",
    "destination_metadata = pd.read_csv(destination_metadata_fileName_full_path, delimiter='\\t', index_col=fine_csv_fileName_header, usecols=fine_csv_usedColumns)\n",
    "\n",
    "destination_cleaned_metadata_final = pd.DataFrame()\n",
    "# For each source\n",
    "for source in sources:\n",
    "    # get metadata\n",
    "    source_metadata_fileName_full_path = os.path.join(data_root, source, cleaned_fine_csv_fileName)\n",
    "    source_metadata = pd.read_csv(source_metadata_fileName_full_path, delimiter='\\t', index_col=fine_csv_fileName_header, usecols=fine_csv_usedColumns)\n",
    "    \n",
    "    #get only interesctsion\n",
    "    destination_metadata['lower'] = destination_metadata.index.str.lower()\n",
    "    source_metadata['lower'] = source_metadata.index.str.lower()\n",
    "    destination_cleaned_metadata = source_metadata.reset_index().merge(destination_metadata, how=\"inner\", on=['lower']).set_index('fileName')\n",
    "    destination_cleaned_metadata = destination_cleaned_metadata[[fine_csv_scientificName_header+\"_x\"\n",
    "                                                                 , fine_csv_Coarse_header+\"_x\"\n",
    "                                                                 , fine_csv_Family_header+\"_x\"]]\n",
    "    destination_cleaned_metadata = destination_cleaned_metadata.rename(columns={fine_csv_scientificName_header+\"_x\": fine_csv_scientificName_header, \n",
    "                                                 fine_csv_Coarse_header+\"_x\": fine_csv_Coarse_header,\n",
    "                                                 fine_csv_Family_header+\"_x\": fine_csv_Family_header})\n",
    "    \n",
    "          \n",
    "    # append it to final metadata\n",
    "    destination_cleaned_metadata_final = pd.concat([destination_cleaned_metadata_final, destination_cleaned_metadata])\n",
    "    \n",
    "# save final metadata\n",
    "destination_cleaned_metadata_final = destination_cleaned_metadata_final.loc[~destination_cleaned_metadata_final.index.duplicated(keep='first')]  \n",
    "destination_cleaned_metadata_final.to_csv(os.path.join(data_root, destination, cleaned_fine_csv_fileName), sep='\\t')\n",
    "\n",
    "\n",
    "#Some code to get unfound images\n",
    "destination_cleaned_metadata_final['lower'] = destination_cleaned_metadata_final.index.str.lower()\n",
    "destination_metadata['lower'] = destination_metadata.index.str.lower()\n",
    "df3 = destination_cleaned_metadata_final.reset_index().merge(destination_metadata, indicator='Exist', how=\"outer\", on=['lower']).set_index('fileName')\n",
    "df3 = df3.loc[df3['Exist'] == 'right_only'][['lower', 'scientificName_y', 'Genus_y', 'Family_y']]\n",
    "df3 = df3.rename(columns={fine_csv_scientificName_header+\"_y\": fine_csv_scientificName_header, \n",
    "                                             fine_csv_Coarse_header+\"_y\": fine_csv_Coarse_header,\n",
    "                                             fine_csv_Family_header+\"_y\": fine_csv_Family_header,\n",
    "                         'lower':'fileName'}).set_index('fileName')\n",
    "print('missing', df3)\n",
    "df3.to_csv(os.path.join(data_root, destination, \"notfound.csv\"), sep='\\t')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
