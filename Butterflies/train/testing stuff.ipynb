{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only way to do it is to launch jupyter this way:\n",
    "\n",
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath = \"/raid/elhamod/CIFAR_HGNN/experiments/\" #\"/raid/elhamod/Fish/experiments/\"\n",
    "dataPath = \"/raid/elhamod/\" #\"/raid/elhamod/Fish/\"\n",
    "experimentName = \"CIFAR_phylogeny_tripletloss_new_archi_full\"\n",
    "i=0\n",
    "device = 0\n",
    "experiment_params = {\"image_path\": \"cifar-100-python\", \"suffix\": None, \"img_res\": 32, \"augmented\": True, \"batchSize\": 64, \"learning_rate\": 0.01, \"numOfTrials\": 2, \"fc_layers\": 1, \"pretrained\": True, \"epochs\": 30, \"patience\": 12, \"optimizer\": \"adabelief\", \"scheduler\": \"cosine\", \"weightdecay\": 0.0005, \"modelType\": \"BB\", \"lambda\": 10, \"tl_model\": \"preResNet\", \"link_layer\": \"avgpool\", \"adaptive_smoothing\": True, \"adaptive_lambda\": 0.1, \"adaptive_alpha\": 0.1, \"tripletEnabled\": True, \"tripletSamples\": 3, \"tripletSelector\": \"semihard\", \"tripletMargin\": 0.3, \"phylogeny_loss\": False, \"displayName\": \"CIFARpretrained4-Triplet-Cos\", \"noSpeciesBackprop\": False, \"phylogeny_loss_epsilon\": 0.03}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# experiment_params = {\"image_path\": \"cifar-100-python\", \"suffix\": None, \"img_res\": 32, \"augmented\": True, \"batchSize\": 64, \"learning_rate\": 0.001, \"numOfTrials\": 1, \"fc_layers\": 1, \"pretrained\": True, \"epochs\": 30, \"patience\": 12, \"optimizer\": \"adabelief\", \"scheduler\": \"plateau\", \"weightdecay\": 0.0005, \"modelType\": \"BB\", \"lambda\": 10, \"tl_model\": \"preResNet\", \"link_layer\": \"avgpool\", \"adaptive_smoothing\": True, \"adaptive_lambda\": 0.1, \"adaptive_alpha\": 0.1, \"tripletEnabled\": False, \"tripletSamples\": 3, \"tripletSelector\": \"semihard\", \"tripletMargin\": 0.2, \"phylogeny_loss\": False, \"displayName\": \"CIFARpretrained4-BB\", \"noSpeciesBackprop\": False, \"phylogeny_loss_epsilon\": 0.03}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from myhelpers import cifar_dataLoader\n",
    "from HGNN.train import CNN\n",
    "from HGNN.train.configParser import getModelName\n",
    "from configParser import ConfigParser, getModelName\n",
    "import os\n",
    "import torch\n",
    "from myhelpers.resnet_cifar2 import cifar100\n",
    "import numpy as np\n",
    "from myhelpers.preresnet_cifar import resnet as preresnet_cifar\n",
    "import random\n",
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# seed_everything(121)\n",
    "\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "experiment_params = config_parser.fixExperimentParams(experiment_params)\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "datasetManager = cifar_dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "\n",
    "train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "architecture = {\n",
    "    \"fine\": len(train_loader.dataset.csv_processor.getFineList()),\n",
    "    \"coarse\" : len(train_loader.dataset.csv_processor.getCoarseList())\n",
    "}\n",
    "\n",
    "# from myhelpers.resnet_cifar import cifar_resnet56\n",
    "\n",
    "# # modelName = getModelName(experiment_params, i)\n",
    "# print(modelName)\n",
    "# modelName = \"models/b07640aa2d0c1aacb31f7bcda75ac772ad8bf53db3dacc06d2280a98\"\n",
    "# trialName = os.path.join(experimentPathAndName, modelName)\n",
    "# # initModelPath = CNN.getInitModelFile(experimentPathAndName)\n",
    "# finalModelPath = CNN.getModelFile(trialName)\n",
    "# model.load_state_dict(torch.load(finalModelPath))\n",
    "\n",
    "# model = cifar_resnet56(pretrained='cifar100')\n",
    "model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "# model = cifar100(128, pretrained=True)\n",
    "# model = preresnet_cifar(dataset='cifar100', inpt_size=32, pretrained=True)\n",
    "# CNN.trainModel(train_loader, validation_loader, experiment_params, model, \"hello\", test_loader, device=device)\n",
    "# print(model)\n",
    "\n",
    "predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params, device=device)\n",
    "predlist, lbllist = CNN.getPredictions(predlist, lbllist)\n",
    "if device is not None:\n",
    "    predlist = predlist.cpu()\n",
    "    lbllist = lbllist.cpu()   \n",
    "print(f1_score(lbllist, predlist, average='macro'))\n",
    "print(f1_score(lbllist, predlist, average='micro'))\n",
    "print(accuracy_score(lbllist, predlist))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     rand_input = torch.rand(2, 3, model.network_fine.img_res, model.network_fine.img_res)\n",
    "#     if model.network_fine.device is not None:\n",
    "#         rand_input = rand_input.cuda()\n",
    "#     out_ = model.network_fine(rand_input)\n",
    "\n",
    "model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "\n",
    "predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params, device=device)\n",
    "predlist, lbllist = CNN.getPredictions(predlist, lbllist)\n",
    "if device is not None:\n",
    "    predlist = predlist.cpu()\n",
    "    lbllist = lbllist.cpu()   \n",
    "print(f1_score(lbllist, predlist, average='macro'))\n",
    "print(f1_score(lbllist, predlist, average='micro'))\n",
    "print(accuracy_score(lbllist, predlist))\n",
    "\n",
    "\n",
    "model = model.network_fine\n",
    "\n",
    "predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params, device=device)\n",
    "predlist, lbllist = CNN.getPredictions(predlist, lbllist)\n",
    "if device is not None:\n",
    "    predlist = predlist.cpu()\n",
    "    lbllist = lbllist.cpu()   \n",
    "print(f1_score(lbllist, predlist, average='macro'))\n",
    "print(f1_score(lbllist, predlist, average='micro'))\n",
    "print(accuracy_score(lbllist, predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_loader))\n",
    "plt.imshow(np.transpose(images['image'][0].cpu().detach().numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "learning_rate = 0.00001\n",
    "scheduler_gamma = 0.1\n",
    "scheduler_patience = 4\n",
    "epochs = 40\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_patience, eta_min=learning_rate*scheduler_gamma)\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(scheduler.get_last_lr())\n",
    "    scheduler.step() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "adaptive_alpha=0.5\n",
    "adaptive_lambda=0.1\n",
    "fine_loss=[torch.tensor(25)]\n",
    "other_losses ={\n",
    "    'layer2': torch.tensor(2),\n",
    "    'layer4': torch.tensor(2)\n",
    "}\n",
    "\n",
    "from myhelpers.adaptive_smoothing import get_lambdas\n",
    "\n",
    "for fine_loss_ in fine_loss:\n",
    "    print(get_lambdas(adaptive_alpha, adaptive_lambda, fine_loss_, other_losses =other_losses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet18()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from HGNN.train import CNN\n",
    "\n",
    "experiment_params = {\"image_path\": \"cifar-100-python\", \n",
    "                     \"suffix\": None, \n",
    "                     \"img_res\": 32,\n",
    "                     \"augmented\": True, \n",
    "                     \"batchSize\": 64,\n",
    "                     \"learning_rate\": 0.01,\n",
    "                     \"numOfTrials\": 2,\n",
    "                     \"fc_layers\": 1, \"pretrained\": True, \"epochs\": 30, \"patience\": 12,\n",
    "                     \"optimizer\": \"adabelief\", \"scheduler\": \"cosine\", \"weightdecay\": 0.0005,\n",
    "                     \"modelType\": \"BB\", \"lambda\": 10, \"tl_model\": \"ResNet18\", \"link_layer\": \"avgpool\", \"adaptive_smoothing\": True, \"adaptive_lambda\": 0.1, \"adaptive_alpha\": 0.1, \"tripletEnabled\": True, \"tripletSamples\": 3, \"tripletSelector\": \"semihard\", \"tripletMargin\": 0.3, \"phylogeny_loss\": False, \"displayName\": \"CIFARpretrained4-Triplet-Cos\", \"noSpeciesBackprop\": False, \"phylogeny_loss_epsilon\": 0.03}\n",
    "\n",
    "architecture = {\n",
    "    \"fine\": 50,\n",
    "    \"coarse\" : None\n",
    "}\n",
    "\n",
    "\n",
    "model = CNN.create_model(architecture, experiment_params)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embeddings = torch.tensor([[4., 3., 0.],[4., 5., 6.]])\n",
    "F.normalize(embeddings, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.tensor([[4.],[4.]])\n",
    "(embeddings-4).eq(torch.zeros_like(embeddings)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import choice\n",
    "\n",
    "a = torch.tensor([[1],[2]])\n",
    "\n",
    "print(torch.FloatTensor(list(map(lambda x : choice([i for i in range(0,3) if i not in [x]]), a))).view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxonomy import Taxonomy\n",
    "from HGNN.train.CSV_processor import CSV_processor\n",
    "\n",
    "fine_csv_scientificName_header = \"scientificName\"\n",
    "fileNameAndPath = \"/raid/elhamod/Fish/Curated4/Easy_30/cleaned_metadata.tre\"\n",
    "data_root = \"/raid/elhamod/Fish/Curated4/Easy_30/\"\n",
    "suffix=\"\"\n",
    "\n",
    "processor = CSV_processor(data_root, suffix, verbose=True)\n",
    "\n",
    "df_nodupes = processor.fine_csv[fine_csv_scientificName_header].drop_duplicates() # Will probably need more processing to deal with small letter...etc\n",
    "node_ids = df_nodupes.tolist()\n",
    "\n",
    "t = Taxonomy(node_ids, fileNameAndPath, verbose=True)\n",
    "\n",
    "# t.get_total_distance()\n",
    "species = node_ids[33]\n",
    "print('species',species)\n",
    "t.get_siblings_by_name(species, 0.5, get_ottids = False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to render the tree beautifully\n",
    "!pip install pyqt5\n",
    "# set flag for rendering\n",
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "import ete3\n",
    "ts = ete3.TreeStyle()\n",
    "ts.show_branch_length=True\n",
    "\n",
    "t.tree.render('%%inline', tree_style=ts)\n",
    "# t.tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "\n",
    "def add(a):\n",
    "    a['1'] = 2\n",
    "    \n",
    "add(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [0,1,2]\n",
    "\n",
    "s[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "sisters_indices = [[1, 2],[3,1,2]]\n",
    "mlb = MultiLabelBinarizer(range(5))\n",
    "mlb.fit_transform(sisters_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "input = torch.randn((2,3), requires_grad=True)\n",
    "target = torch.tensor([[1.,0.,1.],[0.,1.,0.]])\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HGNN.train import CNN\n",
    "\n",
    "architecture\n",
    "model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "CNN.loadModel(model, savedModelName, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('/raid/elhamod/Fish/experiments/Fish30-5run-testPhyloNN/models/9bad7cb5922c83f40dc03a781629256c776a0ad5b44039b9099f47d8/finalModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network[4][1].conv2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phyloDistances=[0.75, 0.5, 0.25]\n",
    "phyloDistances.insert(0, 1)\n",
    "loss_name='1distance'\n",
    "distance_indx = [idx for idx, element in enumerate(phyloDistances) if loss_name == str(element).replace(\".\", \"\")+\"distance\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = phyloDistances[distance_indx]\n",
    "next_distance = phyloDistances[distance_indx+1] if distance_indx<len(phyloDistances)-1 else 0\n",
    "abs_total_dist = 512\n",
    "print('distance_indx', distance_indx, int(next_distance*abs_total_dist), int(distance*abs_total_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phyloDistances[0]*abs_total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permuted\n",
      "torch.Size([5, 15, 3, 3])\n",
      "torch.Size([15, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def deconv_orth_dist(kernel1, kernel2, stride = 2, padding = 1):\n",
    "    assert (kernel1.shape[0] == kernel2.shape[0]) or (kernel1.shape[1] == kernel2.shape[1]) , \"Kernels should be of compatible sizes\" + str(kernel1.shape) + \", \" + str(kernel2.shape)\n",
    "    if kernel1.shape[1] != kernel2.shape[1]:\n",
    "        kernel1 = kernel1.permute(1, 0, 2, 3)\n",
    "        kernel2 = kernel2.permute(1, 0, 2, 3)\n",
    "        print('permuted')\n",
    "    [o_c, i_c, w, h] = kernel1.shape\n",
    "    output = torch.conv2d(kernel1, kernel2, stride=stride, padding=padding)\n",
    "    print(kernel1.shape)\n",
    "#     print(target)\n",
    "#     print(output)\n",
    "    return torch.norm( output )\n",
    "\n",
    "kernel = torch.rand((15,5,3,3)).cuda()\n",
    "kernel2 = torch.rand((15,15,3,3)).cuda()\n",
    "deconv_orth_dist(kernel,kernel2,1, 1)\n",
    "print(kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f076184a2dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 1.0000, 0.3333,\n",
       "        0.3333, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.3333, 1.0000,\n",
       "        0.5000, 0.5000], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myhelpers.imbalanced import inverse_weights_by_labels, get_class_weights\n",
    "import torch\n",
    "\n",
    "dataset = [0,1,1,1,1,1,1,2,5,5,1,1,1,1,1,1,5,3,4,4]\n",
    "\n",
    "weights = inverse_weights_by_labels(dataset) # dataset of 6 samples with these labels. It is the list of targets for all samples\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 17, 14,  8, 16,  0,  9,  9, 17, 17])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(weights, 10, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 0,\n",
       " 19,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 17,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 19,\n",
       " 7,\n",
       " 15,\n",
       " 2,\n",
       " 19,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 17,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 12,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 14,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 19,\n",
       " 16,\n",
       " 7,\n",
       " 7,\n",
       " 14,\n",
       " 18,\n",
       " 9,\n",
       " 0,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 7,\n",
       " 19,\n",
       " 8,\n",
       " 17,\n",
       " 7,\n",
       " 16,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 13,\n",
       " 13,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 16,\n",
       " 0,\n",
       " 4,\n",
       " 17,\n",
       " 18,\n",
       " 17,\n",
       " 9,\n",
       " 15,\n",
       " 18,\n",
       " 7,\n",
       " 14,\n",
       " 17,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 18,\n",
       " 8,\n",
       " 7,\n",
       " 19,\n",
       " 12,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 17,\n",
       " 17,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 16,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 17,\n",
       " 7,\n",
       " 2,\n",
       " 17,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 19,\n",
       " 19,\n",
       " 13,\n",
       " 11,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 18,\n",
       " 19,\n",
       " 16,\n",
       " 9,\n",
       " 17,\n",
       " 18,\n",
       " 7,\n",
       " 17,\n",
       " 19,\n",
       " 1,\n",
       " 17,\n",
       " 18,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 16,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 9,\n",
       " 17,\n",
       " 7,\n",
       " 10,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 17,\n",
       " 18,\n",
       " 6,\n",
       " 19,\n",
       " 17,\n",
       " 0,\n",
       " 17,\n",
       " 17,\n",
       " 0,\n",
       " 7,\n",
       " 18,\n",
       " 7,\n",
       " 10,\n",
       " 19,\n",
       " 0,\n",
       " 0,\n",
       " 19,\n",
       " 19,\n",
       " 8,\n",
       " 17,\n",
       " 7,\n",
       " 8,\n",
       " 18,\n",
       " 17,\n",
       " 13,\n",
       " 7,\n",
       " 8,\n",
       " 18,\n",
       " 9,\n",
       " 15,\n",
       " 5,\n",
       " 15,\n",
       " 16,\n",
       " 3,\n",
       " 19,\n",
       " 10,\n",
       " 17,\n",
       " 17,\n",
       " 1,\n",
       " 19,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 7,\n",
       " 16,\n",
       " 17,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 7,\n",
       " 16,\n",
       " 5,\n",
       " 17,\n",
       " 7,\n",
       " 18,\n",
       " 17,\n",
       " 7,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 17,\n",
       " 0,\n",
       " 7,\n",
       " 17,\n",
       " 19,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 19,\n",
       " 17,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 11,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 17,\n",
       " 1,\n",
       " 17,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 16,\n",
       " 17]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sample_size = 265\n",
    "\n",
    "indices = list(range(sample_size))\n",
    "\n",
    "output = [indices[i] for i in torch.multinomial(weights, sample_size, replacement=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist([dataset[i] for i in output], bins=max(dataset)+1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(output, bins=len(dataset))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"histogram_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-78aff9455446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabel_to_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_to_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: \"histogram_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "# get_class_weights(dataset)\n",
    "import pandas as pd\n",
    "labels = dataset\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"label\"] = labels\n",
    "\n",
    "label_to_count = df[\"label\"].value_counts().sort_index()\n",
    "\n",
    "torch.histc(torch.tensor(label_to_count.values), bins=max(labels)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 12,  1,  1,  2,  3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(label_to_count.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(labels)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 12,  1,  1,  2,  3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_count.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 12,  1,  1,  2,  3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(label_to_count.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 12,  1,  1,  2,  3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_weights(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2553, 0.0213, 0.2553, 0.2553, 0.1277, 0.0851])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myhelpers.imbalanced import inverse_weights_by_labels, get_class_weights\n",
    "import torch\n",
    "\n",
    "dataset = [0,1,1,1,1,1,1,2,5,5,1,1,1,1,1,1,5,3,4,4]\n",
    "\n",
    "weights = get_class_weights(dataset) # dataset of 6 samples with these labels. It is the list of targets for all samples\n",
    "\n",
    "weights/sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.choice(len(weights), p=weights/sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.choice(len(weights), p=weights/sum(weights)) for i in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_logged_fordataimbalance = [1,2] + [2,3]\n",
    "labels_logged_fordataimbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
