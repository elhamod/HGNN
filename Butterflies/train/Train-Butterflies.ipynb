{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath= \"/raid/elhamod/Butterflies2/experiments/\" # \"/raid/elhamod/CIFAR_HGNN/experiments/\"\n",
    "dataPath=\"/raid/elhamod/Butterflies2/Datasets\" #\"/raid/elhamod/Fish\" \"/raid/elhamod/\"\n",
    "experimentName = \"Butterflies_round1_1\" \n",
    "\n",
    "projectName_wandb = 'Butterflies'\n",
    "\n",
    "device = 0\n",
    "detailed_reporting = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmndhamod\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "experiment:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 0\n",
      "{'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 64, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_64', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd370c69db2f46ddaf4a0c8c07bf259d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/4fe35073fb50bbfff99cac9d8fcde0be936515bafeedcf9b990fb6f7', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '54e3be61927e7e3721d482fe2550b14a01929adbaa1039485b8fbd49', 'trialHash': '4fe35073fb50bbfff99cac9d8fcde0be936515bafeedcf9b990fb6f7', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 64, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_64', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">4fe35073fb50bbfff99cac9d8fcde0be936515bafeedcf9b990fb6f7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/10lbjahc\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/10lbjahc</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_185332-10lbjahc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7eb73fef6f48c3b09961f95b596396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:121: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 71085<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_185332-10lbjahc/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_185332-10lbjahc/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>2e-05</td></tr><tr><td>test_fine_f1</td><td>0.84607</td></tr><tr><td>test_fine_acc</td><td>0.86335</td></tr><tr><td>training_fine_acc</td><td>0.80234</td></tr><tr><td>training_fine_f1</td><td>0.76326</td></tr><tr><td>training_loss</td><td>2.17534</td></tr><tr><td>validation_loss</td><td>2.22</td></tr><tr><td>validation_fine_f1</td><td>0.87128</td></tr><tr><td>_runtime</td><td>2369</td></tr><tr><td>_timestamp</td><td>1642638781</td></tr><tr><td>_step</td><td>2142</td></tr><tr><td>loss</td><td>0.03717</td></tr><tr><td>batch</td><td>2039</td></tr><tr><td>loss_fine</td><td>0.03717</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.0</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>██████████▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▅▆███████▇███▇█▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>training_fine_f1</td><td>▁▅▆▇██████▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>training_loss</td><td>█▅▃▂▁▂▂▁▁▁▁▂▂▂▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▅▃▂▁▂▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation_fine_f1</td><td>▁▄▆▇███▇██▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▅▃▂▂▂▁▁▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▄▄▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▅▁▄▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▁▅▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>██▅▃▂▂▂▃▃▂▃▄▆█▅▆▆▁▁▂▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>█████▇▇▆▆▇▅▄▃▂▄▃▃▆▂▄▂▁▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">4fe35073fb50bbfff99cac9d8fcde0be936515bafeedcf9b990fb6f7</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/10lbjahc\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/10lbjahc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/0b61e708d76b31a17454ecc14d145ee75b06d2cf430b22c3fe0cfec0', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '54e3be61927e7e3721d482fe2550b14a01929adbaa1039485b8fbd49', 'trialHash': '0b61e708d76b31a17454ecc14d145ee75b06d2cf430b22c3fe0cfec0', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 64, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_64', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">0b61e708d76b31a17454ecc14d145ee75b06d2cf430b22c3fe0cfec0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/tvozgfp9\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/tvozgfp9</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_193308-tvozgfp9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99806341b7f4e5a8cd0255ca83064b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31066<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_193308-tvozgfp9/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_193308-tvozgfp9/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>2e-05</td></tr><tr><td>test_fine_f1</td><td>0.86504</td></tr><tr><td>test_fine_acc</td><td>0.88509</td></tr><tr><td>training_fine_acc</td><td>0.85686</td></tr><tr><td>training_fine_f1</td><td>0.82044</td></tr><tr><td>training_loss</td><td>2.13161</td></tr><tr><td>validation_loss</td><td>2.16585</td></tr><tr><td>validation_fine_f1</td><td>0.84312</td></tr><tr><td>_runtime</td><td>2368</td></tr><tr><td>_timestamp</td><td>1642641156</td></tr><tr><td>_step</td><td>2142</td></tr><tr><td>loss</td><td>0.03809</td></tr><tr><td>batch</td><td>2039</td></tr><tr><td>loss_fine</td><td>0.03809</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.0</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>█████████▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▅▅████▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇██████████████</td></tr><tr><td>training_fine_f1</td><td>▁▄▆█▇██▇▇▇▇▇▇▇▇▇▇▇█████▇█▇████▇▇▇███████</td></tr><tr><td>training_loss</td><td>█▅▃▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▅▄▂▂▁▁▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▄▅█▇██▇███▇▇██▇▇▇██████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▃▃▃▂▁▁▂▂▁▂▂▂▃▂▁▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▄▃▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▆▁▁▂▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▁▁▂▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▅▅▃▂▂▂▂▂▂▃▄▂▄▄▃█▄▁▇▃▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████▆▅▆▄▃▅▂▃▃▂▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">0b61e708d76b31a17454ecc14d145ee75b06d2cf430b22c3fe0cfec0</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/tvozgfp9\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/tvozgfp9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/d307fb528de4951694271ccf7ebae3e21184ac38c1a50493e8d506c9', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '54e3be61927e7e3721d482fe2550b14a01929adbaa1039485b8fbd49', 'trialHash': 'd307fb528de4951694271ccf7ebae3e21184ac38c1a50493e8d506c9', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 64, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_64', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">d307fb528de4951694271ccf7ebae3e21184ac38c1a50493e8d506c9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/3od8vdev\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/3od8vdev</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_201242-3od8vdev</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac7bb0b178649d69951b691779951cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 61739<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_201242-3od8vdev/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_201242-3od8vdev/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>3e-05</td></tr><tr><td>test_fine_f1</td><td>0.82613</td></tr><tr><td>test_fine_acc</td><td>0.85093</td></tr><tr><td>training_fine_acc</td><td>0.82473</td></tr><tr><td>training_fine_f1</td><td>0.80292</td></tr><tr><td>training_loss</td><td>2.20018</td></tr><tr><td>validation_loss</td><td>2.23854</td></tr><tr><td>validation_fine_f1</td><td>0.87111</td></tr><tr><td>_runtime</td><td>2399</td></tr><tr><td>_timestamp</td><td>1642643561</td></tr><tr><td>_step</td><td>2142</td></tr><tr><td>loss</td><td>0.02743</td></tr><tr><td>batch</td><td>2039</td></tr><tr><td>loss_fine</td><td>0.02743</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.0</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>██████████████▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▅▇██████▇█▄▇▇▇▇▇▇▇▇▇▇▇█▇███████████▇▇█▇</td></tr><tr><td>training_fine_f1</td><td>▁▅▇██████▇█▄█▇▇▇▇▇▇▇▇▇▇█▇████████████▇█▇</td></tr><tr><td>training_loss</td><td>█▅▂▂▁▁▁▁▁▂▂▄▂▃▂▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation_loss</td><td>█▅▂▂▁▂▁▁▁▂▂▅▂▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation_fine_f1</td><td>▁▄▇▇▇▇███▇█▄▇▇▇▇▇▇▇▇▇▇▇█▇██▇██▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▄▃▂▁▁▁▁▂▂▂▂▂▂▂▃▂▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▄▃▅▄▂▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▃▁▂▁▂▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▁▃▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▅▅▃▃▂▂▂▂▂▂▂▁▃▂▄▄▄▇▄▆█▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████▇▇▆▆▇█▄▆▃▃▃▂▃▂▂▂▂▅▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">d307fb528de4951694271ccf7ebae3e21184ac38c1a50493e8d506c9</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/3od8vdev\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/3od8vdev</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  20%|██        | 1/5 [1:59:17<7:57:08, 7157.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 264, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_264', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c88325e7e34bcca9320d4c77f397be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/1a0399f548781277f92444488f4b7463a71fa57fe01cdd596d7df25c', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '4a0e39af4f060f2f574e151cef05ad796bf1ee4cdfb57874b792a579', 'trialHash': '1a0399f548781277f92444488f4b7463a71fa57fe01cdd596d7df25c', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 264, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_264', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">1a0399f548781277f92444488f4b7463a71fa57fe01cdd596d7df25c</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/bgl2tjy2\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/bgl2tjy2</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_205249-bgl2tjy2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af7bcba3c2249dfacdb450bc49db652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32359<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_205249-bgl2tjy2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_205249-bgl2tjy2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.0005</td></tr><tr><td>test_fine_f1</td><td>0.96834</td></tr><tr><td>test_fine_acc</td><td>0.96273</td></tr><tr><td>training_fine_acc</td><td>0.92308</td></tr><tr><td>training_fine_f1</td><td>0.92848</td></tr><tr><td>training_loss</td><td>1.91629</td></tr><tr><td>validation_loss</td><td>1.97215</td></tr><tr><td>validation_fine_f1</td><td>0.97038</td></tr><tr><td>_runtime</td><td>1674</td></tr><tr><td>_timestamp</td><td>1642645243</td></tr><tr><td>_step</td><td>595</td></tr><tr><td>loss</td><td>0.42232</td></tr><tr><td>batch</td><td>479</td></tr><tr><td>loss_fine</td><td>0.00513</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.41719</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>279</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▃▅▇▇█▇█▇███████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▅▆▇█▇█████████████████████████████████</td></tr><tr><td>training_loss</td><td>██▆▄▃▃▂▂▂▂▁▁▁▁▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▇▆▄▃▃▃▂▂▂▂▂▂▁▁▂▁▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▄▆▇▇▇█▇██████▇█████████████████▇██████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▃▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▂▂▂▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▆▆▆▅▄▃▃▁▃▂▁▁▁▁▁▁▂▄▁▁▂▂▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██████▅█▆▁▁▁▁▁▁▁▁▁▂▄▁▁▄▄▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>██▇▇▇▅▄▄▃▂▁▁▁▁▂▁▁▂▁▂▁▄▂▂▄▃▄▃▄▃▄▄▄▂▄▅▅▆▄▃</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>█████████████▇▇▇▆▆█▇▆▆▇▆▂▂▃▃▂▅▂▃▃▄▅▂▁▁▂▅</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">1a0399f548781277f92444488f4b7463a71fa57fe01cdd596d7df25c</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/bgl2tjy2\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/bgl2tjy2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/b5ac8faf99b3fbf924d6207d75c7174da205c6eed9ece304b812ed4d', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '4a0e39af4f060f2f574e151cef05ad796bf1ee4cdfb57874b792a579', 'trialHash': 'b5ac8faf99b3fbf924d6207d75c7174da205c6eed9ece304b812ed4d', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 264, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_264', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">b5ac8faf99b3fbf924d6207d75c7174da205c6eed9ece304b812ed4d</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/399ag9u6\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/399ag9u6</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_212053-399ag9u6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1314aa19deae43a99c2c810fb36faf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 59127<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_212053-399ag9u6/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_212053-399ag9u6/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.00025</td></tr><tr><td>test_fine_f1</td><td>0.9666</td></tr><tr><td>test_fine_acc</td><td>0.96584</td></tr><tr><td>training_fine_acc</td><td>0.99513</td></tr><tr><td>training_fine_f1</td><td>0.99594</td></tr><tr><td>training_loss</td><td>1.86122</td></tr><tr><td>validation_loss</td><td>1.91724</td></tr><tr><td>validation_fine_f1</td><td>0.98048</td></tr><tr><td>_runtime</td><td>1625</td></tr><tr><td>_timestamp</td><td>1642646878</td></tr><tr><td>_step</td><td>595</td></tr><tr><td>loss</td><td>0.01996</td></tr><tr><td>batch</td><td>479</td></tr><tr><td>loss_fine</td><td>0.01197</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.00799</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>147</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>████████████████▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▃▅▇▇▇█▇▇▇███▇█▇▇█▇▇██████▇█████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▅▆▇▇█▇█▇█████▇▇█▇▇██████▇█████████████</td></tr><tr><td>training_loss</td><td>██▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▄▆▇▇▇▇█▇███▇▇▇███▇██████▇█████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▅▅▄▄▃▃▂▃▁▁▂▁▂▁▁▁▁▂▁▁▁▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▆▆▇▆▄▅▂▄▁▁▄▂▂▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██████▇▅▅▆▁▁▄▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▇▇▇▇▇▅▅▅▅▃▂▂▂▂▂▂▃▃▄▃▃▃▄▅▄▃▄▄▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>█████████████▇█▇▇▇▅▃▅▄▃▃▂▂▅▂▃▄▇▅▄▅▂▁▅▄▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">b5ac8faf99b3fbf924d6207d75c7174da205c6eed9ece304b812ed4d</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/399ag9u6\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/399ag9u6</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/117f8de7909ad6e643945970c60c9be24a23a17c6c47388885017493', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '4a0e39af4f060f2f574e151cef05ad796bf1ee4cdfb57874b792a579', 'trialHash': '117f8de7909ad6e643945970c60c9be24a23a17c6c47388885017493', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 264, 'learning_rate': 0.001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'batch_264', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">117f8de7909ad6e643945970c60c9be24a23a17c6c47388885017493</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/329wjecx\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/329wjecx</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_214808-329wjecx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a6c1ede92c4cceaf367e0587994398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9609<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_214808-329wjecx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_214808-329wjecx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.00013</td></tr><tr><td>test_fine_f1</td><td>0.97175</td></tr><tr><td>test_fine_acc</td><td>0.96584</td></tr><tr><td>training_fine_acc</td><td>0.99513</td></tr><tr><td>training_fine_f1</td><td>0.996</td></tr><tr><td>training_loss</td><td>1.8744</td></tr><tr><td>validation_loss</td><td>1.94309</td></tr><tr><td>validation_fine_f1</td><td>0.9732</td></tr><tr><td>_runtime</td><td>1621</td></tr><tr><td>_timestamp</td><td>1642648509</td></tr><tr><td>_step</td><td>595</td></tr><tr><td>loss</td><td>0.0688</td></tr><tr><td>batch</td><td>479</td></tr><tr><td>loss_fine</td><td>0.01125</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.05755</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>122</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▃▅▇▇▇▇█▇▇▇███████▇█████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▃▅▇▇███▇▇████████▇███████▇█████████████</td></tr><tr><td>training_loss</td><td>██▆▄▄▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▅▆▇▇▇▇▇▇▇█▇████▇▇██████████▇██████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▂▂▂▁▂▁▁▁▁▂▂▁▁▁▁▂▂▁▁▃▁▂▁▁▂▂▂▂▂▃▂▂▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▇▆▇▆▃▂▁▂▁▃▁▂▁▁▃▃▁▁▁▁▂▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█████▇▃▁▁▁▅▁▁▁▁▆▅▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▆▆▇▅▆▄▅▃▃▂▂▂▁▂▂▂▂▂▂▂▃▂▄▃▂▄▂▃▂▃▅▅▅▃▅█▄▅▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>█████████████▇█▇█▆▇▆▄▆▃▅▆▃▆▄▅▅▂▂▂▄▂▁▂▂▆▂</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">117f8de7909ad6e643945970c60c9be24a23a17c6c47388885017493</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/329wjecx\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/329wjecx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  40%|████      | 2/5 [3:21:47<5:24:45, 6495.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.1, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.1', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8f403694ff4538b65616564bdf2531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/8c9b7bffaf24625ad5533e7f2de489bc9d82871c043cf2d285136090', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '1ab1a8c16101651a801123747338ad88029d37f068e8ac063bbf8fd9', 'trialHash': '8c9b7bffaf24625ad5533e7f2de489bc9d82871c043cf2d285136090', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.1, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.1', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">8c9b7bffaf24625ad5533e7f2de489bc9d82871c043cf2d285136090</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/18mbolcl\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/18mbolcl</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_221519-18mbolcl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153e80861de748bbad3da0c5f308f9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32084<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_221519-18mbolcl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_221519-18mbolcl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.05</td></tr><tr><td>test_fine_f1</td><td>0.35439</td></tr><tr><td>test_fine_acc</td><td>0.38199</td></tr><tr><td>training_fine_acc</td><td>0.34567</td></tr><tr><td>training_fine_f1</td><td>0.28052</td></tr><tr><td>training_loss</td><td>2.46123</td></tr><tr><td>validation_loss</td><td>2.49703</td></tr><tr><td>validation_fine_f1</td><td>0.39161</td></tr><tr><td>_runtime</td><td>1815</td></tr><tr><td>_timestamp</td><td>1642650334</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>1.69313</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.00568</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.69648</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>103</td></tr><tr><td>loss_layer4</td><td>0.99097</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>391</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████████████████████████▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▂▂▁▂▁▃▂▂▄▄▄▅▅▃▅▅▆▃▇▇▇▇▇█▇▇█▆█▇▇▇▇▇▇█▆▇▇</td></tr><tr><td>training_fine_f1</td><td>▁▁▁▁▂▁▂▂▂▃▄▃▃▄▂▃▄▅▂▇▇▇▆▇█▇██▅██▇▇▇▇▇█▆█▇</td></tr><tr><td>training_loss</td><td>▇█▇▇▇▇▇▇▆▇▆▅▅▄▆▄▃▃▅▃▂▂▂▂▁▂▁▁▃▂▂▁▂▂▂▂▁▂▁▂</td></tr><tr><td>validation_loss</td><td>▇█▇▇▇▇▇▇▆▆▅▅▄▄▆▄▃▃▅▃▂▂▂▂▁▂▁▁▃▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation_fine_f1</td><td>▁▁▁▁▂▁▂▁▂▃▄▃▄▄▂▄▄▅▃▇██▇██▇█▇▅█▇▇▆█▇▆█▇█▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▆▆▅▄▅▆▅▅▄▄▄▃▄▃▂▃▃▃▂▂▃▂▂▂▂▂▂▃▁▂▂▂▁▂▂▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>██▆▆▅▃▆▆▅▄▄▄▃▃▄▁▁▂▃▂▂▁▂▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▇▆▆▆▆▆▆▆▆▆▅▆▅▅▅▄▆▃▅▂▃▄▄▃▂▂▃▂▂▁▂▄▅▁▅▁▂▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██████████████▇▆▅▆█▆▅▅▅█▅▁▂▆▄▂▁▅▄▆▁▅▃▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▇▄▄▄▄▃▄▇▄▄▄▂▂▂▃▂▄▁▂▃▄▄▄▂▃▃▃▂▁▂▄▃▃▃▁▄▂▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>▇▇▇████▇████████▇█████▅█▆██▇▇█▇▆▇▇██▃▆▄▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">8c9b7bffaf24625ad5533e7f2de489bc9d82871c043cf2d285136090</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/18mbolcl\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/18mbolcl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/a5f4a68e1ec6ca52f766fd4db305714ba21bf928d1ff5bd2dd9a1f99', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '1ab1a8c16101651a801123747338ad88029d37f068e8ac063bbf8fd9', 'trialHash': 'a5f4a68e1ec6ca52f766fd4db305714ba21bf928d1ff5bd2dd9a1f99', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.1, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.1', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">a5f4a68e1ec6ca52f766fd4db305714ba21bf928d1ff5bd2dd9a1f99</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1x7p242w\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1x7p242w</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_224542-1x7p242w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec55b9d19c6740428fb7ef616eee124c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 57875<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_224542-1x7p242w/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_224542-1x7p242w/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.05</td></tr><tr><td>test_fine_f1</td><td>0.52508</td></tr><tr><td>test_fine_acc</td><td>0.54037</td></tr><tr><td>training_fine_acc</td><td>0.60565</td></tr><tr><td>training_fine_f1</td><td>0.58156</td></tr><tr><td>training_loss</td><td>2.26857</td></tr><tr><td>validation_loss</td><td>2.34037</td></tr><tr><td>validation_fine_f1</td><td>0.52442</td></tr><tr><td>_runtime</td><td>1787</td></tr><tr><td>_timestamp</td><td>1642652129</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>1.24173</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.00148</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>1.24025</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>310</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▂▁▁▂▂▂▃▂▃▃▄▃▅▄▄▅▆▆▆▄▆▆▆▆▇▇▇▇█▇█▇▇██▇████</td></tr><tr><td>training_fine_f1</td><td>▁▁▁▁▂▂▃▂▃▃▃▃▄▄▄▅▆▅▆▄▆▅▆▆▇▇▇▇▇▇▇▇▇▇█▆▇█▇█</td></tr><tr><td>training_loss</td><td>▇█▇▇▇▇▇▇▆▇▆▆▅▅▅▄▃▃▃▅▃▄▂▃▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▇█▇▇▇▇▆▇▆▇▆▆▅▅▅▄▃▃▃▄▃▄▂▃▂▂▂▂▂▁▁▁▁▁▁▂▁▁▂▁</td></tr><tr><td>validation_fine_f1</td><td>▁▁▁▁▂▁▂▂▃▂▃▃▄▄▅▆▆▅▇▄▅▅▇▆▇▇▇▇█▇▇▇▇▇█▇██▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▅▅▅▃▄▅▄▃▄▄▄▃▂▂▁▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▅▅▅▂▅▅▄▃▄▃▄▃▂▃▁▄▃▃▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▇▆▆▆▅▅▄▃▄▅▄▂▃▃▃▄▄▃▃▄▄▃▃▂▃▄▂▃▂▂▁▁▃▂▂▇▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>███████████▅█▇██▇▅▇▇▆█▆▆▅▂▄▄▃▆▁▂▁▁▅▄▁▅▁▁</td></tr><tr><td>loss_layer4</td><td>█▇▆▄▃▅▃▄▃▃▃▂▄▃▃▁▁▃▂▂▃▂▃▃▅▇▇▆▅▃▂▄▂▂▃▂▁▁▃▂</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>▇▇██████████████████▆▇█▆▅▄▃▃▄▇▇▅▅▆▄▇▁▄▄▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">a5f4a68e1ec6ca52f766fd4db305714ba21bf928d1ff5bd2dd9a1f99</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1x7p242w\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1x7p242w</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/3bf8b6c5d11d3f477b794e7a42a43a47401359f3fafaf03419995d51', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '1ab1a8c16101651a801123747338ad88029d37f068e8ac063bbf8fd9', 'trialHash': '3bf8b6c5d11d3f477b794e7a42a43a47401359f3fafaf03419995d51', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.1, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.1', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">3bf8b6c5d11d3f477b794e7a42a43a47401359f3fafaf03419995d51</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/22ghcqu8\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/22ghcqu8</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_231537-22ghcqu8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb03e64f10d148c59326a88e076e6e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11141<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_231537-22ghcqu8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_231537-22ghcqu8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.025</td></tr><tr><td>test_fine_f1</td><td>0.45058</td></tr><tr><td>test_fine_acc</td><td>0.47516</td></tr><tr><td>training_fine_acc</td><td>0.49075</td></tr><tr><td>training_fine_f1</td><td>0.48313</td></tr><tr><td>training_loss</td><td>2.33134</td></tr><tr><td>validation_loss</td><td>2.38745</td></tr><tr><td>validation_fine_f1</td><td>0.45854</td></tr><tr><td>_runtime</td><td>1771</td></tr><tr><td>_timestamp</td><td>1642653908</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.29899</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.00458</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.29442</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>402</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>█████████████████████████▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▂▁▁▂▃▄▂▅▆▆▅▅▆▅▇▇▄▅▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇███▇▇▇</td></tr><tr><td>training_fine_f1</td><td>▁▁▁▁▂▂▃▂▅▅▅▃▅▅▅▅▇▄▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇████▇█</td></tr><tr><td>training_loss</td><td>▇▇█▇▇▆▆▇▄▄▄▄▄▃▄▂▂▄▄▄▂▂▂▂▃▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▇▇█▇▇▆▆▇▄▃▄▄▄▃▄▂▂▄▃▄▂▂▂▂▃▂▁▁▁▂▁▁▂▁▁▁▁▁▂▁</td></tr><tr><td>validation_fine_f1</td><td>▁▁▁▂▂▃▃▂▅▆▆▃▅▆▅▆▇▄▅▆▆▆▇▇▆▆▇█▇▇█▇▇▇▇██▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▄▄▂▄▄▃▄▃▃▂▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▃▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▄▄▄▃▁▃▄▂▃▂▂▂▁▁▁▁▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▇▆▆▆▅▆▅▅▅▅▄▄▄▃▃▃▄▂▃▂▂▂▂▃▄▁▂▁▃▂▁▂▇▁▁▁▁▁▂</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██████████▆▇█▆▆▇██▂▇▂▆▅█▅▆▁▁▁▄▅▁▁▅▁▁▁▁▁▂</td></tr><tr><td>loss_layer4</td><td>█▇▅▅▄▄▄▄▅▄▄▄▅▅▅▅▄▃▄▄▅▅▅▆▆▆▆▅▄▄▄▄▃▄▂▃▂▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>████████████████████████▇▆▆█▇▇▅▆▆▂▅▄▅▄▁▄</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">3bf8b6c5d11d3f477b794e7a42a43a47401359f3fafaf03419995d51</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/22ghcqu8\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/22ghcqu8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  60%|██████    | 3/5 [4:51:43<3:25:30, 6165.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.01, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.01', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b597b9357ed24b6cbc78db93fa2fe28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/4fd0b5337682c2728e535a1e67269277ea66750bca25585f5687ffa6', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '2a82eaf14db68052ac15fdebb303d8553646a4b8c49dbe1e8931e8de', 'trialHash': '4fd0b5337682c2728e535a1e67269277ea66750bca25585f5687ffa6', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.01, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.01', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">4fd0b5337682c2728e535a1e67269277ea66750bca25585f5687ffa6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2nsodhzl\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2nsodhzl</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_234515-2nsodhzl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91c3ace869541c9b93387b7cf85a69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36717<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_234515-2nsodhzl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220119_234515-2nsodhzl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.00016</td></tr><tr><td>test_fine_f1</td><td>0.45244</td></tr><tr><td>test_fine_acc</td><td>0.50621</td></tr><tr><td>training_fine_acc</td><td>0.36709</td></tr><tr><td>training_fine_f1</td><td>0.28417</td></tr><tr><td>training_loss</td><td>2.43109</td></tr><tr><td>validation_loss</td><td>2.4537</td></tr><tr><td>validation_fine_f1</td><td>0.47983</td></tr><tr><td>_runtime</td><td>1750</td></tr><tr><td>_timestamp</td><td>1642655666</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.38815</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.00614</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.38202</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>345</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>█████████████▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▅▆▇▇█▅▇▇▃█▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆</td></tr><tr><td>training_fine_f1</td><td>▁▄▆▇██▅██▂█▇▆▇▆▇▇▇█▇▆▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅</td></tr><tr><td>training_loss</td><td>█▄▄▃▂▂▄▃▃▆▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃</td></tr><tr><td>validation_loss</td><td>█▄▄▃▂▂▄▃▃▆▂▂▂▁▂▁▁▂▂▂▂▂▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>validation_fine_f1</td><td>▁▄▅▆▇█▅██▃█▇▇▇▆▇▇▇█▇▆▇▇▇▆▆▆▇▆▆▆▆▆▆▆▆▅▆▆▆</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▃▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▅▂▂▂▂▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▄▃▂▁▁▁▁▁▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▆▅▅▂▅▄▅▁▂▄▂▁▄▄▂▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█████▂█▆▄▁▁▅▂▁▄▅▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▅▄▃▃▄▅▄▃▄▂▄▅▅▇▇▄▇█▇▇▄▄▃▅██▆▂▁▃▂▂▁▂▁▂▁▂▂▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>███████████▇█▅▆▇▄▄▅▄▇▅▅▅▁▁▃▇▇▅▆▅▇▅▇▅▅▆▅▄</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">4fd0b5337682c2728e535a1e67269277ea66750bca25585f5687ffa6</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2nsodhzl\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2nsodhzl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/9d459c622b684809cbba0c523d9a14d96c9a326ac9c861eb1a887148', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '2a82eaf14db68052ac15fdebb303d8553646a4b8c49dbe1e8931e8de', 'trialHash': '9d459c622b684809cbba0c523d9a14d96c9a326ac9c861eb1a887148', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.01, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.01', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">9d459c622b684809cbba0c523d9a14d96c9a326ac9c861eb1a887148</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/ubavekgn\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/ubavekgn</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_001435-ubavekgn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46afe2704ce34c34bf8fdbccdb07b229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 62256<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_001435-ubavekgn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_001435-ubavekgn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.00031</td></tr><tr><td>test_fine_f1</td><td>0.41309</td></tr><tr><td>test_fine_acc</td><td>0.52795</td></tr><tr><td>training_fine_acc</td><td>0.42356</td></tr><tr><td>training_fine_f1</td><td>0.37768</td></tr><tr><td>training_loss</td><td>2.45463</td></tr><tr><td>validation_loss</td><td>2.48124</td></tr><tr><td>validation_fine_f1</td><td>0.46172</td></tr><tr><td>_runtime</td><td>1736</td></tr><tr><td>_timestamp</td><td>1642657411</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.40958</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.00554</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.40404</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>280</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>████████████▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▃▅▅▆▃█▇▇▇▇▆▇▆▇▆▇▇▇▇▇▇▇▇██▇▇▆▆▅▅▅▅▅▅▅▅▆▆</td></tr><tr><td>training_fine_f1</td><td>▁▃▄▆▆▃█▇▇▆█▆▇▆▇▆▆▇▇▇▇▇▆▆████▆▆▅▅▅▅▅▅▅▆▇▇</td></tr><tr><td>training_loss</td><td>█▆▄▃▂▅▁▁▁▂▁▃▂▂▁▂▂▂▁▂▁▂▂▂▁▁▁▂▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>validation_loss</td><td>█▆▄▃▃▅▁▁▁▂▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▃▃▃▃▃▃▃▃▃▃▄▃</td></tr><tr><td>validation_fine_f1</td><td>▁▃▄▆▆▃█▇▇▆▇▆▆▆▇▆▆▆▇▇▇▇▆▆██▇▇▇▆▅▅▅▅▅▅▅▆▆▆</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▄▃▃▄▄▄▃▃▃▃▄▃▃▃▂▃▃▃▃▄▂▂▁▂▂▂▂▂▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▅▅▄▆▅▄▂▄▄▂▄▅▂▁▁▁▁▁▂▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>████▇█▅▅▃▅▅▁▁▅▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▇▅▄▄▄▄▆▆▅▅▅▆▇▅▅▇▆▇█▇█▆▄▆▂▃▅▄▄▄▂▂▂▃▄▃▄▄▄▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████████▇█▆▇▇▆▆▅▄▄▄▇█▆█▇▅▅▄▄▆▅▄▄▃▄▁▂▁▆</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">9d459c622b684809cbba0c523d9a14d96c9a326ac9c861eb1a887148</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/ubavekgn\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/ubavekgn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/e88852e1e97151057bf5408bacae05ffae8511b17f95de17c85c6ec7', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '2a82eaf14db68052ac15fdebb303d8553646a4b8c49dbe1e8931e8de', 'trialHash': 'e88852e1e97151057bf5408bacae05ffae8511b17f95de17c85c6ec7', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.01, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.01', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">e88852e1e97151057bf5408bacae05ffae8511b17f95de17c85c6ec7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/33bafhqj\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/33bafhqj</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_004339-33bafhqj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fc3f7319ce47edb6d0db568dabe317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15096<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_004339-33bafhqj/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_004339-33bafhqj/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.00031</td></tr><tr><td>test_fine_f1</td><td>0.46566</td></tr><tr><td>test_fine_acc</td><td>0.54658</td></tr><tr><td>training_fine_acc</td><td>0.40993</td></tr><tr><td>training_fine_f1</td><td>0.32536</td></tr><tr><td>training_loss</td><td>2.44639</td></tr><tr><td>validation_loss</td><td>2.47938</td></tr><tr><td>validation_fine_f1</td><td>0.45136</td></tr><tr><td>_runtime</td><td>1738</td></tr><tr><td>_timestamp</td><td>1642659158</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.55598</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.00445</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.55152</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>247</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>██████████████▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▄▆▂▆█▄▆█▆▇▇▇▇▆▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▅▆▆▆</td></tr><tr><td>training_fine_f1</td><td>▁▄▆▁▆█▄▆█▆▇▇▇▇▅▆▅▇▇▆▆▆▆▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▆</td></tr><tr><td>training_loss</td><td>█▅▃▇▄▁▄▂▁▃▁▂▁▂▂▂▂▂▁▂▂▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂</td></tr><tr><td>validation_loss</td><td>█▅▃▇▃▁▄▂▁▃▁▂▁▂▂▂▂▂▁▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>validation_fine_f1</td><td>▁▃▆▂▆█▄▆█▇█▆▇▇▆▆▆▇▆▆▆▆▆▇▆▇▇▆▆▆▆▆▅▅▆▆▆▆▆▅</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▃▃▄▂▂▃▂▂▂▂▃▃▃▃▃▂▃▂▁▁▂▃▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▄▃▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▆▅▄▄▂▂▅▂▂▂▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>███▆▇█▂▇▄▅▁▂▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▆▅▃▂▃▆▂▄▄▄▅▂▅▅▇█▇▆▆▇▅▁▃▄█▆▃▃▂▄▄▃▂▁▁▁▂▁▁▂</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████████▇█▆█▄▄▅▅▅▅▅▇▅▇▁▃▃▄▄▃▂▄▅▄▄▄▁▁▄▂</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">e88852e1e97151057bf5408bacae05ffae8511b17f95de17c85c6ec7</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/33bafhqj\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/33bafhqj</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  80%|████████  | 4/5 [6:19:13<1:38:10, 5890.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.0001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.0001', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5613f6ba15454779a61f9da25c58d39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/18b02ee11a9dcb5f3432d47ab705ce02bfc6828bdb117490b0f9f5b1', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '2ffb212a811aec7852174289c21a7661cca207248972b020c73772be', 'trialHash': '18b02ee11a9dcb5f3432d47ab705ce02bfc6828bdb117490b0f9f5b1', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.0001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.0001', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">18b02ee11a9dcb5f3432d47ab705ce02bfc6828bdb117490b0f9f5b1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2ncglxp7\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2ncglxp7</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_011246-2ncglxp7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb835e8190d42fbb78482e4ef1a81b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40073<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_011246-2ncglxp7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_011246-2ncglxp7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>5e-05</td></tr><tr><td>test_fine_f1</td><td>0.96008</td></tr><tr><td>test_fine_acc</td><td>0.95652</td></tr><tr><td>training_fine_acc</td><td>1.0</td></tr><tr><td>training_fine_f1</td><td>1.0</td></tr><tr><td>training_loss</td><td>1.96089</td></tr><tr><td>validation_loss</td><td>2.01848</td></tr><tr><td>validation_fine_f1</td><td>0.97037</td></tr><tr><td>_runtime</td><td>1785</td></tr><tr><td>_timestamp</td><td>1642660951</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.13082</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.11096</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.01986</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>103</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████████████████████████▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▁▃▄▅▆▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▁▂▄▅▆▆▆▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>training_loss</td><td>███▇▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>███▇▇▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▁▂▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▅▆▅▄▃▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▆▆▆▅▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▂█▂▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▃▅▂▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>██▇▅▆▆▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>███████████████▇█▇▇█▆▆▆▆▆▆▅▃▄▂▂▃▅▄▄▃▃▁▃▂</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">18b02ee11a9dcb5f3432d47ab705ce02bfc6828bdb117490b0f9f5b1</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2ncglxp7\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2ncglxp7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/be071d98ffe4a074798327a054eb58d16ba8b6a07234a8ff62c13d4b', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '2ffb212a811aec7852174289c21a7661cca207248972b020c73772be', 'trialHash': 'be071d98ffe4a074798327a054eb58d16ba8b6a07234a8ff62c13d4b', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.0001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.0001', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">be071d98ffe4a074798327a054eb58d16ba8b6a07234a8ff62c13d4b</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/3v9hf5e8\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/3v9hf5e8</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_014239-3v9hf5e8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d7bfa523104dcd9bf76be53c563118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 65420<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_014239-3v9hf5e8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_014239-3v9hf5e8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>5e-05</td></tr><tr><td>test_fine_f1</td><td>0.95324</td></tr><tr><td>test_fine_acc</td><td>0.95031</td></tr><tr><td>training_fine_acc</td><td>1.0</td></tr><tr><td>training_fine_f1</td><td>1.0</td></tr><tr><td>training_loss</td><td>1.94256</td></tr><tr><td>validation_loss</td><td>2.01593</td></tr><tr><td>validation_fine_f1</td><td>0.96063</td></tr><tr><td>_runtime</td><td>1802</td></tr><tr><td>_timestamp</td><td>1642662761</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.1123</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.09465</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.01764</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>81</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>██████████████████████████████████▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▁▂▄▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▁▂▄▅▅▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>training_loss</td><td>███▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>███▇▇▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▁▂▃▄▅▅▆▆▇▇▇▇▇▇█▇███████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▅▅▆▆▃▄▃▂▃▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>▇█▅▅▆█▃▄▃▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▇▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▇▅▂▃▁▁▄▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>██▇▆▇▆▅▅▄▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>███████████████████▇▆▆▆▆▆▆▅▅▅▅▄▄▁▃▃▁▂▁▂▄</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">be071d98ffe4a074798327a054eb58d16ba8b6a07234a8ff62c13d4b</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/3v9hf5e8\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/3v9hf5e8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round1_1', 'modelName': 'models/d47f35087be8bb334531b1a33740e1fab1d94efee6670713410e63a7', 'datasetName': 'datasplits/20f0713aa829f297aa689b1adefc4e7fe8a5024c8ffa1ae514fc5a6b', 'experimentHash': '2ffb212a811aec7852174289c21a7661cca207248972b020c73772be', 'trialHash': 'd47f35087be8bb334531b1a33740e1fab1d94efee6670713410e63a7', 'image_path': 'LowResolution', 'suffix': 'preprocessed', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'batchSize': 128, 'learning_rate': 0.0001, 'numOfTrials': 3, 'fc_layers': 1, 'pretrained': True, 'epochs': 120, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'lr0.0001', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">d47f35087be8bb334531b1a33740e1fab1d94efee6670713410e63a7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1cib1zqn\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1cib1zqn</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_021248-1cib1zqn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e8645f05764c00aefff72f2f4d4034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=120.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18688<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_021248-1cib1zqn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220120_021248-1cib1zqn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>119</td></tr><tr><td>learning rate</td><td>0.0001</td></tr><tr><td>test_fine_f1</td><td>0.95096</td></tr><tr><td>test_fine_acc</td><td>0.9472</td></tr><tr><td>training_fine_acc</td><td>1.0</td></tr><tr><td>training_fine_f1</td><td>1.0</td></tr><tr><td>training_loss</td><td>1.96462</td></tr><tr><td>validation_loss</td><td>2.03142</td></tr><tr><td>validation_fine_f1</td><td>0.9679</td></tr><tr><td>_runtime</td><td>1821</td></tr><tr><td>_timestamp</td><td>1642664589</td></tr><tr><td>_step</td><td>1190</td></tr><tr><td>loss</td><td>0.09319</td></tr><tr><td>batch</td><td>1079</td></tr><tr><td>loss_fine</td><td>0.08607</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.00712</td></tr><tr><td>lambda_layer4</td><td>1</td></tr><tr><td>nonzerotriplets_layer4</td><td>243</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▁▂▃▄▅▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▁▂▃▄▅▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>training_loss</td><td>███▇▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>███▇▇▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▁▂▂▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▅▆▅▄▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▅█▆▅▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>██▄▁▁▁▂▁▄▁▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>▇█▇▆▆▆▅▄▅▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████████████████▇▇▇▇▆▆▄▆▄▄▅▅▄▃▃▃▃▃▂▁▂▂</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">d47f35087be8bb334531b1a33740e1fab1d94efee6670713410e63a7</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1cib1zqn\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1cib1zqn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment: 100%|██████████| 5/5 [7:49:44<00:00, 5636.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import trange\n",
    "import wandb\n",
    "from torchsummary import summary\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    print('wandb not found')\n",
    "\n",
    "from myhelpers import config_plots, TrialStatistics\n",
    "from myhelpers.try_warning import try_running\n",
    "from Butterflies.train import CNN, dataLoader\n",
    "from myhelpers import cifar_dataLoader\n",
    "from Butterflies.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "config_plots.global_settings()\n",
    "from myhelpers.seeding import seed, get_seed_from_trialNumber\n",
    "\n",
    "experimetnsFileName = \"experiments.csv\"\n",
    "WANDB_message=\"wandb not working\"\n",
    "\n",
    "\n",
    "# For logging to server\n",
    "try_running(lambda : wandb.login(), WANDB_message)\n",
    "\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "# set cuda\n",
    "if device is not None:\n",
    "    print(\"using cuda\", device)\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "else:\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# get experiment params\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "\n",
    "# init experiments file\n",
    "experimentsFileNameAndPath = os.path.join(experimentsPath, experimetnsFileName)\n",
    "\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)  \n",
    "experiment_index = 0\n",
    "\n",
    "# Loop through experiments\n",
    "# with progressbar.ProgressBar(max_value=number_of_experiments) as bar:\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for experiment_params in config_parser.getExperiments():\n",
    "        print(experiment_params)\n",
    "        experimentHash =TrialStatistics.getTrialName(experiment_params)\n",
    "\n",
    "        # load images \n",
    "        if experiment_params['image_path'] == 'cifar-100-python':\n",
    "            datasetManager = cifar_dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "        else:\n",
    "            datasetManager = dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "        datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "\n",
    "        # Loop through n trials\n",
    "        for i in trange(experiment_params[\"numOfTrials\"], desc=\"trial\"):\n",
    "            # We need to set the seed so that whenever exactly the same model params are used, we get same results.\n",
    "            # SEED_INT = get_seed_from_Hex(trialHash)\n",
    "\n",
    "            # We want the seed to only be dependent on trial number \n",
    "            SEED_INT = get_seed_from_trialNumber(i)\n",
    "            if detailed_reporting:\n",
    "                print(\"used seed: \", SEED_INT)\n",
    "            seed(SEED_INT)\n",
    "    \n",
    "            train_loader, validation_loader, test_loader = datasetManager.getLoaders(SEED_INT)\n",
    "            architecture = CNN.get_architecture(experiment_params, train_loader.dataset.csv_processor)\n",
    "            \n",
    "            modelName = getModelName(experiment_params, i)\n",
    "            trialName = os.path.join(experimentPathAndName, modelName)\n",
    "            trialHash = TrialStatistics.getTrialName(experiment_params, i)\n",
    "\n",
    "            row_information = {\n",
    "                'experimentName': experimentName,\n",
    "                'modelName': modelName,\n",
    "                'datasetName': getDatasetName(config_parser.fixPaths(experiment_params)),\n",
    "                'experimentHash': experimentHash,\n",
    "                'trialHash': trialHash\n",
    "            }\n",
    "            row_information = {**row_information, **experiment_params} \n",
    "            print(row_information)\n",
    "\n",
    "            run = try_running(lambda : wandb.init(project=projectName_wandb, group=experimentName+\"-\"+experimentHash, name=trialHash, config=row_information), WANDB_message) #, reinit=True\n",
    "\n",
    "            # Train/Load model\n",
    "            model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "\n",
    "            if detailed_reporting:\n",
    "                print(model)\n",
    "                summary(model, (3, 448, 448))\n",
    "                try_running(lambda : wandb.watch(model, log=\"all\"), WANDB_message)\n",
    "\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                print(\"Model {0} found!\".format(trialName))\n",
    "            else:\n",
    "                initModelPath = CNN.getInitModelFile(experimentPathAndName)\n",
    "                if os.path.exists(initModelPath):\n",
    "                    model.load_state_dict(torch.load(initModelPath))\n",
    "                    print(\"Init Model {0} found!\".format(initModelPath))\n",
    "                CNN.trainModel(train_loader, validation_loader, experiment_params, model, trialName, test_loader, device=device, detailed_reporting=detailed_reporting)\n",
    "\n",
    "            # Add to experiments file\n",
    "            if os.path.exists(experimentsFileNameAndPath):\n",
    "                experiments_df = pd.read_csv(experimentsFileNameAndPath)\n",
    "            else:\n",
    "                experiments_df = pd.DataFrame()\n",
    "\n",
    "            record_exists = not (experiments_df[experiments_df['modelName'] == modelName][experiments_df['experimentName'] == experimentName]).empty if not experiments_df.empty else False\n",
    "            if record_exists:\n",
    "                experiments_df.drop(experiments_df[experiments_df['modelName'] == modelName][experiments_df['experimentName'] == experimentName].index, inplace = True) \n",
    "\n",
    "            experiments_df = experiments_df.append(pd.DataFrame(row_information, index=[0]), ignore_index = True)\n",
    "            experiments_df.to_csv(experimentsFileNameAndPath, header=True, index=False)\n",
    "\n",
    "            try_running(lambda : run.finish(), WANDB_message)\n",
    "\n",
    "        bar.update()\n",
    "\n",
    "        experiment_index = experiment_index + 1\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     torch.multiprocessing.set_start_method('spawn')\n",
    "    \n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--cuda', required=True, type=int)\n",
    "#     parser.add_argument('--experiments', required=True)\n",
    "#     parser.add_argument('--data', required=True)\n",
    "#     parser.add_argument('--name', required=True)\n",
    "#     parser.add_argument('--detailed', required=False, action='store_true')\n",
    "#     args = parser.parse_args()\n",
    "#     main(experimentName=args.name, experimentsPath=args.experiments, dataPath=args.data, device=args.cuda, detailed_reporting=args.detailed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
