{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath= \"/raid/elhamod/Butterflies2/experiments/\" # \"/raid/elhamod/CIFAR_HGNN/experiments/\"\n",
    "dataPath=\"/raid/elhamod/Butterflies2/Datasets\" #\"/raid/elhamod/Fish\" \"/raid/elhamod/\"\n",
    "experimentName = \"Butterflies_round3_sampling0\" \n",
    "\n",
    "projectName_wandb = 'Butterflies'\n",
    "\n",
    "device = 0\n",
    "detailed_reporting = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmndhamod\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "experiment:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 0\n",
      "{'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': False, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'no_sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a93a2c7bb914f5ab73b801f0e6cb133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/f5e7415646ba90108111ae6b24592e705fcf8bf79c94e69be03a63e3', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': 'c7e4c18f09ebaa904bf61682f8811fa7308a90e1e75b12e165dfeea1', 'trialHash': 'f5e7415646ba90108111ae6b24592e705fcf8bf79c94e69be03a63e3', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': False, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'no_sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">f5e7415646ba90108111ae6b24592e705fcf8bf79c94e69be03a63e3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/5gf2a6cw\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/5gf2a6cw</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_155228-5gf2a6cw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b2c6f46ad444f692b965ccdf765fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhamod/melhamodenv3/lib/python3.6/site-packages/ipykernel_launcher.py:121: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27335<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_155228-5gf2a6cw/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_155228-5gf2a6cw/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.6405</td></tr><tr><td>test_fine_acc</td><td>0.83333</td></tr><tr><td>training_fine_acc</td><td>0.95102</td></tr><tr><td>training_fine_f1</td><td>0.88219</td></tr><tr><td>training_loss</td><td>2.79373</td></tr><tr><td>validation_loss</td><td>2.93038</td></tr><tr><td>validation_fine_f1</td><td>0.64749</td></tr><tr><td>_runtime</td><td>8871</td></tr><tr><td>_timestamp</td><td>1643325619</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.08383</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.06574</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.18088</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>967</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▂▅▆▇▇██████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▃▅▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>training_loss</td><td>██▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▃▄▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▃▅▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▅▃▅▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▃▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▄▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▄▃▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████████████████▇▅████████▇████▇█▄█▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">f5e7415646ba90108111ae6b24592e705fcf8bf79c94e69be03a63e3</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/5gf2a6cw\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/5gf2a6cw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/81e56daf4226e7a57e9f91eb30b5af69f7bc8ba9afcaa864a6663aa0', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': 'c7e4c18f09ebaa904bf61682f8811fa7308a90e1e75b12e165dfeea1', 'trialHash': '81e56daf4226e7a57e9f91eb30b5af69f7bc8ba9afcaa864a6663aa0', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': False, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'no_sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">81e56daf4226e7a57e9f91eb30b5af69f7bc8ba9afcaa864a6663aa0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2t6wg2sq\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2t6wg2sq</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_182030-2t6wg2sq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1732bb0c7e3410597ea850b3bdddf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 65473<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_182030-2t6wg2sq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_182030-2t6wg2sq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.65297</td></tr><tr><td>test_fine_acc</td><td>0.84146</td></tr><tr><td>training_fine_acc</td><td>0.96756</td></tr><tr><td>training_fine_f1</td><td>0.92231</td></tr><tr><td>training_loss</td><td>2.73648</td></tr><tr><td>validation_loss</td><td>2.87882</td></tr><tr><td>validation_fine_f1</td><td>0.71985</td></tr><tr><td>_runtime</td><td>8899</td></tr><tr><td>_timestamp</td><td>1643334529</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.04331</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.02915</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.14158</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>879</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████████████▄▄▄▄▄▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▃▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▃▄▅▆▇▇▇▇▇████▇████████████████████████</td></tr><tr><td>training_loss</td><td>██▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▃▄▅▆▆▇▇▇▇▇▇█▇▇████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▃▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▄▃▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▂▄▂▁▁▁▁▁▁▁▁▂▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▅▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>████████████████████████▇▇▇█▇▆▆▆▅▁▅▆▅▆▃▅</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">81e56daf4226e7a57e9f91eb30b5af69f7bc8ba9afcaa864a6663aa0</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2t6wg2sq\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2t6wg2sq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/2dcf33d1898d4d8d350bf93ba2b32c428e776898766f814aa1fe169f', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': 'c7e4c18f09ebaa904bf61682f8811fa7308a90e1e75b12e165dfeea1', 'trialHash': '2dcf33d1898d4d8d350bf93ba2b32c428e776898766f814aa1fe169f', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': False, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'no_sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">2dcf33d1898d4d8d350bf93ba2b32c428e776898766f814aa1fe169f</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1edqzjf3\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1edqzjf3</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_204901-1edqzjf3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd79c55a564c49e0837cdd9db73b7dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29242<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_204901-1edqzjf3/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_204901-1edqzjf3/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.63987</td></tr><tr><td>test_fine_acc</td><td>0.82317</td></tr><tr><td>training_fine_acc</td><td>0.95929</td></tr><tr><td>training_fine_f1</td><td>0.88369</td></tr><tr><td>training_loss</td><td>2.8257</td></tr><tr><td>validation_loss</td><td>2.96286</td></tr><tr><td>validation_fine_f1</td><td>0.687</td></tr><tr><td>_runtime</td><td>8902</td></tr><tr><td>_timestamp</td><td>1643343443</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.08019</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.05615</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.24044</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>958</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>██████████████▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▃▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▃▅▆▆▇▇▇███████████████████████████████</td></tr><tr><td>training_loss</td><td>██▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▃▅▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▄▃▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▅▃▅▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▃▂▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>█████████████████████████████▇██▁██▃▂▂█▇</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">2dcf33d1898d4d8d350bf93ba2b32c428e776898766f814aa1fe169f</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1edqzjf3\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1edqzjf3</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/b6e073f38a852d559385b5f21ac85a303d5f327f592a380de01ac765', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': 'c7e4c18f09ebaa904bf61682f8811fa7308a90e1e75b12e165dfeea1', 'trialHash': 'b6e073f38a852d559385b5f21ac85a303d5f327f592a380de01ac765', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': False, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'no_sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">b6e073f38a852d559385b5f21ac85a303d5f327f592a380de01ac765</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/14qyxkjy\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/14qyxkjy</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_231734-14qyxkjy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd6c423740144c3b9dda6884c022cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 64561<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_231734-14qyxkjy/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220127_231734-14qyxkjy/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.65955</td></tr><tr><td>test_fine_acc</td><td>0.8252</td></tr><tr><td>training_fine_acc</td><td>0.96819</td></tr><tr><td>training_fine_f1</td><td>0.91973</td></tr><tr><td>training_loss</td><td>2.76993</td></tr><tr><td>validation_loss</td><td>2.90688</td></tr><tr><td>validation_fine_f1</td><td>0.72489</td></tr><tr><td>_runtime</td><td>8965</td></tr><tr><td>_timestamp</td><td>1643352419</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.03582</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.02556</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.10262</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>905</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>█████████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▂▅▆▇▇▇▇████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▃▄▅▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>training_loss</td><td>██▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▁▃▄▅▆▆▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▃▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▄▃▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▄▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▇▄▄▄▃▃▂▂▂▂▂▂▁▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>██████████████████████████████▇█▇▅▁▅▂▅▄▄</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">b6e073f38a852d559385b5f21ac85a303d5f327f592a380de01ac765</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/14qyxkjy\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/14qyxkjy</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/5651a8dba05268d7ff709d1e92d330bc701f6bbd91c5c646f584335a', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': 'c7e4c18f09ebaa904bf61682f8811fa7308a90e1e75b12e165dfeea1', 'trialHash': '5651a8dba05268d7ff709d1e92d330bc701f6bbd91c5c646f584335a', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': False, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'no_sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">5651a8dba05268d7ff709d1e92d330bc701f6bbd91c5c646f584335a</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/3inq9dw6\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/3inq9dw6</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_014710-3inq9dw6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f69598993643329609e4de47e995fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:01:05.641693, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27508<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_014710-3inq9dw6/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_014710-3inq9dw6/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.65244</td></tr><tr><td>test_fine_acc</td><td>0.83537</td></tr><tr><td>training_fine_acc</td><td>0.9612</td></tr><tr><td>training_fine_f1</td><td>0.90078</td></tr><tr><td>training_loss</td><td>2.82493</td></tr><tr><td>validation_loss</td><td>2.95342</td></tr><tr><td>validation_fine_f1</td><td>0.70288</td></tr><tr><td>_runtime</td><td>9147</td></tr><tr><td>_timestamp</td><td>1643361577</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.08081</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.05645</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.24352</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>961</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████████▄▄▄▄▄▄▄▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▂▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▂▃▅▆▆▇▇▇▇▇█████████████████████████████</td></tr><tr><td>training_loss</td><td>██▆▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▄▅▅▆▆▇█▇▇▇██████▇████▇████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▅▃▅▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▇▅▃▅▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▂▂▂▂</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>█████████████████▁██▃██████▄▇▇▇▁███▆▅▆▆▇</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">5651a8dba05268d7ff709d1e92d330bc701f6bbd91c5c646f584335a</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/3inq9dw6\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/3inq9dw6</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment:  50%|█████     | 1/2 [12:27:19<12:27:19, 44839.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': True, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013ddfb3d67d4abdbc9bd698f81c97be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='trial', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Creating datasets... Done.\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/18d488f1216277601e503a23dd6a30fa98cf7ae2e844a7b46a09bd7e', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': '32418e537914bf49a686f2c690391c74c725011990e33ec089930950', 'trialHash': '18d488f1216277601e503a23dd6a30fa98cf7ae2e844a7b46a09bd7e', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': True, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">18d488f1216277601e503a23dd6a30fa98cf7ae2e844a7b46a09bd7e</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2hdjq5ec\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2hdjq5ec</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_041948-2hdjq5ec</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7718e65fba8949c6accc932cd5d580d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6593<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_041948-2hdjq5ec/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_041948-2hdjq5ec/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.82365</td></tr><tr><td>test_fine_acc</td><td>0.9065</td></tr><tr><td>training_fine_acc</td><td>0.99936</td></tr><tr><td>training_fine_f1</td><td>0.99938</td></tr><tr><td>training_loss</td><td>2.61048</td></tr><tr><td>validation_loss</td><td>2.74291</td></tr><tr><td>validation_fine_f1</td><td>0.8214</td></tr><tr><td>_runtime</td><td>9105</td></tr><tr><td>_timestamp</td><td>1643370693</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.02357</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.01646</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.07116</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>967</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>█████████▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_loss</td><td>██▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▃▆▇█▇▇███████████▇█████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▅▂▂▂▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▇▂▄▃▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>▁███████████████████████████████████████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">18d488f1216277601e503a23dd6a30fa98cf7ae2e844a7b46a09bd7e</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2hdjq5ec\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2hdjq5ec</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/91114fad414d0098ba7480f85c9b36df7028517f29e6637851e726fd', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': '32418e537914bf49a686f2c690391c74c725011990e33ec089930950', 'trialHash': '91114fad414d0098ba7480f85c9b36df7028517f29e6637851e726fd', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': True, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">91114fad414d0098ba7480f85c9b36df7028517f29e6637851e726fd</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2xpvky1e\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2xpvky1e</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_065144-2xpvky1e</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f825b81a146f4f3da165ad2987bb9015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 53174<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_065144-2xpvky1e/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_065144-2xpvky1e/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.81029</td></tr><tr><td>test_fine_acc</td><td>0.9065</td></tr><tr><td>training_fine_acc</td><td>1.0</td></tr><tr><td>training_fine_f1</td><td>1.0</td></tr><tr><td>training_loss</td><td>2.61329</td></tr><tr><td>validation_loss</td><td>2.74797</td></tr><tr><td>validation_fine_f1</td><td>0.82656</td></tr><tr><td>_runtime</td><td>9097</td></tr><tr><td>_timestamp</td><td>1643379801</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.02675</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.0164</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.10346</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>967</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>███████▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_loss</td><td>██▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▃▆▇████████████████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▇▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">91114fad414d0098ba7480f85c9b36df7028517f29e6637851e726fd</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/2xpvky1e\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/2xpvky1e</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/452a5f2c5750e8d01de5a463d450f364466dbe3f9e0b9680d500fd7b', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': '32418e537914bf49a686f2c690391c74c725011990e33ec089930950', 'trialHash': '452a5f2c5750e8d01de5a463d450f364466dbe3f9e0b9680d500fd7b', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': True, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">452a5f2c5750e8d01de5a463d450f364466dbe3f9e0b9680d500fd7b</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/6svwwglk\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/6svwwglk</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_092333-6svwwglk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f72dc7ded7403f9911c2b714493164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26075<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_092333-6svwwglk/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_092333-6svwwglk/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.81494</td></tr><tr><td>test_fine_acc</td><td>0.90447</td></tr><tr><td>training_fine_acc</td><td>1.0</td></tr><tr><td>training_fine_f1</td><td>1.0</td></tr><tr><td>training_loss</td><td>2.61021</td></tr><tr><td>validation_loss</td><td>2.75158</td></tr><tr><td>validation_fine_f1</td><td>0.79427</td></tr><tr><td>_runtime</td><td>9058</td></tr><tr><td>_timestamp</td><td>1643388871</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.02201</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.01194</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.1007</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>967</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>█████████▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_loss</td><td>██▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▃▆█████████████████████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▇▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">452a5f2c5750e8d01de5a463d450f364466dbe3f9e0b9680d500fd7b</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/6svwwglk\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/6svwwglk</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/55ea49327773c88453a1a024ba129f598ce08dffbec2f5fabb1b44b5', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': '32418e537914bf49a686f2c690391c74c725011990e33ec089930950', 'trialHash': '55ea49327773c88453a1a024ba129f598ce08dffbec2f5fabb1b44b5', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': True, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">55ea49327773c88453a1a024ba129f598ce08dffbec2f5fabb1b44b5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/394vq4gx\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/394vq4gx</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_115442-394vq4gx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0972129fe7954dbcab530c33451bfb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17994<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_115442-394vq4gx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_115442-394vq4gx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>299</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>test_fine_f1</td><td>0.81551</td></tr><tr><td>test_fine_acc</td><td>0.90854</td></tr><tr><td>training_fine_acc</td><td>1.0</td></tr><tr><td>training_fine_f1</td><td>1.0</td></tr><tr><td>training_loss</td><td>2.60735</td></tr><tr><td>validation_loss</td><td>2.7317</td></tr><tr><td>validation_fine_f1</td><td>0.84759</td></tr><tr><td>_runtime</td><td>8949</td></tr><tr><td>_timestamp</td><td>1643397831</td></tr><tr><td>_step</td><td>2691</td></tr><tr><td>loss</td><td>0.01921</td></tr><tr><td>batch</td><td>2099</td></tr><tr><td>loss_fine</td><td>0.01611</td></tr><tr><td>lambda_fine</td><td>1</td></tr><tr><td>loss_layer2</td><td>0.0</td></tr><tr><td>lambda_layer2</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer2</td><td>1</td></tr><tr><td>loss_layer4</td><td>0.031</td></tr><tr><td>lambda_layer4</td><td>0.1</td></tr><tr><td>nonzerotriplets_layer4</td><td>967</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning rate</td><td>████████████▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_fine_acc</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_fine_f1</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>training_loss</td><td>█▇▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>██▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_fine_f1</td><td>▁▂▆▇██████████████▇█████▇███████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_fine</td><td>█▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_fine</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer2</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer2</td><td>█▅▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_layer4</td><td>█▆▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lambda_layer4</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzerotriplets_layer4</td><td>███████████████████████████▃██▁████▆████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">55ea49327773c88453a1a024ba129f598ce08dffbec2f5fabb1b44b5</strong>: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/394vq4gx\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/394vq4gx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders...\n",
      "Creating loaders... Done.\n",
      "{'experimentName': 'Butterflies_round3_sampling0', 'modelName': 'models/bdd4d6015de35acf450cce2b3c9d1d563d309a274025130434447577', 'datasetName': 'datasplits/a917eb2e4fc6c9750425ae03015bfd42c8ef7f1ac3fa49191683e3b7', 'experimentHash': '32418e537914bf49a686f2c690391c74c725011990e33ec089930950', 'trialHash': 'bdd4d6015de35acf450cce2b3c9d1d563d309a274025130434447577', 'image_path': 'LowResolution', 'suffix': 'full', 'useCrossValidation': False, 'img_res': 224, 'augmented': True, 'useImbalancedSampling': True, 'batchSize': 256, 'learning_rate': 0.0001, 'numOfTrials': 5, 'fc_layers': 1, 'pretrained': True, 'epochs': 300, 'patience': -1, 'optimizer': 'adabelief', 'scheduler': 'plateau', 'weightdecay': 0.01, 'scheduler_gamma': 0.5, 'scheduler_patience': 15, 'modelType': 'BB', 'lambda': 0.1, 'two_phase_lambda': False, 'tl_model': 'ResNet18', 'link_layer': 'avgpool', 'adaptive_smoothing': False, 'adaptive_lambda': 0.1, 'adaptive_alpha': 0.5, 'tripletEnabled': True, 'regularTripletLoss': False, 'tripletSamples': 8, 'tripletSelector': 'semihard', 'tripletMargin': 2, 'triplet_layers_dic': 'layer2,layer4', 'L1reg': False, 'phylogeny_loss': False, 'grayscale': False, 'tl_extralayer': False, 'random_fitting': False, 'phyloDistances': '0.75,0.5,0.25', 'addKernelOrthogonality': False, 'displayName': 'sampling hier-triplet', 'noSpeciesBackprop': False, 'phylogeny_loss_epsilon': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bdd4d6015de35acf450cce2b3c9d1d563d309a274025130434447577</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mndhamod/Butterflies\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mndhamod/Butterflies/runs/1ekn1ax9\" target=\"_blank\">https://wandb.ai/mndhamod/Butterflies/runs/1ekn1ax9</a><br/>\n",
       "                Run data is saved locally in <code>/home/elhamod/projects/phyloNNbutterflies/phyloNNbutterflies/Butterflies/train/wandb/run-20220128_142402-1ekn1ax9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166e4b052c4c49f995946c0cd78fd178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='iteration', max=300.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import trange\n",
    "import wandb\n",
    "from torchsummary import summary\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    print('wandb not found')\n",
    "\n",
    "from myhelpers import config_plots, TrialStatistics\n",
    "from myhelpers.try_warning import try_running\n",
    "from Butterflies.train import CNN, dataLoader\n",
    "from myhelpers import cifar_dataLoader\n",
    "from Butterflies.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "config_plots.global_settings()\n",
    "from myhelpers.seeding import seed, get_seed_from_trialNumber\n",
    "\n",
    "experimetnsFileName = \"experiments.csv\"\n",
    "WANDB_message=\"wandb not working\"\n",
    "\n",
    "\n",
    "# For logging to server\n",
    "try_running(lambda : wandb.login(), WANDB_message)\n",
    "\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "# set cuda\n",
    "if device is not None:\n",
    "    print(\"using cuda\", device)\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "else:\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# get experiment params\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "\n",
    "# init experiments file\n",
    "experimentsFileNameAndPath = os.path.join(experimentsPath, experimetnsFileName)\n",
    "\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)  \n",
    "experiment_index = 0\n",
    "\n",
    "# Loop through experiments\n",
    "# with progressbar.ProgressBar(max_value=number_of_experiments) as bar:\n",
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for experiment_params in config_parser.getExperiments():\n",
    "        print(experiment_params)\n",
    "        experimentHash =TrialStatistics.getTrialName(experiment_params)\n",
    "\n",
    "        # load images \n",
    "        if experiment_params['image_path'] == 'cifar-100-python':\n",
    "            datasetManager = cifar_dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "        else:\n",
    "            datasetManager = dataLoader.datasetManager(experimentPathAndName, dataPath)\n",
    "        datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "\n",
    "        # Loop through n trials\n",
    "        for i in trange(experiment_params[\"numOfTrials\"], desc=\"trial\"):\n",
    "            # We need to set the seed so that whenever exactly the same model params are used, we get same results.\n",
    "            # SEED_INT = get_seed_from_Hex(trialHash)\n",
    "\n",
    "            # We want the seed to only be dependent on trial number \n",
    "            SEED_INT = get_seed_from_trialNumber(i)\n",
    "            if detailed_reporting:\n",
    "                print(\"used seed: \", SEED_INT)\n",
    "            seed(SEED_INT)\n",
    "    \n",
    "            train_loader, validation_loader, test_loader = datasetManager.getLoaders(SEED_INT)\n",
    "            architecture = CNN.get_architecture(experiment_params, train_loader.dataset.csv_processor)\n",
    "            \n",
    "            modelName = getModelName(experiment_params, i)\n",
    "            trialName = os.path.join(experimentPathAndName, modelName)\n",
    "            trialHash = TrialStatistics.getTrialName(experiment_params, i)\n",
    "\n",
    "            row_information = {\n",
    "                'experimentName': experimentName,\n",
    "                'modelName': modelName,\n",
    "                'datasetName': getDatasetName(config_parser.fixPaths(experiment_params)),\n",
    "                'experimentHash': experimentHash,\n",
    "                'trialHash': trialHash\n",
    "            }\n",
    "            row_information = {**row_information, **experiment_params} \n",
    "            print(row_information)\n",
    "\n",
    "            run = try_running(lambda : wandb.init(project=projectName_wandb, group=experimentName+\"-\"+experimentHash, name=trialHash, config=row_information), WANDB_message) #, reinit=True\n",
    "\n",
    "            # Train/Load model\n",
    "            model = CNN.create_model(architecture, experiment_params, device=device)\n",
    "\n",
    "            if detailed_reporting:\n",
    "                print(model)\n",
    "                summary(model, (3, 448, 448))\n",
    "                try_running(lambda : wandb.watch(model, log=\"all\"), WANDB_message)\n",
    "\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                print(\"Model {0} found!\".format(trialName))\n",
    "            else:\n",
    "                initModelPath = CNN.getInitModelFile(experimentPathAndName)\n",
    "                if os.path.exists(initModelPath):\n",
    "                    model.load_state_dict(torch.load(initModelPath))\n",
    "                    print(\"Init Model {0} found!\".format(initModelPath))\n",
    "                CNN.trainModel(train_loader, validation_loader, experiment_params, model, trialName, test_loader, device=device, detailed_reporting=detailed_reporting)\n",
    "\n",
    "            # Add to experiments file\n",
    "            if os.path.exists(experimentsFileNameAndPath):\n",
    "                experiments_df = pd.read_csv(experimentsFileNameAndPath)\n",
    "            else:\n",
    "                experiments_df = pd.DataFrame()\n",
    "\n",
    "            record_exists = not (experiments_df[experiments_df['modelName'] == modelName][experiments_df['experimentName'] == experimentName]).empty if not experiments_df.empty else False\n",
    "            if record_exists:\n",
    "                experiments_df.drop(experiments_df[experiments_df['modelName'] == modelName][experiments_df['experimentName'] == experimentName].index, inplace = True) \n",
    "\n",
    "            experiments_df = experiments_df.append(pd.DataFrame(row_information, index=[0]), ignore_index = True)\n",
    "            experiments_df.to_csv(experimentsFileNameAndPath, header=True, index=False)\n",
    "\n",
    "            try_running(lambda : run.finish(), WANDB_message)\n",
    "\n",
    "        bar.update()\n",
    "\n",
    "        experiment_index = experiment_index + 1\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     torch.multiprocessing.set_start_method('spawn')\n",
    "    \n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--cuda', required=True, type=int)\n",
    "#     parser.add_argument('--experiments', required=True)\n",
    "#     parser.add_argument('--data', required=True)\n",
    "#     parser.add_argument('--name', required=True)\n",
    "#     parser.add_argument('--detailed', required=False, action='store_true')\n",
    "#     args = parser.parse_args()\n",
    "#     main(experimentName=args.name, experimentsPath=args.experiments, dataPath=args.data, device=args.cuda, detailed_reporting=args.detailed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
