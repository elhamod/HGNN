{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_fine_csv_fileName = \"TableS2HoyalCuthilletal2019ScienceAdvances_cleaned.csv\"\n",
    "data_root=\"/raid/elhamod/Butterflies2/Datasets/LowResolution\"\n",
    "suffix = \"preprocessed\"\n",
    "image_subpath = \"images\"\n",
    "\n",
    "training_count=0.64\n",
    "validation_count=0.16#0.16 0 is used if we are planning to do cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata table headers.\n",
    "fine_csv_fileName_header = \"Image filename\"\n",
    "fine_csv_scientificName_header = \"Fullsubspecies\"\n",
    "fine_csv_usedColumns = [fine_csv_fileName_header,\n",
    "                          fine_csv_scientificName_header,]\n",
    "\n",
    "# species_csv_fileName_header = \"Image filename\"\n",
    "# species_csv_scientificName_header = \"Species\"\n",
    "# species_csv_fullsubspecies_header= \"Fullsubspecies\"\n",
    "# species_csv_view_header = \"View\"\n",
    "# species_csv_subspecies_header = \"Subspecies\"\n",
    "# species_csv_sex_header = \"Sex\"\n",
    "\n",
    "# species_csv_usedColumns = [species_csv_fileName_header,\n",
    "#                           species_csv_scientificName_header,\n",
    "#                           species_csv_view_header,\n",
    "#                           species_csv_subspecies_header,\n",
    "#                           species_csv_sex_header]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_fine_csv_fileName_full_path = os.path.join(data_root, suffix, cleaned_fine_csv_fileName)\n",
    "fine_csv = pd.read_csv(cleaned_fine_csv_fileName_full_path, delimiter=',', index_col=fine_csv_fileName_header, usecols=fine_csv_usedColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_labels = fine_csv[fine_csv_scientificName_header].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_csv_size = len(fine_csv.index)\n",
    "labels = fine_csv[fine_csv_scientificName_header].to_numpy()\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(fine_csv_size), test_size= 1-training_count-validation_count, \n",
    "                                                            stratify=labels)\n",
    "\n",
    "val_indices=[]\n",
    "if validation_count > 0:\n",
    "    labels_sub = labels[train_indices]\n",
    "    train_indices, val_indices = train_test_split(train_indices, test_size= validation_count/(validation_count+training_count), \n",
    "                                                                stratify=labels_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(experiment_name, indices, subset_name, csv):\n",
    "    # create directiory\n",
    "    folder_name = os.path.join(data_root, suffix, subset_name)\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    for i in tqdm(indices):\n",
    "        row = csv.iloc[i]\n",
    "        fine_label = row[fine_csv_scientificName_header]\n",
    "        file_name = csv.index[i]\n",
    "\n",
    "        # create fine_label directory if not found\n",
    "        sub_folder_name = os.path.join(data_root, suffix, subset_name, fine_label)\n",
    "        if not os.path.exists(sub_folder_name):\n",
    "            os.makedirs(sub_folder_name)\n",
    "            \n",
    "        # copy file\n",
    "        fileFullName = os.path.join(sub_folder_name,file_name)\n",
    "        newFile = shutil.copy(os.path.join(data_root, image_subpath, file_name), fileFullName)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8053f00eaffd48889eb53196c7ae36de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1027.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dataset(suffix, train_indices, 'train', fine_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8970af10dba141bcacfbd91d6ade579e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=257.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dataset(suffix, val_indices, 'val', fine_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d2aea2163a4f1c92016e42962fe03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=322.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_dataset(suffix, test_indices, 'test', fine_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
